#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
FunASR + Silero VAD è¯­éŸ³è¯†åˆ«æ¨¡å—
åŸºäºFunASR ASR + Silero VADçš„è¯­éŸ³å½•å…¥å’Œè¯†åˆ«åŠŸèƒ½ï¼Œå¯ä½œä¸ºæ¨¡å—å¯¼å…¥ä½¿ç”¨
ç»“åˆç¥ç»ç½‘ç»œVADã€æµå¼è¯†åˆ«å’Œå¤šç§ä¼˜åŒ–ç­–ç•¥

Silero VADä¼˜åŠ¿ï¼š
- ç¥ç»ç½‘ç»œVADï¼Œæ¯”ä¼ ç»Ÿèƒ½é‡é˜ˆå€¼æ›´å‡†ç¡®
- æŠ—å™ªéŸ³èƒ½åŠ›å¼ºï¼Œè¯¯æ£€ç‡ä½
- èƒ½å¤Ÿæ£€æµ‹è½»å£°è¯­éŸ³
- æ— éœ€æ‰‹åŠ¨è°ƒå‚ï¼Œå¼€ç®±å³ç”¨
- æµå¼æ”¯æŒï¼Œä½å»¶è¿Ÿ
- Hugging Faceç»´æŠ¤ï¼ŒæŒç»­æ›´æ–°

ä½¿ç”¨ç¤ºä¾‹:
    from funasr_voice_Silero import FunASRVoiceRecognizer

    recognizer = FunASRVoiceRecognizer()
    recognizer.initialize()
    result = recognizer.recognize_speech(duration=10)
    print(f"è¯†åˆ«ç»“æœ: {result}")
"""

import os
import sys
import warnings
import logging
import torch
import numpy as np

# å¯¼å…¥æ€§èƒ½ç›‘æ§
from performance_monitor import performance_monitor, PerformanceStep

# å¯¼å…¥Debugæ€§èƒ½è¿½è¸ªæ¨¡å—
try:
    from debug_performance_tracker import debug_tracker
except ImportError:
    debug_tracker = None

# Silero VADç›¸å…³
SILERO_VAD_AVAILABLE = False
silero_vad_model = None
silero_vad_utils = None

try:
    # åŠ è½½æœ¬åœ°Silero VAD
    silero_vad_path = "F:/04_AI/01_Workplace/silero-vad"
    if os.path.exists(silero_vad_path):
        sys.path.insert(0, os.path.join(silero_vad_path, "src"))

        # å¯¼å…¥æœ¬åœ°Silero VAD (åŸºäºçœŸå®API)
        from silero_vad import silero_vad, utils_vad

        # åˆ›å»ºSilero VADå®ä¾‹
        silero_vad_model, silero_vad_utils = silero_vad()
        SILERO_VAD_AVAILABLE = True
        print("âœ… Silero VAD åŠ è½½æˆåŠŸ (ä½¿ç”¨æœ¬åœ°æ¨¡å‹)")

    else:
        print(f"âš ï¸ Silero VADè·¯å¾„ä¸å­˜åœ¨: {silero_vad_path}")
        print("ğŸ”„ å°è¯•ä»torch hubåŠ è½½...")
        # å¤‡é€‰ï¼štorch hubåŠ è½½
        silero_vad_model, silero_vad_utils = torch.hub.load(
            repo_or_dir='snakers4/silero-vad',
            model='silero_vad',
            force_reload=False
        )
        SILERO_VAD_AVAILABLE = True
        print("âœ… Silero VAD ä»torch hubåŠ è½½æˆåŠŸ")

except Exception as e:
    print(f"âš ï¸ Silero VADåŠ è½½å¤±è´¥: {e}")
    print("ğŸ’¡ å»ºè®®æ£€æŸ¥:")
    print("  1. torch å’Œ torchaudio æ˜¯å¦å·²å®‰è£…")
    print("  2. ç½‘ç»œè¿æ¥æ˜¯å¦æ­£å¸¸")
    print("  3. å°†è‡ªåŠ¨å›é€€åˆ°èƒ½é‡é˜ˆå€¼VAD")
    SILERO_VAD_AVAILABLE = False

# å½»åº•æŠ‘åˆ¶FunASRçš„è¿›åº¦æ¡å’Œè°ƒè¯•è¾“å‡º
os.environ['TQDM_DISABLE'] = '1'
os.environ['PYTHONWARNINGS'] = 'ignore'
os.environ['HIDE_PROGRESS'] = '1'
os.environ['FUNASR_LOG_LEVEL'] = 'ERROR'

# é…ç½®æ—¥å¿—çº§åˆ«ï¼Œåªæ˜¾ç¤ºé”™è¯¯
logging.getLogger("funasr").setLevel(logging.ERROR)
logging.getLogger("modelscope").setLevel(logging.ERROR)
logging.getLogger("transformers").setLevel(logging.ERROR)

warnings.filterwarnings('ignore')

# ============================================================================
# ğŸ”§ å…³é”®ï¼šFFmpegç¯å¢ƒå¿…é¡»åœ¨FunASRå¯¼å…¥å‰è®¾ç½®
# ============================================================================
def setup_ffmpeg_environment():
    """è®¾ç½®FFmpegç¯å¢ƒï¼ˆå¿…é¡»åœ¨å¯¼å…¥FunASRä¹‹å‰è°ƒç”¨ï¼‰"""
    # æ–¹æ³•1ï¼šä½¿ç”¨ç¯å¢ƒå˜é‡æ°¸ä¹…è®¾ç½®ï¼ˆæœ€å¿«ï¼‰
    # å¦‚æœå·²ç»è®¾ç½®è¿‡FFmpegè·¯å¾„ï¼Œç›´æ¥è·³è¿‡
    if os.environ.get('FFMPEG_PATH_SET') == '1':
        return True

    try:
        # æ–¹æ³•2ï¼šé…ç½®å›ºå®šè·¯å¾„ï¼ˆæ¨èç”¨äºå¿«é€Ÿå¯åŠ¨ï¼‰
        # è¿™é‡Œè®¾ç½®ä¸€ä¸ªå›ºå®šçš„FFmpegè·¯å¾„ï¼Œé¿å…å¤šæ¬¡æ£€æŸ¥
        # ç”¨æˆ·å¯ä»¥æ ¹æ®å®é™…æƒ…å†µä¿®æ”¹è¿™ä¸ªè·¯å¾„
        FIXED_FFMPEG_PATH = "./onnx_deps/ffmpeg-master-latest-win64-gpl-shared/bin"

        if FIXED_FFMPEG_PATH and os.path.exists(FIXED_FFMPEG_PATH):
            current_path = os.environ.get('PATH', '')
            if FIXED_FFMPEG_PATH not in current_path:
                os.environ['PATH'] = FIXED_FFMPEG_PATH + os.pathsep + current_path
            # æ ‡è®°FFmpegè·¯å¾„å·²è®¾ç½®
            os.environ['FFMPEG_PATH_SET'] = '1'
            return True

        # æ–¹æ³•3ï¼šå¿«é€Ÿæ£€æŸ¥ï¼ˆä»…æ£€æŸ¥æœ€å¯èƒ½çš„ä½ç½®ï¼‰
        script_dir = os.path.dirname(os.path.abspath(__file__))
        fast_check_paths = [
            # ä¸»è¦æ£€æŸ¥FunASR_Deploymentç›®å½•
            os.path.join(script_dir, "FunASR_Deployment",
                        "dependencies", "ffmpeg-master-latest-win64-gpl-shared", "bin"),
        ]

        for ffmpeg_path in fast_check_paths:
            if os.path.exists(ffmpeg_path):
                current_path = os.environ.get('PATH', '')
                if ffmpeg_path not in current_path:
                    os.environ['PATH'] = ffmpeg_path + os.pathsep + current_path
                os.environ['FFMPEG_PATH_SET'] = '1'
                return True

        # æ³¨æ„ï¼šç³»ç»ŸPATHæ£€æŸ¥å·²ç§»é™¤ï¼Œå› ä¸ºå®ƒè¾ƒæ…¢
        # å»ºè®®ï¼šå°†FFmpegæ·»åŠ åˆ°ç³»ç»Ÿç¯å¢ƒå˜é‡PATHä¸­
        print("âš ï¸ æœªæ‰¾åˆ°FFmpegå¿«é€Ÿè·¯å¾„")
        print("ğŸ’¡ æ€§èƒ½ä¼˜åŒ–å»ºè®®ï¼š")
        print("  1. å°†FFmpegå®‰è£…åˆ°ç³»ç»ŸPATHç¯å¢ƒå˜é‡ä¸­")
        print(f"  2. æˆ–ä¿®æ”¹ä»£ç ä¸­çš„FIXED_FFMPEG_PATHä¸ºæ‚¨çš„FFmpegè·¯å¾„")

        return False

    except Exception:
        # é™é»˜å¤±è´¥ï¼Œé¿å…å½±å“å¯åŠ¨é€Ÿåº¦
        return False

# ç«‹å³æ‰§è¡ŒFFmpegç¯å¢ƒè®¾ç½®
setup_ffmpeg_environment()

# ============================================================================
# ğŸ“¦ å¯¼å…¥å…¶ä»–ä¾èµ–
# ============================================================================
import io
import time
import pyaudio
import threading
from contextlib import contextmanager
from typing import List, Dict, Optional, Callable, Union, Tuple, Any
from dataclasses import dataclass
from collections import deque

# ä½¿ç”¨ç»Ÿä¸€çš„æ—¥å¿—å·¥å…·ç±»
from logging_utils import LoggingManager

# è·å–é…ç½®å¥½çš„æ—¥å¿—è®°å½•å™¨ï¼ˆå‚è€ƒvoice_gui.pyçš„é…ç½®é£æ ¼ï¼‰
logger = LoggingManager.get_logger(
    name='funasr_voice_Silero',
    level=logging.DEBUG,  # æ–‡ä»¶è®°å½•è¯¦ç»†æ—¥å¿—
    console_level=logging.INFO,  # æ§åˆ¶å°æ˜¾ç¤ºINFOåŠä»¥ä¸Šä¿¡æ¯
    log_to_console=True,
    log_to_file=True
)

# å…¨å±€å¯ç”¨æ€§æ£€æŸ¥
FUNASR_AVAILABLE = False
PYAUDIO_AVAILABLE = False
NUMPY_AVAILABLE = False

# æ£€æŸ¥ä¾èµ–
try:
    import numpy as np
    NUMPY_AVAILABLE = True
except ImportError:
    logger.error("âŒ numpy ä¸å¯ç”¨ï¼Œè¯·å®‰è£…: pip install numpy")
    # ä¸è®¾ç½® np å˜é‡ï¼Œé¿å…ç±»å‹å†²çª

try:
    import pyaudio
    PYAUDIO_AVAILABLE = True
except ImportError:
    logger.error("âŒ pyaudio ä¸å¯ç”¨ï¼Œè¯·å®‰è£…: pip install pyaudio")

try:
    from funasr import AutoModel
    FUNASR_AVAILABLE = True
    logger.info("âœ… FunASR æ¨¡å—å¯ç”¨")
except ImportError as e:
    logger.error(f"âŒ FunASR ä¸å¯ç”¨: {e}")
    AutoModel = None

@dataclass
class RecognitionResult:
    """è¯­éŸ³è¯†åˆ«ç»“æœæ•°æ®ç±»"""
    text: str                    # æœ€ç»ˆè¯†åˆ«æ–‡æœ¬
    partial_results: List[str]   # éƒ¨åˆ†è¯†åˆ«ç»“æœåˆ—è¡¨
    confidence: float            # ç½®ä¿¡åº¦
    duration: float              # è¯†åˆ«æ—¶é•¿
    timestamp: float             # æ—¶é—´æˆ³
    audio_buffer: List[np.ndarray]  # éŸ³é¢‘ç¼“å†²åŒº

@dataclass
class VADConfig:
    """Silero VADé…ç½®"""
    # Silero VADä¸»è¦å‚æ•°
    vad_threshold: float = 0.5           # VADæ£€æµ‹é˜ˆå€¼ (0-1)
    min_speech_duration: float = 0.25    # æœ€å°è¯­éŸ³æ—¶é•¿ (250ms)
    min_silence_duration: float = 0.1    # æœ€å°é™éŸ³æ—¶é•¿ (100ms)
    speech_padding: float = 0.03          # è¯­éŸ³å¡«å…… (30ms)

    # å›é€€é…ç½®ï¼šå½“Silero VADä¸å¯ç”¨æ—¶ä½¿ç”¨
    fallback_energy_threshold: float = 0.015  # å›é€€åˆ°èƒ½é‡é˜ˆå€¼

    # Silero VADç‰¹å®šé…ç½®
    use_silero_vad: bool = True        # æ˜¯å¦ä½¿ç”¨Silero VAD
    auto_fallback: bool = True          # è‡ªåŠ¨å›é€€åˆ°èƒ½é‡é˜ˆå€¼

    # Silero VADé«˜çº§å‚æ•°
    window_size_samples: int = 512        # çª—å£å¤§å°æ ·æœ¬æ•°
    min_speech_duration_ms: int = 250   # æœ€å°è¯­éŸ³æ—¶é•¿æ¯«ç§’
    min_silence_duration_ms: int = 100   # æœ€å°é™éŸ³æ—¶é•¿æ¯«ç§’
    speech_pad_ms: int = 30            # è¯­éŸ³å¡«å……æ¯«ç§’

@dataclass
class FunASRConfig:
    """FunASRé…ç½®"""
    model_path: str = "f:/04_AI/01_Workplace/Voice_Input/model/fun"
    device: str = "cpu"
    chunk_size: Optional[List[int]] = None
    encoder_chunk_look_back: int = 4
    decoder_chunk_look_back: int = 1
    disable_update: bool = True
    trust_remote_code: bool = False

    def __post_init__(self):
        if self.chunk_size is None:
            self.chunk_size = [0, 10, 5]  # é»˜è®¤æµå¼å‚æ•°

class FunASRVoiceRecognizer:
    """
    FunASR + Silero VAD è¯­éŸ³è¯†åˆ«å™¨ä¸»ç±»
    æä¾›è¯­éŸ³å½•å…¥ã€è¯†åˆ«å’Œç¥ç»ç½‘ç»œVADåŠŸèƒ½
    """

    def __init__(self,
                 model_path: Optional[str] = None,
                 device: str = "cpu",
                 sample_rate: int = 16000,
                 chunk_size: int = 400,
                 silent_mode: bool = True):
        """
        åˆå§‹åŒ–è¯­éŸ³è¯†åˆ«å™¨

        Args:
            model_path: FunASRæ¨¡å‹è·¯å¾„
            device: è®¾å¤‡ç±»å‹ ("cpu" æˆ– "cuda")
            sample_rate: éŸ³é¢‘é‡‡æ ·ç‡
            chunk_size: éŸ³é¢‘å—å¤§å°
            silent_mode: é™é»˜æ¨¡å¼ï¼Œéšè—ä¸­é—´è¿‡ç¨‹ä¿¡æ¯
        """
        # åŸºç¡€é…ç½®
        self.sample_rate = sample_rate
        self.chunk_size = chunk_size
        self.model_path = model_path or "./model/fun"
        self.silent_mode = silent_mode

        # FunASRé…ç½®
        self.funasr_config = FunASRConfig(
            model_path=self.model_path,
            device=device
        )

        # VADé…ç½® - æ”¯æŒä»é…ç½®æ–‡ä»¶åŠ è½½
        self.vad_config = self._load_vad_config()

        # æ¨¡å‹ç›¸å…³
        self._model: Optional[Any] = None
        self._model_loaded = False
        self._model_load_time = 0.0

        # è¿è¡ŒçŠ¶æ€
        self._is_initialized = False
        self._is_running = False
        self._stop_event = threading.Event()
        self._speech_detected = False

        # éŸ³é¢‘å¤„ç†
        self._audio_buffer: deque[np.ndarray] = deque(maxlen=sample_rate * 5)  # 5ç§’ç¼“å†²
        self._speech_buffer: List[np.ndarray] = []
        self._funasr_cache: Dict[str, Any] = {}

        # Silero VADéŸ³é¢‘ç¼“å†² (ç”¨äºå¤„ç†512æ ·æœ¬çš„çª—å£)
        self._silero_vad_buffer: List[np.ndarray] = []
        self._silero_window_size = 512  # Silero VADè¦æ±‚çš„çª—å£å¤§å°

        # è¯†åˆ«ç»“æœ
        self._current_text = ""
        self._partial_results: List[str] = []
        self._final_results: List[RecognitionResult] = []

        # ç»Ÿè®¡ä¿¡æ¯
        self.stats = {
            'total_recognitions': 0,
            'successful_recognitions': 0,
            'total_audio_time': 0.0,
            'total_processing_time': 0.0,
            'average_confidence': 0.0
        }

        # å›è°ƒå‡½æ•°
        self._on_partial_result: Optional[Callable[[str], None]] = None
        self._on_final_result: Optional[Callable[[RecognitionResult], None]] = None
        self._on_vad_event: Optional[Callable[[str, Dict], None]] = None

        # Silero VADåˆå§‹åŒ–çŠ¶æ€
        self._silero_vad_enabled = SILERO_VAD_AVAILABLE and self.vad_config.use_silero_vad

    def _load_vad_config(self):
        """ä»é…ç½®åŠ è½½å™¨åŠ è½½VADè®¾ç½®"""
        try:
            from config_loader import config

            return VADConfig(
                vad_threshold=0.5,  # Silero VADé»˜è®¤é˜ˆå€¼
                min_speech_duration=config.get_vad_min_speech_duration(),
                min_silence_duration=config.get_vad_min_silence_duration(),
                speech_padding=config.get_vad_speech_padding(),
                fallback_energy_threshold=config.get_vad_energy_threshold(),
                use_silero_vad=True,  # é»˜è®¤ä½¿ç”¨Silero VAD
                auto_fallback=True
            )

        except Exception as e:
            logger.warning(f"åŠ è½½VADé…ç½®å¤±è´¥: {e}ï¼Œä½¿ç”¨é»˜è®¤é…ç½®")
            return VADConfig()

    def _get_gui_display_threshold(self) -> float:
        """è·å–GUIèƒ½é‡æ˜¾ç¤ºé˜ˆå€¼ï¼ˆç‹¬ç«‹äºVADæ£€æµ‹ï¼‰"""
        try:
            from config_loader import config
            return config.get_gui_display_threshold()
        except Exception as e:
            logger.warning(f"åŠ è½½GUIæ˜¾ç¤ºé˜ˆå€¼å¤±è´¥: {e}ï¼Œä½¿ç”¨é»˜è®¤å€¼0.00001")
            return 0.00001

    def set_callbacks(self,
                     on_partial_result: Optional[Callable[[str], None]] = None,
                     on_final_result: Optional[Callable[[RecognitionResult], None]] = None,
                     on_vad_event: Optional[Callable[[str, Dict], None]] = None):
        """
        è®¾ç½®å›è°ƒå‡½æ•°

        Args:
            on_partial_result: éƒ¨åˆ†ç»“æœå›è°ƒ
            on_final_result: æœ€ç»ˆç»“æœå›è°ƒ
            on_vad_event: VADäº‹ä»¶å›è°ƒ
        """
        self._on_partial_result = on_partial_result
        self._on_final_result = on_final_result
        self._on_vad_event = on_vad_event

    def setup_environment(self) -> bool:
        """è®¾ç½®è¿è¡Œç¯å¢ƒ"""
        try:
            # è®¾ç½®FFmpegè·¯å¾„ï¼ˆå¦‚æœéœ€è¦ï¼‰
            script_dir = os.path.dirname(os.path.abspath(__file__))
            local_ffmpeg_bin = os.path.join(script_dir, "FunASR_Deployment",
                                          "dependencies", "ffmpeg-master-latest-win64-gpl-shared", "bin")

            if os.path.exists(local_ffmpeg_bin):
                current_path = os.environ.get('PATH', '')
                if local_ffmpeg_bin not in current_path:
                    os.environ['PATH'] = local_ffmpeg_bin + os.pathsep + current_path
                    logger.info(f"ğŸ”§ è®¾ç½®æœ¬åœ°FFmpeg: {local_ffmpeg_bin}")

            return True

        except Exception as e:
            logger.warning(f"ç¯å¢ƒè®¾ç½®å¤±è´¥: {e}")
            return False

    def check_dependencies(self) -> bool:
        """æ£€æŸ¥ä¾èµ–æ˜¯å¦æ»¡è¶³"""
        missing_deps = []

        if not NUMPY_AVAILABLE:
            missing_deps.append("numpy")
        if not PYAUDIO_AVAILABLE:
            missing_deps.append("pyaudio")
        if not FUNASR_AVAILABLE:
            missing_deps.append("funasr")

        if missing_deps:
            logger.error(f"âŒ ç¼ºå°‘ä¾èµ–: {', '.join(missing_deps)}")
            logger.error("è¯·æ‰§è¡Œ: pip install " + " ".join(missing_deps))
            return False

        return True

    def initialize(self) -> bool:
        """åˆå§‹åŒ–è¯†åˆ«å™¨ï¼Œä¼˜åŒ–ç¬¬ä¸€æ¬¡å¯åŠ¨æ€§èƒ½"""
        if self._is_initialized:
            logger.info("âœ… è¯†åˆ«å™¨å·²åˆå§‹åŒ–")
            return True

        logger.info("ğŸš€ åˆå§‹åŒ–FunASR + Silero VADè¯­éŸ³è¯†åˆ«å™¨...")
        init_start_time = time.time()

        # æ£€æŸ¥ä¾èµ– - å‰ç½®æ£€æŸ¥ï¼Œé¿å…åç»­å¤±è´¥
        if not self.check_dependencies():
            return False

        # è®¾ç½®ç¯å¢ƒ - é¢„å…ˆé…ç½®ï¼Œå‡å°‘è¿è¡Œæ—¶å»¶è¿Ÿ
        self.setup_environment()

        # åŠ è½½æ¨¡å‹ - æ ¸å¿ƒä¼˜åŒ–ç‚¹
        if not self._load_model():
            return False

        self._is_initialized = True
        total_init_time = time.time() - init_start_time
        logger.info(f"âœ… FunASR + Silero VADè¯­éŸ³è¯†åˆ«å™¨åˆå§‹åŒ–å®Œæˆ (æ€»è€—æ—¶: {total_init_time:.2f}ç§’)")

        # æ˜¾ç¤ºVADçŠ¶æ€
        if self._silero_vad_enabled:
            logger.info("ğŸ¯ Silero VADå·²å¯ç”¨ (window_size=512, threshold=0.5)")
        else:
            logger.info("âš ï¸ Silero VADä¸å¯ç”¨ï¼Œä½¿ç”¨å›é€€çš„èƒ½é‡é˜ˆå€¼VAD")

        return True

    def _load_model(self) -> bool:
        """åŠ è½½FunASRæ¨¡å‹"""
        if self._model_loaded:
            return True

        if not FUNASR_AVAILABLE:
            logger.error("âŒ FunASRä¸å¯ç”¨")
            return False

        logger.info(f"ğŸ“¦ åŠ è½½FunASRæ¨¡å‹: {self.model_path}")
        start_time = time.time()

        try:
            # æ£€æŸ¥æ¨¡å‹è·¯å¾„
            if not os.path.exists(self.model_path):
                logger.error(f"âŒ æ¨¡å‹è·¯å¾„ä¸å­˜åœ¨: {self.model_path}")
                return False

            # åŠ è½½æ¨¡å‹
            self._model = AutoModel(
                model=self.funasr_config.model_path,
                device=self.funasr_config.device,
                trust_remote_code=self.funasr_config.trust_remote_code,
                disable_update=self.funasr_config.disable_update
            )

            self._model_loaded = True
            self._model_load_time = time.time() - start_time

            logger.info(f"âœ… æ¨¡å‹åŠ è½½æˆåŠŸ (è€—æ—¶: {self._model_load_time:.2f}ç§’)")
            return True

        except Exception as e:
            logger.error(f"âŒ æ¨¡å‹åŠ è½½å¤±è´¥: {e}")
            import traceback
            logger.error(f"è¯¦ç»†é”™è¯¯: {traceback.format_exc()}")
            return False

    def _detect_vad(self, audio_data: np.ndarray, current_time: float) -> Tuple[bool, Optional[str]]:
        """
        VADè¯­éŸ³æ´»åŠ¨æ£€æµ‹ - ä½¿ç”¨Silero VAD

        Args:
            audio_data: éŸ³é¢‘æ•°æ®
            current_time: å½“å‰æ—¶é—´

        Returns:
            (is_speech, event_type): æ˜¯å¦æœ‰è¯­éŸ³å’Œäº‹ä»¶ç±»å‹
        """
        is_speech = False
        vad_confidence = 0.0

        # ä¼˜å…ˆä½¿ç”¨Silero VAD
        if self._silero_vad_enabled and silero_vad_model and silero_vad_utils:
            try:
                # å°†éŸ³é¢‘æ•°æ®æ·»åŠ åˆ°Silero VADç¼“å†²åŒº
                self._silero_vad_buffer.extend(audio_data)

                # å½“ç¼“å†²åŒºè¶³å¤Ÿå¤§æ—¶ï¼Œå¤„ç†Silero VAD
                is_speech = False
                while len(self._silero_vad_buffer) >= self._silero_window_size:
                    # å–å‡º512ä¸ªæ ·æœ¬è¿›è¡Œå¤„ç†
                    window_audio = np.array(self._silero_vad_buffer[:self._silero_window_size])
                    self._silero_vad_buffer = self._silero_vad_buffer[self._silero_window_size:]

                    # è½¬æ¢ä¸ºtorch tensor
                    if isinstance(window_audio, np.ndarray):
                        audio_tensor = torch.from_numpy(window_audio).float()
                    else:
                        audio_tensor = window_audio.float()

                    # ä½¿ç”¨Silero VADçš„get_speech_timestampsæ–¹æ³• (åŸºäºçœŸå®API)
                    try:
                        # get_speech_timestampséœ€è¦å®Œæ•´çš„éŸ³é¢‘ï¼Œè¿™é‡Œä½¿ç”¨ç®€åŒ–çš„VADæ£€æµ‹
                        # å®é™…ä¸Šï¼Œæˆ‘ä»¬éœ€è¦çš„æ˜¯å®æ—¶çš„VADåˆ¤æ–­
                        if hasattr(silero_vad_model, '__call__'):
                            # ç›´æ¥è°ƒç”¨æ¨¡å‹è¿›è¡ŒVADæ¨ç†
                            with torch.no_grad():
                                vad_output = silero_vad_model(audio_tensor)
                                # vad_outputé€šå¸¸æ˜¯è¯­éŸ³æ¦‚ç‡
                                if len(vad_output.shape) > 0:
                                    vad_confidence = float(vad_output.mean())
                                    is_speech = vad_confidence > self.vad_config.vad_threshold
                        else:
                            # å¦‚æœæ— æ³•ç›´æ¥è°ƒç”¨ï¼Œå›é€€åˆ°èƒ½é‡é˜ˆå€¼
                            energy = np.sqrt(np.mean(audio_data ** 2))
                            vad_confidence = energy
                            is_speech = energy > self.vad_config.fallback_energy_threshold

                    except Exception as vad_error:
                        logger.debug(f"Silero VADæ¨ç†å¤±è´¥: {vad_error}")
                        # å›é€€åˆ°èƒ½é‡é˜ˆå€¼
                        energy = np.sqrt(np.mean(audio_data ** 2))
                        vad_confidence = energy
                        is_speech = energy > self.vad_config.fallback_energy_threshold

                    if is_speech:
                        break  # åªè¦æœ‰ä¸€ä¸ªçª—å£æ£€æµ‹åˆ°è¯­éŸ³ï¼Œå°±è®¤ä¸ºå½“å‰æœ‰è¯­éŸ³

                logger.debug(f"Silero VAD: ç½®ä¿¡åº¦={vad_confidence:.6f}, æ£€æµ‹è¯­éŸ³={is_speech}")

            except Exception as e:
                logger.error(f"âŒ Silero VADæ£€æµ‹å¤±è´¥: {e}")
                # è‡ªåŠ¨å›é€€åˆ°èƒ½é‡é˜ˆå€¼
                if self.vad_config.auto_fallback:
                    energy = np.sqrt(np.mean(audio_data ** 2))
                    is_speech = energy > self.vad_config.fallback_energy_threshold
                    vad_confidence = energy
                    logger.debug(f"å›é€€åˆ°èƒ½é‡é˜ˆå€¼: {energy:.6f}")

        else:
            # å›é€€åˆ°ä¼ ç»Ÿèƒ½é‡é˜ˆå€¼VAD
            energy = np.sqrt(np.mean(audio_data ** 2))
            is_speech = energy > self.vad_config.fallback_energy_threshold
            vad_confidence = energy if is_speech else 0.0

        # è®¡ç®—éŸ³é¢‘èƒ½é‡ï¼ˆç”¨äºæ˜¾ç¤ºå’Œè°ƒè¯•ï¼‰
        audio_energy = np.sqrt(np.mean(audio_data ** 2))

        # äº‹ä»¶çŠ¶æ€ç®¡ç†
        event_type = None
        if is_speech:
            if not hasattr(self, '_speech_detected') or not self._speech_detected:
                event_type = "speech_start"
                self._speech_detected = True
                self._speech_start_time = current_time
                vad_method = "Silero VAD" if self._silero_vad_enabled else "Energy Threshold"
                logger.info(f"ğŸ¤ è¯­éŸ³å¼€å§‹ ({vad_method}: {vad_confidence:.3f}, èƒ½é‡: {audio_energy:.6f})")
        else:
            if hasattr(self, '_speech_detected') and self._speech_detected:
                silence_duration = current_time - getattr(self, '_last_speech_time', current_time)
                if silence_duration >= self.vad_config.min_silence_duration:
                    event_type = "speech_end"
                    self._speech_detected = False
                    vad_method = "Silero VAD" if self._silero_vad_enabled else "Energy Threshold"
                    logger.info(f"ğŸ”‡ è¯­éŸ³ç»“æŸ (é™éŸ³{silence_duration:.2f}s, {vad_method}: {vad_confidence:.3f})")

        if is_speech:
            self._last_speech_time = current_time

        return is_speech, event_type

    def _process_audio_chunk(self, audio_data: np.ndarray, current_time: float):
        """
        å¤„ç†éŸ³é¢‘å—

        Args:
            audio_data: éŸ³é¢‘æ•°æ®
            current_time: å½“å‰æ—¶é—´
        """
        # æ·»åŠ åˆ°éŸ³é¢‘ç¼“å†²åŒº
        self._audio_buffer.extend(audio_data)

        # VADæ£€æµ‹
        is_speech, vad_event = self._detect_vad(audio_data, current_time)

        # è®¡ç®—éŸ³é¢‘èƒ½é‡
        audio_energy = np.sqrt(np.mean(audio_data ** 2))

        # æ£€æŸ¥æ˜¯å¦åº”è¯¥å‘é€GUIèƒ½é‡æ›´æ–°
        gui_threshold = self._get_gui_display_threshold()
        should_send_gui_update = not vad_event and audio_energy > gui_threshold

        # å¦‚æœæ²¡æœ‰VADäº‹ä»¶ä½†èƒ½é‡è¶…è¿‡æ˜¾ç¤ºé˜ˆå€¼ï¼Œä¹Ÿå‘é€èƒ½é‡æ›´æ–°ç”¨äºæ˜¾ç¤º
        if should_send_gui_update:
            if self._on_vad_event:
                self._on_vad_event("energy_update", {
                    'time': current_time,
                    'energy': audio_energy
                })

        if vad_event and self._on_vad_event:
            self._on_vad_event(vad_event, {
                'time': current_time,
                'energy': audio_energy
            })

        # å¦‚æœæ£€æµ‹åˆ°è¯­éŸ³ï¼Œæ·»åŠ åˆ°è¯­éŸ³ç¼“å†²åŒº
        if is_speech:
            # è®°å½•è¯­éŸ³è¾“å…¥å¼€å§‹ï¼ˆå¦‚æœæ˜¯æ–°çš„è¯­éŸ³æ®µï¼‰
            if vad_event == "speech_start" and debug_tracker:
                debug_tracker.record_voice_input_start(audio_energy)

            self._speech_buffer.extend(audio_data)

            # å®šæœŸè¿›è¡Œæµå¼è¯†åˆ«
            if len(self._speech_buffer) >= self.sample_rate * 1:  # 1ç§’éŸ³é¢‘
                self._perform_streaming_recognition()
        else:
            # å¦‚æœé™éŸ³æ—¶é—´è¶³å¤Ÿé•¿ä¸”æœ‰è¯­éŸ³ç¼“å†²åŒºï¼Œè¿›è¡Œæœ€ç»ˆè¯†åˆ«
            if (len(self._speech_buffer) > 0 and
                hasattr(self, '_last_speech_time') and
                current_time - self._last_speech_time >= self.vad_config.min_silence_duration):

                if len(self._speech_buffer) >= self.sample_rate * self.vad_config.min_speech_duration:
                    # è®°å½•è¯­éŸ³è¾“å…¥ç»“æŸå’ŒASRå¼€å§‹
                    if debug_tracker:
                        debug_tracker.record_voice_input_end(len(self._speech_buffer) / self.sample_rate)
                        debug_tracker.record_asr_start(len(self._speech_buffer))

                    self._perform_final_recognition()

    def _perform_streaming_recognition(self):
        """æ‰§è¡Œæµå¼è¯†åˆ«"""
        if not self._model or not self._model_loaded:
            return

        try:
            # å–æœ€è¿‘çš„éŸ³é¢‘æ•°æ®è¿›è¡Œè¯†åˆ«
            audio_array = np.array(list(self._speech_buffer))

            result = self._model.generate(
                input=audio_array,
                cache=self._funasr_cache,
                is_final=False,
                chunk_size=self.funasr_config.chunk_size,
                encoder_chunk_look_back=self.funasr_config.encoder_chunk_look_back,
                decoder_chunk_look_back=self.funasr_config.decoder_chunk_look_back
            )

            if result and isinstance(result, list) and len(result) > 0:
                text = result[0].get("text", "").strip()
                if text and text != self._current_text:
                    self._current_text = text
                    self._partial_results.append(text)

                    # è§¦å‘éƒ¨åˆ†ç»“æœå›è°ƒ
                    if self._on_partial_result:
                        self._on_partial_result(text)

                    if not self.silent_mode:
                        logger.info(f"ğŸ—£ï¸ æµå¼è¯†åˆ«: '{text}'")

        except Exception as e:
            logger.debug(f"æµå¼è¯†åˆ«å¼‚å¸¸: {e}")

    def _perform_final_recognition(self):
        """æ‰§è¡Œæœ€ç»ˆè¯†åˆ«"""
        if not self._model or not self._model_loaded or not self._speech_buffer:
            return

        try:
            start_time = time.time()

            audio_array = np.array(list(self._speech_buffer))

            result = self._model.generate(
                input=audio_array,
                cache=self._funasr_cache,
                is_final=True,
                chunk_size=self.funasr_config.chunk_size,
                encoder_chunk_look_back=self.funasr_config.encoder_chunk_look_back,
                decoder_chunk_look_back=self.funasr_config.decoder_chunk_look_back
            )

            processing_time = time.time() - start_time

            if result and isinstance(result, list) and len(result) > 0:
                text = result[0].get("text", "").strip()
                if text:
                    # åˆ›å»ºè¯†åˆ«ç»“æœ
                    recognition_result = RecognitionResult(
                        text=text,
                        partial_results=self._partial_results.copy(),
                        confidence=0.9,  # FunASRæš‚ä¸æä¾›ç½®ä¿¡åº¦ï¼Œä½¿ç”¨é»˜è®¤å€¼
                        duration=len(self._speech_buffer) / self.sample_rate,
                        timestamp=time.time(),
                        audio_buffer=self._speech_buffer.copy()
                    )

                    self._final_results.append(recognition_result)
                    self.stats['total_recognitions'] += 1
                    self.stats['successful_recognitions'] += 1
                    self.stats['total_processing_time'] += processing_time

                    # è§¦å‘æœ€ç»ˆç»“æœå›è°ƒ
                    if self._on_final_result:
                        self._on_final_result(recognition_result)

                    if not self.silent_mode:
                        logger.info(f"âœ… æœ€ç»ˆè¯†åˆ«: '{text}' (è€—æ—¶: {processing_time:.3f}s)")

        except Exception as e:
            logger.error(f"æœ€ç»ˆè¯†åˆ«å¼‚å¸¸: {e}")
        finally:
            # æ¸…ç©ºè¯­éŸ³ç¼“å†²åŒº
            self._speech_buffer = []
            self._current_text = ""

    def get_status(self) -> Dict[str, Any]:
        """è·å–è¯†åˆ«å™¨çŠ¶æ€"""
        return {
            'initialized': self._is_initialized,
            'model_loaded': self._model_loaded,
            'model_path': self.model_path,
            'device': self.funasr_config.device,
            'vad_method': 'Silero VAD' if self._silero_vad_enabled else 'Energy Threshold',
            'silero_vad_available': SILERO_VAD_AVAILABLE,
            'stats': self.stats.copy(),
            'model_load_time': self._model_load_time,
            'dependencies': {
                'funasr': FUNASR_AVAILABLE,
                'pyaudio': PYAUDIO_AVAILABLE,
                'numpy': NUMPY_AVAILABLE,
                'silero_vad': SILERO_VAD_AVAILABLE
            }
        }

# ä¾¿æ·å‡½æ•°
def create_recognizer(model_path: Optional[str] = None,
                     device: str = "cpu") -> FunASRVoiceRecognizer:
    """
    åˆ›å»ºå¹¶åˆå§‹åŒ–è¯­éŸ³è¯†åˆ«å™¨

    Args:
        model_path: æ¨¡å‹è·¯å¾„
        device: è®¾å¤‡ç±»å‹

    Returns:
        FunASRVoiceRecognizer: å·²åˆå§‹åŒ–çš„è¯†åˆ«å™¨
    """
    recognizer = FunASRVoiceRecognizer(model_path=model_path, device=device)
    if not recognizer.initialize():
        raise RuntimeError("è¯†åˆ«å™¨åˆå§‹åŒ–å¤±è´¥")
    return recognizer

if __name__ == "__main__":
    # ç¤ºä¾‹ç”¨æ³•
    print("ğŸ¯ FunASR + Silero VAD è¯­éŸ³è¯†åˆ«æ¨¡å—æµ‹è¯•")
    print("=" * 50)

    # åˆ›å»ºè¯†åˆ«å™¨
    recognizer = FunASRVoiceRecognizer()

    # æ˜¾ç¤ºçŠ¶æ€
    status = recognizer.get_status()
    print(f"ğŸ“Š è¯†åˆ«å™¨çŠ¶æ€: {status}")

    if recognizer.initialize():
        print("âœ… è¯†åˆ«å™¨åˆå§‹åŒ–æˆåŠŸ")
        print("ğŸ¤ Silero VADé›†æˆå®Œæˆï¼Œå¯ä»¥è¿›è¡Œè¯­éŸ³è¯†åˆ«æµ‹è¯•")
    else:
        print("âŒ è¯†åˆ«å™¨åˆå§‹åŒ–å¤±è´¥")