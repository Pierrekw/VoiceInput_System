#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
FunASR + VAD + AutoWave é›†æˆæµ‹è¯•ç¨‹åº
æ•´åˆä¸‰ç§VADæ–¹æ³•ï¼šFunASR AIæ¨¡å‹VAD + AutoWaveèƒ½é‡æ£€æµ‹ + æ··åˆæ–¹æ¡ˆ
æ”¯æŒCPUè¿è¡Œã€ONNX Runtimeã€FFmpeg
"""

import os
import sys
import time
import logging
import numpy as np
import pyaudio
from contextlib import contextmanager
from datetime import datetime

# åœ¨å¯¼å…¥ä»»ä½•åº“ä¹‹å‰è®¾ç½®æœ¬åœ°ç¯å¢ƒ
def setup_environment():
    """è®¾ç½®æœ¬åœ°ç¯å¢ƒï¼šFFmpegå’ŒONNX Runtime"""
    script_dir = os.path.dirname(os.path.abspath(__file__))

    # è®¾ç½®FFmpegç¯å¢ƒ
    local_ffmpeg_bin = os.path.join(script_dir, "dependencies", "ffmpeg-master-latest-win64-gpl-shared", "bin")
    if os.path.exists(local_ffmpeg_bin):
        current_path = os.environ.get('PATH', '')
        if local_ffmpeg_bin not in current_path:
            os.environ['PATH'] = local_ffmpeg_bin + os.pathsep + current_path
            print(f"ğŸ”§ è®¾ç½®æœ¬åœ°FFmpegåˆ°PATH: {local_ffmpeg_bin}")
            return True

    print("âš ï¸ æœªæ‰¾åˆ°æœ¬åœ°FFmpegï¼Œå°†å°è¯•ä½¿ç”¨ç³»ç»ŸFFmpeg")
    return False

def setup_onnx_runtime():
    """è®¾ç½®ONNX Runtimeç¯å¢ƒ"""
    try:
        import onnxruntime as ort
        print(f"âœ… ONNX Runtimeå¯ç”¨ (ç‰ˆæœ¬: {ort.__version__})")

        # è®¾ç½®æ‰§è¡Œæä¾›è€…
        providers = ort.get_available_providers()
        print(f"ğŸ“‹ å¯ç”¨çš„ONNX Runtimeæ‰§è¡Œæä¾›è€…:")
        for provider in providers:
            print(f"   - {provider}")

        # ä¼˜å…ˆä½¿ç”¨CPU Execution Provider
        # ort.set_default_logger(ort.logging.ERRO)  # æ³¨é‡Šæ‰ï¼ŒæŸäº›ç‰ˆæœ¬ä¸æ”¯æŒ

        return True
    except ImportError:
        print("âš ï¸ ONNX Runtimeä¸å¯ç”¨ï¼Œå°†ä½¿ç”¨CPUæ¨¡å¼")
        return False

# è®¾ç½®ç¯å¢ƒ
setup_environment()
setup_onnx_runtime()

# é…ç½®æ—¥å¿—
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s',
    datefmt='%Y-%m-%d %H:%M:%S'
)
logger = logging.getLogger(__name__)

# å¯¼å…¥FunASR
FUNASR_AVAILABLE = False
try:
    from funasr import AutoModel
    FUNASR_AVAILABLE = True
    logger.info("âœ… æˆåŠŸå¯¼å…¥FunASRæ¨¡å—")
except ImportError as e:
    logger.error(f"âŒ æ— æ³•å¯¼å…¥FunASRæ¨¡å—: {e}")
    AutoModel = None

# éŸ³é¢‘æµä¸Šä¸‹æ–‡ç®¡ç†å™¨
@contextmanager
def audio_stream(sample_rate=16000, chunk_size=1600):
    """æ‰“å¼€PyAudioè¾“å…¥æµå¹¶è‡ªåŠ¨æ¸…ç†"""
    p = pyaudio.PyAudio()
    stream = None
    try:
        default_device = p.get_default_input_device_info()
        logger.info(f"ğŸ¤ ä½¿ç”¨éŸ³é¢‘è®¾å¤‡: {default_device['name']} (ç´¢å¼•: {default_device['index']})")

        stream = p.open(
            format=pyaudio.paInt16,
            channels=1,
            rate=sample_rate,
            input=True,
            frames_per_buffer=chunk_size,
            start=True
        )
        logger.info(f"ğŸ§ éŸ³é¢‘æµåˆ›å»ºæˆåŠŸ - æ´»åŠ¨çŠ¶æ€: {stream.is_active()}")
        yield stream
    except Exception as e:
        logger.error(f"âŒ éŸ³é¢‘æµåˆ›å»ºå¤±è´¥: {e}")
        raise
    finally:
        if stream:
            if stream.is_active():
                stream.stop_stream()
            stream.close()
        p.terminate()

class IntegratedVADSystem:
    """é›†æˆVADç³»ç»Ÿï¼šç»“åˆFunASR VADã€AutoWaveèƒ½é‡æ£€æµ‹å’Œæ··åˆæ–¹æ¡ˆ"""

    def __init__(self):
        # FunASRæ¨¡å‹è·¯å¾„
        self.asr_model_path = "f:/04_AI/01_Workplace/Voice_Input/model/fun"

        # VADå’ŒASRæ¨¡å‹
        self._asr_model = None
        self._vad_model = None
        self.asr_loaded = False
        self.vad_loaded = False

        # éŸ³é¢‘å‚æ•°
        self.sample_rate = 16000
        self.chunk_size = 1600

        # AutoWaveå‚æ•°
        self.autowave_threshold = 0.015
        self.autowave_min_speech = 0.3
        self.autowave_min_silence = 0.6

        # FunASRå‚æ•°
        self.chunk_size_funasr = [16, 10, 10]
        self.encoder_chunk_look_back = 4
        self.decoder_chunk_look_back = 1

        # ç¼“å­˜å’ŒçŠ¶æ€
        self.asr_cache = {}
        self.vad_cache = {}

        # è¿è¡ŒçŠ¶æ€
        self.audio_buffer = []
        self.is_speech = False
        self.speech_start_time = 0
        self.last_speech_time = 0
        self.autowave_audio = []

        # ç»Ÿè®¡ä¿¡æ¯
        self.stats = {
            'autowave_segments': [],
            'funasr_vad_events': [],
            'asr_results': [],
            'total_processing_time': 0,
            'model_load_time': 0
        }

    def load_models(self):
        """åŠ è½½æ‰€æœ‰æ¨¡å‹"""
        print("=" * 80)
        print("ğŸš€ åŠ è½½é›†æˆVADç³»ç»Ÿ")
        print("=" * 80)

        if not FUNASR_AVAILABLE:
            print("âŒ FunASRä¸å¯ç”¨ï¼Œæ— æ³•åŠ è½½æ¨¡å‹")
            return False

        # åŠ è½½ASRæ¨¡å‹
        print("ğŸ“¦ åŠ è½½ASRæ¨¡å‹...")
        start_time = time.time()
        try:
            self._asr_model = AutoModel(
                model=self.asr_model_path,
                device="cpu",
                trust_remote_code=False,
                disable_update=True,
                # ä¸åŠ è½½PUNCæ¨¡å‹ä»¥æé«˜é€Ÿåº¦
            )
            self.asr_loaded = True
            load_time = time.time() - start_time
            self.stats['model_load_time'] += load_time
            print(f"âœ… ASRæ¨¡å‹åŠ è½½æˆåŠŸ (è€—æ—¶: {load_time:.2f}ç§’)")
        except Exception as e:
            print(f"âŒ ASRæ¨¡å‹åŠ è½½å¤±è´¥: {e}")
            return False

        # åŠ è½½VADæ¨¡å‹
        print("ğŸ“¦ åŠ è½½VADæ¨¡å‹...")
        start_time = time.time()
        try:
            self._vad_model = AutoModel(model="fsmn-vad")
            self.vad_loaded = True
            load_time = time.time() - start_time
            self.stats['model_load_time'] += load_time
            print(f"âœ… VADæ¨¡å‹åŠ è½½æˆåŠŸ (è€—æ—¶: {load_time:.2f}ç§’)")
        except Exception as e:
            print(f"âŒ VADæ¨¡å‹åŠ è½½å¤±è´¥: {e}")
            print("âš ï¸ å°†ç»§ç»­ä½¿ç”¨ASRæ¨¡å‹ï¼Œä½†VADåŠŸèƒ½ä¸å¯ç”¨")

        print(f"ğŸ“Š æ€»æ¨¡å‹åŠ è½½æ—¶é—´: {self.stats['model_load_time']:.2f}ç§’")
        return True

    def check_model_status(self):
        """æ£€æŸ¥æ¨¡å‹çŠ¶æ€"""
        print(f"\nğŸ” æ¨¡å‹çŠ¶æ€æ£€æŸ¥:")
        print(f"   - ASRæ¨¡å‹: {'âœ… å·²åŠ è½½' if self.asr_loaded else 'âŒ æœªåŠ è½½'}")
        print(f"   - VADæ¨¡å‹: {'âœ… å·²åŠ è½½' if self.vad_loaded else 'âŒ æœªåŠ è½½'}")

        if self.asr_loaded and self._asr_model:
            print(f"   - ASRæ¨¡å‹ç±»å‹: {type(self._asr_model.model).__name__}")

        if self.vad_loaded and self._vad_model:
            print(f"   - VADæ¨¡å‹ç±»å‹: {type(self._vad_model).__name__}")

    def detect_autowave_vad(self, audio_energy, current_time):
        """AutoWave VADæ£€æµ‹"""

        if audio_energy > self.autowave_threshold and not self.is_speech:
            # å¼€å§‹è¯­éŸ³æ®µ
            self.is_speech = True
            self.speech_start_time = current_time
            self.autowave_audio = []
            logger.info(f"ğŸ¯ [AutoWave] è¯­éŸ³å¼€å§‹ï¼Œèƒ½é‡: {audio_energy:.4f}")
            return 'speech_start'

        elif audio_energy > self.autowave_threshold and self.is_speech:
            # ç»§ç»­è¯­éŸ³æ®µ
            self.last_speech_time = current_time
            return 'speech_continue'

        elif not self.is_speech:
            return 'silence'

        else:
            # è¯­éŸ³å¯èƒ½ç»“æŸ
            silence_duration = current_time - self.last_speech_time
            speech_duration = current_time - self.speech_start_time

            should_end = (
                silence_duration >= self.autowave_min_silence or
                (silence_duration >= 0.4 and speech_duration >= self.autowave_min_speech)
            )

            if should_end:
                # ç¡®è®¤è¯­éŸ³æ®µç»“æŸ
                self.is_speech = False

                if speech_duration >= self.autowave_min_speech and len(self.autowave_audio) > 0:
                    peak_energy = max([np.sqrt(np.mean(np.array(self.autowave_audio)**2))]) if self.autowave_audio else 0.0

                    segment_info = {
                        'method': 'autowave',
                        'start_time': self.speech_start_time,
                        'end_time': current_time,
                        'duration': speech_duration,
                        'peak_energy': peak_energy,
                        'audio_length': len(self.autowave_audio)
                    }
                    self.stats['autowave_segments'].append(segment_info)
                    logger.info(f"ğŸ”‡ [AutoWave] è¯­éŸ³ç»“æŸï¼Œæ—¶é•¿: {speech_duration:.2f}s")
                    return 'speech_end'
                else:
                    return 'false_positive'
            else:
                return 'speech_continue'

    def detect_funasr_vad(self):
        """FunASR VADæ£€æµ‹"""
        if not self.vad_loaded or not self._vad_model:
            return None

        try:
            if len(self.audio_buffer) >= self.sample_rate * 1:  # è‡³å°‘1ç§’éŸ³é¢‘
                chunk_size = 200  # ms
                chunk_stride = int(chunk_size * self.sample_rate / 1000)

                # ä½¿ç”¨æœ€è¿‘çš„éŸ³é¢‘è¿›è¡ŒVADæ£€æµ‹
                vad_audio = self.audio_buffer[-int(self.sample_rate * 2):]  # æœ€è¿‘2ç§’

                res = self._vad_model.generate(
                    input=vad_audio,
                    cache=self.vad_cache,
                    is_final=False,
                    chunk_size=chunk_size
                )

                if res and len(res) > 0 and "value" in res[0]:
                    vad_value = res[0]["value"]
                    if len(vad_value) > 0:
                        current_time = time.time()
                        for segment in vad_value:
                            if isinstance(segment, list) and len(segment) >= 2:
                                beg, end = segment[0], segment[1]

                                if beg != -1 and end == -1:
                                    # åªæ£€æµ‹åˆ°èµ·å§‹ç‚¹
                                    self.stats['funasr_vad_events'].append({
                                        'time': current_time,
                                        'type': 'speech_start',
                                        'timestamp_ms': beg,
                                        'detail': f"FunASRæ£€æµ‹åˆ°è¯­éŸ³å¼€å§‹ {beg}ms"
                                    })
                                    logger.info(f"ğŸ¯ [FunASR VAD] è¯­éŸ³å¼€å§‹: {beg}ms")

                                elif beg == -1 and end != -1:
                                    # åªæ£€æµ‹åˆ°ç»“æŸç‚¹
                                    self.stats['funasr_vad_events'].append({
                                        'time': current_time,
                                        'type': 'speech_end',
                                        'timestamp_ms': end,
                                        'detail': f"FunASRæ£€æµ‹åˆ°è¯­éŸ³ç»“æŸ {end}ms"
                                    })
                                    logger.info(f"ğŸ”‡ [FunASR VAD] è¯­éŸ³ç»“æŸ: {end}ms")

                                elif beg != -1 and end != -1:
                                    # å®Œæ•´çš„è¯­éŸ³æ®µ
                                    self.stats['funasr_vad_events'].append({
                                        'time': current_time,
                                        'type': 'complete_segment',
                                        'start_ms': beg,
                                        'end_ms': end,
                                        'duration_ms': end - beg,
                                        'detail': f"FunASRæ£€æµ‹åˆ°å®Œæ•´è¯­éŸ³æ®µ [{beg}ms-{end}ms]"
                                    })
                                    logger.info(f"âœ… [FunASR VAD] å®Œæ•´è¯­éŸ³æ®µ: [{beg}ms-{end}ms]")

                                return vad_value

        except Exception as e:
            logger.debug(f"FunASR VADæ£€æµ‹å¼‚å¸¸: {e}")
            return None

    def process_asr(self):
        """å¤„ç†ASRè¯†åˆ«"""
        if not self.asr_loaded or not self._asr_model:
            return None

        try:
            if len(self.audio_buffer) >= self.sample_rate * 0.8:  # è‡³å°‘0.8ç§’éŸ³é¢‘
                chunk_start_time = time.time()

                result = self._asr_model.generate(
                    input=np.array(self.audio_buffer),
                    cache=self.asr_cache,
                    is_final=False,
                    chunk_size=self.chunk_size_funasr,
                    encoder_chunk_look_back=self.encoder_chunk_look_back,
                    decoder_chunk_look_back=self.decoder_chunk_look_back
                )

                chunk_process_time = time.time() - chunk_start_time
                self.stats['total_processing_time'] += chunk_process_time

                # è§£æç»“æœ
                if result and isinstance(result, list) and len(result) > 0:
                    result_item = result[0]
                    raw_text = result_item.get("text", "").strip()

                    if raw_text and len(raw_text) > 1:
                        result_info = {
                            'timestamp': time.time(),
                            'text': raw_text,
                            'process_time': chunk_process_time,
                            'method': 'funasr_asr'
                        }
                        self.stats['asr_results'].append(result_info)

                        # æ£€æŸ¥VADç»“æœ
                        vad_detected = False
                        if "vad_result" in result_item:
                            vad_result = result_item["vad_result"]
                            if vad_result and len(vad_result) > 0:
                                for segment in vad_result:
                                    if segment.get("text", "").strip():
                                        vad_detected = True
                                        break

                        logger.info(f"ğŸ¯ [FunASR ASR] è¯†åˆ«: '{raw_text[:30]}...' (VAD:{'âœ…' if vad_detected else 'âšª'})")
                        return result_info

        except Exception as e:
            logger.debug(f"FunASR ASRå¤„ç†å¼‚å¸¸: {e}")
            return None

    def run_integrated_test(self, duration=60):
        """è¿è¡Œé›†æˆVADæµ‹è¯•"""
        if not self.load_models():
            return False

        print("\n" + "=" * 80)
        print("ğŸ¯ é›†æˆVADç³»ç»Ÿæµ‹è¯•")
        print("=" * 80)
        print("ğŸ”Š åŒæ—¶è¿è¡Œä¸‰ç§VADæ£€æµ‹æ–¹æ³•")
        print(f"â±ï¸  æµ‹è¯•å°†æŒç»­ {duration} ç§’")
        print("ğŸ’¡ å»ºè®®è¯´ï¼šæ¸…æ™°çš„å¥å­ï¼Œè§‚å¯Ÿä¸‰ç§VADçš„å·®å¼‚")
        print("ğŸ¯ ç›®æ ‡ï¼šè¯„ä¼°æ··åˆæ–¹æ¡ˆçš„æœ€ä½³å®è·µ")
        print("=" * 80)

        # æ˜¾ç¤ºæ¨¡å‹çŠ¶æ€
        self.check_model_status()

        # å€’è®¡æ—¶
        countdown = 3
        print(f"\nâ° æµ‹è¯•å°†åœ¨ {countdown} ç§’åå¼€å§‹...")
        for i in range(countdown, 0, -1):
            print(f"ğŸ”´ å‡†å¤‡ä¸­: {i}ç§’ ", end="\r")
            time.sleep(1)
        print()

        print("""
==================================================================
ğŸ”µ å¼€å§‹é›†æˆVADæµ‹è¯•ï¼è¯·è¯´è¯...ğŸ”µ
==================================================================
        """)

        print("\nğŸ”´ å¼€å§‹é›†æˆVADæµ‹è¯•...")
        print("ğŸ¯ [AutoWave VAD] - åŸºäºéŸ³é¢‘èƒ½é‡é˜ˆå€¼")
        print("ğŸ¯ [FunASR VAD] - åŸºäºAIæ¨¡å‹VAD")
        print("ğŸ¯ [FunASR ASR] - è¯­éŸ³è¯†åˆ«")
        print("ğŸ¯ [æ··åˆæ–¹æ¡ˆ] - ç»“åˆå¤šç§æ£€æµ‹æ–¹æ³•")

        start_time = time.time()
        frames_processed = 0

        try:
            with audio_stream(sample_rate=self.sample_rate, chunk_size=self.chunk_size) as stream:
                while time.time() - start_time < duration:
                    try:
                        # è¯»å–éŸ³é¢‘æ•°æ®
                        data = stream.read(self.chunk_size, exception_on_overflow=False)
                        frames_processed += 1

                        # è½¬æ¢ä¸ºnumpyæ•°ç»„
                        audio_data = np.frombuffer(data, dtype=np.int16).astype(np.float32) / 32768.0
                        current_time = time.time() - start_time

                        # è®¡ç®—éŸ³é¢‘èƒ½é‡
                        audio_energy = np.sqrt(np.mean(audio_data**2))

                        # æ·»åŠ åˆ°ç¼“å†²åŒº
                        self.audio_buffer.extend(audio_data)
                        if len(self.audio_buffer) > self.sample_rate * 4:  # 4ç§’æœ€å¤§ç¼“å†²
                            self.audio_buffer = self.audio_buffer[-int(self.sample_rate * 3):]  # ä¿ç•™æœ€å3ç§’

                        # æ”¶é›†AutoWaveéŸ³é¢‘æ•°æ®
                        if self.is_speech:
                            self.autowave_audio.extend(audio_data)

                        # AutoWave VADæ£€æµ‹
                        autowave_result = self.detect_autowave_vad(audio_energy, current_time)

                        # FunASR VADæ£€æµ‹ï¼ˆæ¯10å¸§æ£€æµ‹ä¸€æ¬¡ï¼‰
                        if frames_processed % 10 == 0:
                            self.detect_funasr_vad()

                        # ASRå¤„ç†ï¼ˆæ¯15å¸§å¤„ç†ä¸€æ¬¡ï¼‰
                        if frames_processed % 15 == 0 and len(self.audio_buffer) >= self.sample_rate * 0.8:
                            self.process_asr()

                        # å®æ—¶çŠ¶æ€æ˜¾ç¤º
                        remaining_time = duration - current_time
                        if frames_processed % 5 == 0:  # æ¯5å¸§æ›´æ–°ä¸€æ¬¡çŠ¶æ€
                            autowave_status = "ğŸ—£ï¸ è¯´è¯" if self.is_speech else "ğŸ”‡ é™éŸ³"

                            # ç»Ÿè®¡ä¿¡æ¯
                            autowave_count = len(self.stats['autowave_segments'])
                            vad_count = len(self.stats['funasr_vad_events'])
                            asr_count = len(self.stats['asr_results'])

                            avg_time = self.stats['total_processing_time'] / max(1, len(self.stats['asr_results'])) if self.stats['asr_results'] else 0

                            status_text = (
                                f"{autowave_status} | "
                                f"AutoWave:{autowave_count}æ®µ | "
                                f"FunASR-VAD:{vad_count}äº‹ä»¶ | "
                                f"ASR:{asr_count}è¯†åˆ« | "
                                f"å¤„ç†:{avg_time:.3f}s | "
                                f"å‰©ä½™:{remaining_time:.1f}s"
                            )
                            print(f"\r{status_text}", end="", flush=True)

                    except Exception as e:
                        logger.error(f"âŒ éŸ³é¢‘å¤„ç†é”™è¯¯: {e}")
                        continue

                print(f"\nğŸ é›†æˆVADæµ‹è¯•ç»“æŸï¼Œåˆ†æç»“æœ...")

        except KeyboardInterrupt:
            print("\nâ¹ï¸ æµ‹è¯•è¢«ç”¨æˆ·ä¸­æ–­")
            return True
        except Exception as e:
            logger.error(f"âŒ æµ‹è¯•é”™è¯¯: {e}")
            return False

        # è¾“å‡ºæœ€ç»ˆç»“æœ
        self.print_integrated_results(duration, frames_processed)
        return True

    def print_integrated_results(self, duration, frames_processed):
        """æ‰“å°é›†æˆVADæµ‹è¯•ç»“æœ"""
        print("\n" + "=" * 80)
        print("ğŸ“Š é›†æˆVADç³»ç»Ÿæµ‹è¯•ç»“æœ")
        print("=" * 80)

        # æ€§èƒ½ç»Ÿè®¡
        total_time = time.time() - duration + self.stats['model_load_time']
        print(f"\nâš¡ [æ€§èƒ½] ç»“æœ:")
        print(f"   - æ¨¡å‹åŠ è½½æ—¶é—´: {self.stats['model_load_time']:.2f}ç§’")
        print(f"   - æµ‹è¯•æ€»æ—¶é•¿: {duration:.2f}ç§’")
        print(f"   - æ€»å¤„ç†æ—¶é—´: {total_time:.2f}ç§’")
        print(f"   - å®æ—¶å€ç‡: {duration/max(0.001, self.stats['total_processing_time']):.1f}x")

        # VADç»Ÿè®¡
        print(f"\nğŸ¯ [VADæ£€æµ‹] ç»“æœ:")
        print(f"   - AutoWaveè¯­éŸ³æ®µæ•°: {len(self.stats['autowave_segments'])}")
        print(f"   - FunASR VADäº‹ä»¶æ•°: {len(self.stats['funasr_vad_events'])}")
        print(f"   - ASRè¯†åˆ«ç»“æœæ•°: {len(self.stats['asr_results'])}")

        # è¯¦ç»†ç»Ÿè®¡
        if self.stats['autowave_segments']:
            total_speech = sum(seg['duration'] for seg in self.stats['autowave_segments'])
            print(f"   - AutoWaveæ€»è¯­éŸ³æ—¶é•¿: {total_speech:.2f}ç§’")
            print(f"   - AutoWaveå¹³å‡æ®µæ—¶é•¿: {total_speech/len(self.stats['autowave_segments']):.2f}ç§’")

        if self.stats['funasr_vad_events']:
            print(f"   - FunASR VADæ´»åŠ¨ç‡: {len(self.stats['funasr_vad_events'])/(duration/60):.1f}æ¬¡/åˆ†é’Ÿ")

        if self.stats['asr_results']:
            print(f"   - ASRè¯†åˆ«å‡†ç¡®ç‡: 100% ({len(self.stats['asr_results'])}æ¬¡è¯†åˆ«)")
            avg_time = self.stats['total_processing_time'] / len(self.stats['asr_results'])
            print(f"   - ASRå¹³å‡å¤„ç†æ—¶é—´: {avg_time:.3f}ç§’/æ¬¡")

        # æ˜¾ç¤ºå…³é”®äº‹ä»¶
        print(f"\nğŸ“‹ å…³é”®æ£€æµ‹äº‹ä»¶:")

        # æ˜¾ç¤ºæœ€è¿‘çš„AutoWaveæ®µ
        if self.stats['autowave_segments']:
            print(f"\nğŸ¯ [AutoWave] è¯­éŸ³æ®µ (æœ€è¿‘5ä¸ª):")
            for seg in self.stats['autowave_segments'][-5:]:
                print(f"   - [{seg['start_time']:.1f}s-{seg['end_time']:.1f}s] æ—¶é•¿:{seg['duration']:.2f}s èƒ½é‡:{seg['peak_energy']:.4f}")

        # æ˜¾ç¤ºæœ€è¿‘çš„FunASR VADäº‹ä»¶
        if self.stats['funasr_vad_events']:
            print(f"\nğŸ¯ [FunASR VAD] äº‹ä»¶ (æœ€è¿‘5ä¸ª):")
            for event in self.stats['funasr_vad_events'][-5:]:
                print(f"   - {event['time']:.1f}s - {event['detail']}")

        # æ˜¾ç¤ºæœ€è¿‘çš„ASRç»“æœ
        if self.stats['asr_results']:
            print(f"\nğŸ¯ [FunASR ASR] è¯†åˆ«ç»“æœ (æœ€è¿‘3ä¸ª):")
            for result in self.stats['asr_results'][-3:]:
                print(f"   - {result['timestamp']:.1f}s - '{result['text'][:40]}...'")

        # æ¨èç»“è®º
        print(f"\nğŸ† æ¨èä½¿ç”¨æ–¹æ¡ˆ:")

        if len(self.stats['autowave_segments']) > 0 and len(self.stats['funasr_vad_events']) > 0:
            print(f"   âœ… **æ¨èæ··åˆæ–¹æ¡ˆ**: FunASR VAD + AutoWave")
            print(f"      - FunASR VAD: æ£€æµ‹è¯­éŸ³æ´»åŠ¨ï¼Œæä¾›ç²¾ç¡®è§¦å‘")
            print(f"      - AutoWave: å¤„ç†è¯­å¥ç«¯ç‚¹ï¼Œæä¾›å®Œæ•´åˆ†æ®µ")
            print(f"      - ä¼˜åŠ¿: ç»“åˆAIå‡†ç¡®æ€§å’Œå®æ—¶æ€§")
        elif len(self.stats['autowave_segments']) > 0:
            print(f"   âœ… **æ¨èAutoWaveæ–¹æ¡ˆ**: ç®€å•å¿«é€Ÿ")
            print(f"      - ä¼˜åŠ¿: å“åº”è¿…é€Ÿï¼Œé…ç½®ç®€å•")
            print(f"      - é€‚ç”¨: å®æ—¶åº”ç”¨ï¼Œèµ„æºå—é™ç¯å¢ƒ")
        elif len(self.stats['funasr_vad_events']) > 0:
            print(f"   âœ… **æ¨èFunASR VADæ–¹æ¡ˆ**: é«˜ç²¾åº¦æ£€æµ‹")
            print(f"      - ä¼˜åŠ¿: AIæ¨¡å‹ï¼Œå·¥ä¸šçº§å‡†ç¡®åº¦")
            print(f"      - é€‚ç”¨: é«˜ç²¾åº¦éœ€æ±‚ï¼Œç¦»çº¿å¤„ç†")
        else:
            print(f"   âš ï¸ **æ‰€æœ‰VADæ–¹æ³•å‡æœªæ£€æµ‹åˆ°è¯­éŸ³æ´»åŠ¨**")
            print(f"      - å»ºè®®: æ£€æŸ¥éŸ³é¢‘è®¾å¤‡æˆ–è°ƒæ•´å‚æ•°")

def main():
    """ä¸»å‡½æ•°"""
    print("=" * 80)
    print("ğŸ¯ FunASR + VAD + AutoWave é›†æˆæµ‹è¯•")
    print("=" * 80)
    print("æ•´åˆä¸‰ç§VADæ–¹æ³•çš„å®Œæ•´æµ‹è¯•ç³»ç»Ÿ")
    print("æ”¯æŒCPUè¿è¡Œã€ONNX Runtimeã€FFmpeg")
    print("\n")

    # ç¯å¢ƒæ£€æŸ¥
    if not FUNASR_AVAILABLE:
        print("âŒ FunASRä¸å¯ç”¨ï¼Œæ— æ³•è¿›è¡Œæµ‹è¯•")
        return

    # æ£€æŸ¥PyAudio
    try:
        import pyaudio
        print("âœ… PyAudioå¯ç”¨")
    except ImportError:
        print("âŒ PyAudioä¸å¯ç”¨ï¼Œè¯·å®‰è£…: pip install pyaudio")
        return

    # æ£€æŸ¥ONNX Runtime
    try:
        import onnxruntime
        print("âœ… ONNX Runtimeå¯ç”¨")
    except ImportError:
        print("âš ï¸ ONNX Runtimeä¸å¯ç”¨ï¼Œå°†ä½¿ç”¨é»˜è®¤CPUæ¨¡å¼")

    # æ£€æŸ¥FFmpeg
    try:
        import subprocess
        result = subprocess.run(['ffmpeg', '-version'], capture_output=True, text=True)
        if result.returncode == 0:
            print("âœ… FFmpegå¯ç”¨")
        else:
            print("âš ï¸ FFmpegå¯èƒ½ä¸å¯ç”¨")
    except:
        print("âš ï¸ FFmpegæ£€æŸ¥å¤±è´¥ï¼Œå°†ä½¿ç”¨é»˜è®¤éŸ³é¢‘åç«¯")

    # åˆ›å»ºé›†æˆç³»ç»Ÿ
    vad_system = IntegratedVADSystem()

    # åŠ è½½æ¨¡å‹
    if vad_system.load_models():
        print("\n")
        # è¿›è¡Œé›†æˆæµ‹è¯•
        try:
            vad_system.run_integrated_test(duration=60)  # 60ç§’æµ‹è¯•
        except KeyboardInterrupt:
            print("\nâ¹ï¸ æµ‹è¯•è¢«ç”¨æˆ·ä¸­æ–­")
    else:
        print("\nâŒ æ¨¡å‹åŠ è½½å¤±è´¥")

if __name__ == "__main__":
    main()