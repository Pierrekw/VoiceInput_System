# -*- coding: utf-8 -*-
"""
æ€§èƒ½å¯¹æ¯”æµ‹è¯•å¥—ä»¶

å¯¹æ¯”åŸå§‹åŒæ­¥ç³»ç»Ÿå’Œæ–°å¼‚æ­¥ç³»ç»Ÿçš„æ€§èƒ½æŒ‡æ ‡ã€‚
"""

import sys
import os
import time
import asyncio
import statistics
import threading
import psutil
import gc
from typing import Dict, List, Any, Optional
from datetime import datetime
import json

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°Pythonè·¯å¾„
current_dir = os.path.dirname(os.path.abspath(__file__))
project_root = os.path.abspath(os.path.join(current_dir, '..'))
if project_root not in sys.path:
    sys.path.insert(0, project_root)


class PerformanceMetrics:
    """æ€§èƒ½æŒ‡æ ‡æ”¶é›†å™¨"""

    def __init__(self):
        self.reset()

    def reset(self):
        """é‡ç½®æ‰€æœ‰æŒ‡æ ‡"""
        self.start_time = None
        self.end_time = None
        self.memory_usage = []
        self.cpu_usage = []
        self.response_times = []
        self.throughput_samples = []
        self.error_count = 0
        self.success_count = 0

    def start_monitoring(self):
        """å¼€å§‹æ€§èƒ½ç›‘æ§"""
        self.start_time = time.time()
        self.reset()

        # å¯åŠ¨èµ„æºç›‘æ§çº¿ç¨‹
        self.monitoring = True
        self.monitor_thread = threading.Thread(target=self._monitor_resources)
        self.monitor_thread.daemon = True
        self.monitor_thread.start()

    def stop_monitoring(self):
        """åœæ­¢æ€§èƒ½ç›‘æ§"""
        self.end_time = time.time()
        self.monitoring = False
        if hasattr(self, 'monitor_thread'):
            self.monitor_thread.join(timeout=1)

    def _monitor_resources(self):
        """ç›‘æ§ç³»ç»Ÿèµ„æºä½¿ç”¨"""
        process = psutil.Process()

        while self.monitoring:
            try:
                # å†…å­˜ä½¿ç”¨ç‡
                memory_percent = process.memory_percent()
                self.memory_usage.append(memory_percent)

                # CPUä½¿ç”¨ç‡
                cpu_percent = process.cpu_percent()
                self.cpu_usage.append(cpu_percent)

                time.sleep(0.1)  # æ¯100msé‡‡æ ·ä¸€æ¬¡
            except Exception:
                break

    def record_response_time(self, response_time: float):
        """è®°å½•å“åº”æ—¶é—´"""
        self.response_times.append(response_time)

    def record_success(self):
        """è®°å½•æˆåŠŸæ“ä½œ"""
        self.success_count += 1

    def record_error(self):
        """è®°å½•é”™è¯¯æ“ä½œ"""
        self.error_count += 1

    def record_throughput(self, operations_per_second: float):
        """è®°å½•ååé‡"""
        self.throughput_samples.append(operations_per_second)

    def get_summary(self) -> Dict[str, Any]:
        """è·å–æ€§èƒ½æ‘˜è¦"""
        duration = self.end_time - self.start_time if self.end_time and self.start_time else 0

        return {
            'duration': duration,
            'total_operations': self.success_count + self.error_count,
            'success_rate': self.success_count / max(1, self.success_count + self.error_count),
            'avg_response_time': statistics.mean(self.response_times) if self.response_times else 0,
            'median_response_time': statistics.median(self.response_times) if self.response_times else 0,
            'p95_response_time': self._percentile(self.response_times, 95) if self.response_times else 0,
            'p99_response_time': self._percentile(self.response_times, 99) if self.response_times else 0,
            'avg_memory_usage': statistics.mean(self.memory_usage) if self.memory_usage else 0,
            'max_memory_usage': max(self.memory_usage) if self.memory_usage else 0,
            'avg_cpu_usage': statistics.mean(self.cpu_usage) if self.cpu_usage else 0,
            'max_cpu_usage': max(self.cpu_usage) if self.cpu_usage else 0,
            'avg_throughput': statistics.mean(self.throughput_samples) if self.throughput_samples else 0,
            'peak_throughput': max(self.throughput_samples) if self.throughput_samples else 0,
            'error_rate': self.error_count / max(1, self.success_count + self.error_count)
        }

    def _percentile(self, data: List[float], percentile: int) -> float:
        """è®¡ç®—ç™¾åˆ†ä½æ•°"""
        if not data:
            return 0
        sorted_data = sorted(data)
        index = int(len(sorted_data) * percentile / 100)
        return sorted_data[min(index, len(sorted_data) - 1)]


class SyncSystemTest:
    """åŸå§‹åŒæ­¥ç³»ç»Ÿæµ‹è¯•"""

    def __init__(self):
        self.metrics = PerformanceMetrics()

    def setup(self):
        """è®¾ç½®æµ‹è¯•ç¯å¢ƒ"""
        try:
            from audio_capture_v import AudioCapture
            from excel_exporter import ExcelExporter
            from main import VoiceInputSystem

            self.audio_capture = AudioCapture()
            self.excel_exporter = ExcelExporter()
            self.voice_system = VoiceInputSystem()

            return True
        except Exception as e:
            print(f"åŒæ­¥ç³»ç»Ÿè®¾ç½®å¤±è´¥: {e}")
            return False

    def test_audio_processing_performance(self, duration: float = 10.0) -> Dict[str, Any]:
        """æµ‹è¯•éŸ³é¢‘å¤„ç†æ€§èƒ½"""
        print(f"æµ‹è¯•åŒæ­¥ç³»ç»ŸéŸ³é¢‘å¤„ç†æ€§èƒ½ ({duration}ç§’)...")

        self.metrics.start_monitoring()
        start_time = time.time()

        try:
            # æ¨¡æ‹ŸéŸ³é¢‘æ•°æ®å¤„ç†
            test_texts = [
                "æ¸©åº¦äºŒåäº”ç‚¹äº”åº¦",
                "å‹åŠ›ä¸€ç™¾äºŒååƒå¸•",
                "æµé‡ä¸‰ç‚¹ä¸€å››ç«‹æ–¹ç±³æ¯å°æ—¶",
                "æ·±åº¦é›¶ç‚¹å…«ç±³",
                "é‡é‡ä¸¤åƒå…‹",
                "é€Ÿåº¦ä¸‰åå…¬é‡Œæ¯å°æ—¶"
            ]

            operation_count = 0
            while time.time() - start_time < duration:
                for text in test_texts:
                    op_start = time.time()

                    try:
                        # æ¨¡æ‹ŸéŸ³é¢‘å¤„ç†æµç¨‹
                        result = self.audio_capture.filtered_callback(text)

                        op_end = time.time()
                        self.metrics.record_response_time(op_end - op_start)
                        self.metrics.record_success()
                        operation_count += 1

                    except Exception as e:
                        self.metrics.record_error()
                        print(f"å¤„ç†å¤±è´¥: {e}")

                # æ¨¡æ‹Ÿå¤„ç†å»¶è¿Ÿ
                time.sleep(0.01)

            # è®¡ç®—ååé‡
            actual_duration = time.time() - start_time
            throughput = operation_count / actual_duration
            self.metrics.record_throughput(throughput)

        finally:
            self.metrics.stop_monitoring()

        return self.metrics.get_summary()

    def test_concurrent_performance(self, thread_count: int = 4, duration: float = 5.0) -> Dict[str, Any]:
        """æµ‹è¯•å¹¶å‘æ€§èƒ½"""
        print(f"æµ‹è¯•åŒæ­¥ç³»ç»Ÿå¹¶å‘æ€§èƒ½ ({thread_count}çº¿ç¨‹, {duration}ç§’)...")

        self.metrics.start_monitoring()
        start_time = time.time()

        def worker_thread():
            """å·¥ä½œçº¿ç¨‹"""
            test_texts = ["æ¸©åº¦äºŒåäº”ç‚¹äº”åº¦", "å‹åŠ›ä¸€ç™¾äºŒååƒå¸•", "æµé‡ä¸‰ç‚¹ä¸€å››"]

            while time.time() - start_time < duration:
                for text in test_texts:
                    op_start = time.time()

                    try:
                        self.audio_capture.filtered_callback(text)
                        op_end = time.time()
                        self.metrics.record_response_time(op_end - op_start)
                        self.metrics.record_success()
                    except Exception:
                        self.metrics.record_error()

                time.sleep(0.01)

        try:
            # å¯åŠ¨å¤šä¸ªçº¿ç¨‹
            threads = []
            for _ in range(thread_count):
                thread = threading.Thread(target=worker_thread)
                thread.start()
                threads.append(thread)

            # ç­‰å¾…æ‰€æœ‰çº¿ç¨‹å®Œæˆ
            for thread in threads:
                thread.join()

            # è®¡ç®—æ€»ååé‡
            actual_duration = time.time() - start_time
            total_operations = self.metrics.success_count + self.metrics.error_count
            throughput = total_operations / actual_duration
            self.metrics.record_throughput(throughput)

        finally:
            self.metrics.stop_monitoring()

        return self.metrics.get_summary()


class AsyncSystemTest:
    """æ–°å¼‚æ­¥ç³»ç»Ÿæµ‹è¯•"""

    def __init__(self):
        self.metrics = PerformanceMetrics()

    async def setup(self):
        """è®¾ç½®æµ‹è¯•ç¯å¢ƒ"""
        try:
            from events.event_bus import AsyncEventBus
            from events.event_types import AudioDataReceivedEvent
            from events.system_coordinator import SystemCoordinator

            self.event_bus = AsyncEventBus()
            await self.event_bus.start()

            self.coordinator = SystemCoordinator(self.event_bus)
            await self.coordinator.start()

            return True
        except Exception as e:
            print(f"å¼‚æ­¥ç³»ç»Ÿè®¾ç½®å¤±è´¥: {e}")
            return False

    async def cleanup(self):
        """æ¸…ç†æµ‹è¯•ç¯å¢ƒ"""
        try:
            if hasattr(self, 'coordinator'):
                await self.coordinator.stop()
            if hasattr(self, 'event_bus'):
                await self.event_bus.stop()
        except Exception:
            pass

    async def test_event_processing_performance(self, duration: float = 10.0) -> Dict[str, Any]:
        """æµ‹è¯•äº‹ä»¶å¤„ç†æ€§èƒ½"""
        print(f"æµ‹è¯•å¼‚æ­¥ç³»ç»Ÿäº‹ä»¶å¤„ç†æ€§èƒ½ ({duration}ç§’)...")

        self.metrics.start_monitoring()
        start_time = time.time()

        try:
            # åˆ›å»ºäº‹ä»¶å¤„ç†å™¨
            processed_events = []

            async def event_handler(event):
                processed_events.append(event)

            await self.event_bus.subscribe(AudioDataReceivedEvent, event_handler)

            # ç”Ÿæˆæµ‹è¯•äº‹ä»¶
            test_data = [
                b"mock_audio_data_1",
                b"mock_audio_data_2",
                b"mock_audio_data_3",
                b"mock_audio_data_4",
                b"mock_audio_data_5"
            ]

            event_count = 0
            while time.time() - start_time < duration:
                for i, data in enumerate(test_data):
                    op_start = time.time()

                    try:
                        event = AudioDataReceivedEvent(
                            source="PerformanceTest",
                            stream_id="perf_test_stream",
                            audio_data=data,
                            size=len(data),
                            sequence_number=event_count + i
                        )

                        await self.event_bus.publish(event)

                        op_end = time.time()
                        self.metrics.record_response_time(op_end - op_start)
                        self.metrics.record_success()
                        event_count += 1

                    except Exception as e:
                        self.metrics.record_error()
                        print(f"äº‹ä»¶å‘å¸ƒå¤±è´¥: {e}")

                # æ¨¡æ‹Ÿå¤„ç†å»¶è¿Ÿ
                await asyncio.sleep(0.001)

            # ç­‰å¾…äº‹ä»¶å¤„ç†å®Œæˆ
            await asyncio.sleep(0.1)

            # è®¡ç®—ååé‡
            actual_duration = time.time() - start_time
            throughput = event_count / actual_duration
            self.metrics.record_throughput(throughput)

        finally:
            self.metrics.stop_monitoring()

        return self.metrics.get_summary()

    async def test_concurrent_performance(self, concurrent_tasks: int = 10, duration: float = 5.0) -> Dict[str, Any]:
        """æµ‹è¯•å¹¶å‘æ€§èƒ½"""
        print(f"æµ‹è¯•å¼‚æ­¥ç³»ç»Ÿå¹¶å‘æ€§èƒ½ ({concurrent_tasks}ä»»åŠ¡, {duration}ç§’)...")

        self.metrics.start_monitoring()
        start_time = time.time()

        async def event_producer(task_id: int):
            """äº‹ä»¶ç”Ÿäº§è€…ä»»åŠ¡"""
            test_data = [f"task_{task_id}_data_{i}".encode() for i in range(5)]

            while time.time() - start_time < duration:
                for i, data in enumerate(test_data):
                    op_start = time.time()

                    try:
                        event = AudioDataReceivedEvent(
                            source=f"Task{task_id}",
                            stream_id=f"stream_{task_id}",
                            audio_data=data,
                            size=len(data),
                            sequence_number=i
                        )

                        await self.event_bus.publish(event)

                        op_end = time.time()
                        self.metrics.record_response_time(op_end - op_start)
                        self.metrics.record_success()

                    except Exception:
                        self.metrics.record_error()

                await asyncio.sleep(0.001)

        try:
            # å¯åŠ¨å¤šä¸ªå¹¶å‘ä»»åŠ¡
            tasks = []
            for task_id in range(concurrent_tasks):
                task = asyncio.create_task(event_producer(task_id))
                tasks.append(task)

            # ç­‰å¾…æ‰€æœ‰ä»»åŠ¡å®Œæˆ
            await asyncio.gather(*tasks)

            # è®¡ç®—æ€»ååé‡
            actual_duration = time.time() - start_time
            total_operations = self.metrics.success_count + self.metrics.error_count
            throughput = total_operations / actual_duration
            self.metrics.record_throughput(throughput)

        finally:
            self.metrics.stop_monitoring()

        return self.metrics.get_summary()


class PerformanceComparison:
    """æ€§èƒ½å¯¹æ¯”æµ‹è¯•ä¸»ç±»"""

    def __init__(self):
        self.results = {}
        self.timestamp = datetime.now().isoformat()

    async def run_full_comparison(self) -> Dict[str, Any]:
        """è¿è¡Œå®Œæ•´æ€§èƒ½å¯¹æ¯”"""
        print("=" * 60)
        print("ğŸš€ æ€§èƒ½å¯¹æ¯”æµ‹è¯•å¼€å§‹")
        print("=" * 60)

        # å¼ºåˆ¶åƒåœ¾å›æ”¶
        gc.collect()

        # æµ‹è¯•åŸå§‹åŒæ­¥ç³»ç»Ÿ
        print("\nğŸ“Š æµ‹è¯•åŸå§‹åŒæ­¥ç³»ç»Ÿ...")
        sync_test = SyncSystemTest()

        if sync_test.setup():
            sync_results = {
                'single_thread': sync_test.test_audio_processing_performance(duration=10.0),
                'multi_thread': sync_test.test_concurrent_performance(thread_count=4, duration=5.0)
            }
            self.results['sync_system'] = sync_results
        else:
            print("âŒ åŒæ­¥ç³»ç»Ÿè®¾ç½®å¤±è´¥ï¼Œè·³è¿‡æµ‹è¯•")
            self.results['sync_system'] = None

        # æ¸…ç†å†…å­˜
        del sync_test
        gc.collect()

        # æµ‹è¯•æ–°å¼‚æ­¥ç³»ç»Ÿ
        print("\nâš¡ æµ‹è¯•æ–°å¼‚æ­¥ç³»ç»Ÿ...")
        async_test = AsyncSystemTest()

        if await async_test.setup():
            async_results = {
                'single_task': await async_test.test_event_processing_performance(duration=10.0),
                'multi_task': await async_test.test_concurrent_performance(concurrent_tasks=10, duration=5.0)
            }
            self.results['async_system'] = async_results

            await async_test.cleanup()
        else:
            print("âŒ å¼‚æ­¥ç³»ç»Ÿè®¾ç½®å¤±è´¥ï¼Œè·³è¿‡æµ‹è¯•")
            self.results['async_system'] = None

        # æ¸…ç†å†…å­˜
        del async_test
        gc.collect()

        # ç”Ÿæˆå¯¹æ¯”æŠ¥å‘Š
        comparison_report = self._generate_comparison_report()

        print("\n" + "=" * 60)
        print("âœ… æ€§èƒ½å¯¹æ¯”æµ‹è¯•å®Œæˆ")
        print("=" * 60)

        return {
            'timestamp': self.timestamp,
            'results': self.results,
            'comparison': comparison_report
        }

    def _generate_comparison_report(self) -> Dict[str, Any]:
        """ç”Ÿæˆå¯¹æ¯”æŠ¥å‘Š"""
        if not self.results.get('sync_system') or not self.results.get('async_system'):
            return {'error': 'ç¼ºå°‘æµ‹è¯•æ•°æ®'}

        sync_single = self.results['sync_system']['single_thread']
        async_single = self.results['async_system']['single_task']

        sync_multi = self.results['sync_system']['multi_thread']
        async_multi = self.results['async_system']['multi_task']

        return {
            'single_thread_comparison': {
                'sync_avg_response_time': sync_single['avg_response_time'],
                'async_avg_response_time': async_single['avg_response_time'],
                'response_time_improvement': ((sync_single['avg_response_time'] - async_single['avg_response_time']) / sync_single['avg_response_time'] * 100) if sync_single['avg_response_time'] > 0 else 0,
                'sync_throughput': sync_single['avg_throughput'],
                'async_throughput': async_single['avg_throughput'],
                'throughput_improvement': ((async_single['avg_throughput'] - sync_single['avg_throughput']) / sync_single['avg_throughput'] * 100) if sync_single['avg_throughput'] > 0 else 0,
                'sync_memory_usage': sync_single['avg_memory_usage'],
                'async_memory_usage': async_single['avg_memory_usage'],
                'memory_efficiency': ((sync_single['avg_memory_usage'] - async_single['avg_memory_usage']) / sync_single['avg_memory_usage'] * 100) if sync_single['avg_memory_usage'] > 0 else 0
            },
            'concurrent_comparison': {
                'sync_throughput': sync_multi['avg_throughput'],
                'async_throughput': async_multi['avg_throughput'],
                'concurrent_improvement': ((async_multi['avg_throughput'] - sync_multi['avg_throughput']) / sync_multi['avg_throughput'] * 100) if sync_multi['avg_throughput'] > 0 else 0,
                'sync_success_rate': sync_multi['success_rate'],
                'async_success_rate': async_multi['success_rate'],
                'reliability_improvement': async_multi['success_rate'] - sync_multi['success_rate']
            },
            'summary': {
                'overall_performance_gain': self._calculate_overall_gain(),
                'recommendation': self._get_recommendation()
            }
        }

    def _calculate_overall_gain(self) -> float:
        """è®¡ç®—æ€»ä½“æ€§èƒ½æå‡"""
        try:
            sync_throughput = self.results['sync_system']['single_thread']['avg_throughput']
            async_throughput = self.results['async_system']['single_task']['avg_throughput']

            if sync_throughput > 0:
                return ((async_throughput - sync_throughput) / sync_throughput) * 100
            return 0
        except:
            return 0

    def _get_recommendation(self) -> str:
        """è·å–è¿ç§»å»ºè®®"""
        overall_gain = self._calculate_overall_gain()

        if overall_gain > 50:
            return "å¼ºçƒˆæ¨èè¿ç§»åˆ°å¼‚æ­¥ç³»ç»Ÿï¼Œæ€§èƒ½æå‡æ˜¾è‘—"
        elif overall_gain > 20:
            return "æ¨èè¿ç§»åˆ°å¼‚æ­¥ç³»ç»Ÿï¼Œæœ‰æ˜æ˜¾æ€§èƒ½ä¼˜åŠ¿"
        elif overall_gain > 0:
            return "å¯ä»¥è€ƒè™‘è¿ç§»åˆ°å¼‚æ­¥ç³»ç»Ÿï¼Œæœ‰é€‚åº¦æ€§èƒ½æå‡"
        else:
            return "å»ºè®®ä¿æŒå½“å‰ç³»ç»Ÿï¼Œå¼‚æ­¥ç³»ç»Ÿä¼˜åŠ¿ä¸æ˜æ˜¾"

    def save_results(self, filename: str = None) -> str:
        """ä¿å­˜æµ‹è¯•ç»“æœ"""
        if filename is None:
            timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
            filename = f"performance_comparison_{timestamp}.json"

        filepath = os.path.join("tests", "results", filename)
        os.makedirs(os.path.dirname(filepath), exist_ok=True)

        with open(filepath, 'w', encoding='utf-8') as f:
            json.dump({
                'timestamp': self.timestamp,
                'results': self.results,
                'comparison': self._generate_comparison_report()
            }, f, indent=2, ensure_ascii=False)

        return filepath


async def run_performance_comparison():
    """è¿è¡Œæ€§èƒ½å¯¹æ¯”æµ‹è¯•çš„ä¸»å‡½æ•°"""
    comparison = PerformanceComparison()

    try:
        results = await comparison.run_full_comparison()

        # æ‰“å°å…³é”®ç»“æœ
        print("\nğŸ“ˆ æ€§èƒ½å¯¹æ¯”ç»“æœ:")
        if 'comparison' in results and 'summary' in results['comparison']:
            summary = results['comparison']['summary']
            print(f"  æ€»ä½“æ€§èƒ½æå‡: {summary['overall_performance_gain']:.2f}%")
            print(f"  å»ºè®®: {summary['recommendation']}")

        # ä¿å­˜ç»“æœ
        saved_file = comparison.save_results()
        print(f"\nğŸ’¾ è¯¦ç»†ç»“æœå·²ä¿å­˜åˆ°: {saved_file}")

        return results

    except Exception as e:
        print(f"âŒ æ€§èƒ½æµ‹è¯•å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return None


if __name__ == "__main__":
    # è¿è¡Œæ€§èƒ½å¯¹æ¯”æµ‹è¯•
    results = asyncio.run(run_performance_comparison())