# -*- coding: utf-8 -*-
"""
å¼‚æ­¥éŸ³é¢‘å¤„ç†å™¨é€‚é…å™¨

å°†AsyncAudioCaptureé€‚é…ä¸ºIAudioProcessoræ¥å£ï¼Œæä¾›å®Œæ•´çš„å¼‚æ­¥åŠŸèƒ½æ”¯æŒã€‚
åŒæ—¶ä¿æŒä¸ç°æœ‰AudioCaptureçš„å…¼å®¹æ€§ï¼Œæ”¯æŒæ¸è¿›å¼è¿ç§»ã€‚
"""

import asyncio
import logging
import time
from typing import List, Optional, Dict, Any, Callable, Tuple

from interfaces.audio_processor import (
    IAudioProcessor, RecognitionResult, VoiceCommand, VoiceCommandType,
    AudioProcessorState
)
import sys
import os
sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

from async_audio import AsyncAudioCapture, create_async_audio_capture
from async_audio.async_number_extractor import extract_measurements
from audio_capture_v import AudioCapture

logger = logging.getLogger(__name__)


class AsyncAudioProcessorAdapter(IAudioProcessor):
    """
    å¼‚æ­¥éŸ³é¢‘å¤„ç†å™¨é€‚é…å™¨

    ç‰¹æ€§:
    - å®Œå…¨å¼‚æ­¥çš„éŸ³é¢‘å¤„ç†
    - ä¸åŒæ­¥æ¥å£çš„å…¼å®¹æ€§
    - é«˜æ€§èƒ½çš„å¹¶å‘å¤„ç†
    - äº‹ä»¶é©±åŠ¨çš„çŠ¶æ€ç®¡ç†
    """

    def __init__(
        self,
        async_capture: Optional[AsyncAudioCapture] = None,
        sync_capture: Optional[AudioCapture] = None,
        use_async: bool = True,
        **kwargs
    ):
        """
        åˆå§‹åŒ–å¼‚æ­¥éŸ³é¢‘å¤„ç†å™¨é€‚é…å™¨

        Args:
            async_capture: ç°æœ‰çš„AsyncAudioCaptureå®ä¾‹
            sync_capture: ç°æœ‰çš„AudioCaptureå®ä¾‹ï¼ˆå…¼å®¹æ€§ï¼‰
            use_async: æ˜¯å¦ä½¿ç”¨å¼‚æ­¥æ¨¡å¼
            **kwargs: ä¼ é€’ç»™AudioCaptureæ„é€ å‡½æ•°çš„å‚æ•°
        """
        self.use_async = use_async
        self._kwargs = kwargs

        # è¿‡æ»¤å‚æ•°ï¼Œåªä¼ é€’AudioCaptureæ”¯æŒçš„å‚æ•°
        sync_kwargs = {}
        async_kwargs = {}

        # æ”¯æŒçš„å‚æ•°æ˜ å°„
        supported_sync_params = ['timeout_seconds', 'model_path', 'test_mode', 'device_index']
        supported_async_params = ['sample_rate', 'chunk_size', 'model_path', 'timeout_seconds', 'test_mode']

        for key, value in kwargs.items():
            if key in supported_sync_params:
                sync_kwargs[key] = value
            if key in supported_async_params:
                async_kwargs[key] = value

        # å¼‚æ­¥å¤„ç†å™¨
        if async_capture:
            self._async_capture = async_capture
        else:
            self._async_capture = AsyncAudioCapture(**async_kwargs)

        # åŒæ­¥å¤„ç†å™¨ï¼ˆå…¼å®¹æ€§ï¼‰
        if sync_capture:
            self._sync_capture = sync_capture
        else:
            self._sync_capture = AudioCapture(**sync_kwargs)

        # å›è°ƒç®¡ç†
        self._recognition_callbacks: List[Callable[[RecognitionResult], None]] = []
        self._state_change_callbacks: List[Callable[[AudioProcessorState], None]] = []

        # çŠ¶æ€ç¼“å­˜
        self._last_state: AudioProcessorState = AudioProcessorState.IDLE
        self._state_lock = asyncio.Lock()

        # å¼‚æ­¥åˆå§‹åŒ–çŠ¶æ€
        self._async_initialized = False

        logger.info(f"AsyncAudioProcessorAdapter initialized (async_mode: {use_async})")

    async def async_initialize(self) -> bool:
        """å¼‚æ­¥åˆå§‹åŒ–"""
        if not self.use_async or self._async_initialized:
            return True

        logger.info("ğŸš€ åˆå§‹åŒ–å¼‚æ­¥éŸ³é¢‘å¤„ç†å™¨...")

        try:
            # åˆå§‹åŒ–å¼‚æ­¥å¤„ç†å™¨
            success = await self._async_capture.initialize()

            if success:
                # è®¾ç½®å›è°ƒ
                self._async_capture.add_recognition_callback(self._on_recognition_result)
                self._async_capture.add_state_change_callback(self._on_state_change)

                self._async_initialized = True
                logger.info("âœ… å¼‚æ­¥éŸ³é¢‘å¤„ç†å™¨åˆå§‹åŒ–æˆåŠŸ")

            return success

        except Exception as e:
            logger.error(f"âŒ å¼‚æ­¥éŸ³é¢‘å¤„ç†å™¨åˆå§‹åŒ–å¤±è´¥: {e}")
            return False

    # IAudioProcessor æ¥å£å®ç°

    async def start_recognition_async(self, callback: Optional[Callable[[List[float]], None]] = None) -> RecognitionResult:
        """å¼‚æ­¥å¼€å§‹è¯­éŸ³è¯†åˆ«"""
        # å­˜å‚¨å›è°ƒå‡½æ•°ï¼ˆå¦‚æœæä¾›ï¼‰
        if callback:
            self.set_callback(callback)
        if not self.use_async:
            # åŒæ­¥æ¨¡å¼çš„å¼‚æ­¥åŒ…è£…
            # å°†listen_realtime_voskè¿”å›çš„å­—å…¸è½¬æ¢ä¸ºRecognitionResultå¯¹è±¡
            result_dict = await asyncio.to_thread(self._sync_capture.listen_realtime_vosk)
            # ç¡®ä¿è·å–çš„å€¼å…·æœ‰æ­£ç¡®çš„ç±»å‹
            final_text = str(result_dict.get('text', ''))
            
            # ç¡®ä¿buffered_valuesæ˜¯List[float]
            raw_values = result_dict.get('values', [])
            buffered_values: List[float] = []
            if isinstance(raw_values, list):
                for val in raw_values:
                    # åªå°è¯•è½¬æ¢å¯ä»¥è½¬æ¢ä¸ºfloatçš„ç±»å‹
                    if isinstance(val, (int, float, str)):
                        try:
                            buffered_values.append(float(val))
                        except (ValueError, TypeError):
                            pass
            
            # ç¡®ä¿collected_textæ˜¯List[str]
            raw_texts = result_dict.get('collected_text', [])
            collected_text: List[str] = []
            if isinstance(raw_texts, list):
                for text in raw_texts:
                    try:
                        collected_text.append(str(text))
                    except (ValueError, TypeError):
                        pass
            
            # ç¡®ä¿session_dataæ˜¯List[Tuple[int, float, str]]
            raw_session_data = result_dict.get('session_data', [])
            session_data: List[Tuple[int, float, str]] = []
            if isinstance(raw_session_data, list):
                for item in raw_session_data:
                    try:
                        if isinstance(item, tuple) and len(item) == 3:
                            # å°è¯•è½¬æ¢ä¸ºæ­£ç¡®çš„ç±»å‹
                            timestamp = int(item[0])
                            value = float(item[1])
                            text = str(item[2])
                            session_data.append((timestamp, value, text))
                    except (ValueError, TypeError, IndexError):
                        pass
            
            # ç¡®ä¿æ•°å€¼ç±»å‹æ­£ç¡® - å…ˆè·å–å€¼å¹¶ç¡®ä¿å®ƒæ˜¯å¯è½¬æ¢çš„ç±»å‹
            recognition_count_val = result_dict.get('recognition_count', 0)
            recognition_count = 0
            if isinstance(recognition_count_val, (int, float, str)):
                try:
                    recognition_count = int(recognition_count_val)
                except (ValueError, TypeError):
                    pass
            
            audio_frames_val = result_dict.get('audio_frames', 0)
            audio_frames = 0
            if isinstance(audio_frames_val, (int, float, str)):
                try:
                    audio_frames = int(audio_frames_val)
                except (ValueError, TypeError):
                    pass
            
            processing_time_val = result_dict.get('processing_time', 0.0)
            processing_time = 0.0
            if isinstance(processing_time_val, (int, float, str)):
                try:
                    processing_time = float(processing_time_val)
                except (ValueError, TypeError):
                    pass
            
            return RecognitionResult(
                final_text=final_text,
                buffered_values=buffered_values,
                collected_text=collected_text,
                session_data=session_data,
                recognition_count=recognition_count,
                audio_frames=audio_frames,
                processing_time=processing_time
            )

        # ç¡®ä¿å¼‚æ­¥å¤„ç†å™¨å·²åˆå§‹åŒ–
        if not await self.async_initialize():
            return RecognitionResult(
                final_text="",
                session_data=[],
                processing_time=0.0
            )

        return await self._async_capture.start_recognition()

    async def stop_recognition_async(self) -> RecognitionResult:
        """å¼‚æ­¥åœæ­¢è¯­éŸ³è¯†åˆ«"""
        if not self.use_async:
            # åŒæ­¥æ¨¡å¼çš„å¼‚æ­¥åŒ…è£…
            # TODO: å®ç°åŒæ­¥åœæ­¢é€»è¾‘
            return RecognitionResult(
                final_text="Stop sync recognition",
                session_data=[],
                processing_time=0.0
            )

        return await self._async_capture.stop_recognition()

    async def pause_recognition_async(self) -> bool:
        """å¼‚æ­¥æš‚åœè¯­éŸ³è¯†åˆ«"""
        if not self.use_async:
            return False  # åŒæ­¥æ¨¡å¼æš‚ä¸æ”¯æŒæš‚åœ

        return await self._async_capture.pause_recognition()

    async def resume_recognition_async(self) -> bool:
        """å¼‚æ­¥æ¢å¤è¯­éŸ³è¯†åˆ«"""
        if not self.use_async:
            return False  # åŒæ­¥æ¨¡å¼æš‚ä¸æ”¯æŒæ¢å¤

        return await self._async_capture.resume_recognition()

    def extract_measurements(self, text: str) -> List[float]:
        """æå–æ•°å€¼ï¼ˆåŒæ­¥æ¥å£ï¼‰"""
        try:
            # å¦‚æœæ˜¯å¼‚æ­¥æ¨¡å¼ï¼Œå°è¯•ä½¿ç”¨å¼‚æ­¥æå–å™¨çš„åŒæ­¥ç‰ˆæœ¬
            if self.use_async:
                # ä½¿ç”¨asyncio.runåœ¨åŒæ­¥ä¸Šä¸‹æ–‡ä¸­è¿è¡Œå¼‚æ­¥å‡½æ•°
                try:
                    # æ³¨æ„ï¼šè¿™åªèƒ½åœ¨éå¼‚æ­¥ä¸Šä¸‹æ–‡ä¸­ä½¿ç”¨
                    if not asyncio.get_event_loop().is_running():
                        return asyncio.run(extract_measurements(text))
                except RuntimeError:
                    # å¦‚æœå·²æœ‰äº‹ä»¶å¾ªç¯åœ¨è¿è¡Œï¼Œå›é€€åˆ°åŒæ­¥ç‰ˆæœ¬
                    pass

            # å›é€€åˆ°åŒæ­¥ç‰ˆæœ¬çš„æ•°å€¼æå–
            # ç”±äºextract_measurementsæ˜¯å¼‚æ­¥å‡½æ•°ï¼Œéœ€è¦åœ¨åŒæ­¥ç¯å¢ƒä¸­ä½¿ç”¨runæ¥æ‰§è¡Œ
            def sync_wrapper():
                try:
                    # æ£€æŸ¥æ˜¯å¦æœ‰æ­£åœ¨è¿è¡Œçš„äº‹ä»¶å¾ªç¯
                    loop = asyncio.get_event_loop()
                    if loop.is_running():
                        # å¦‚æœäº‹ä»¶å¾ªç¯æ­£åœ¨è¿è¡Œï¼Œä½¿ç”¨åˆ›å»ºä»»åŠ¡çš„æ–¹å¼
                        future = asyncio.run_coroutine_threadsafe(extract_measurements(text), loop)
                        return future.result()
                    else:
                        # å¦‚æœæ²¡æœ‰è¿è¡Œçš„äº‹ä»¶å¾ªç¯ï¼Œç›´æ¥è¿è¡Œ
                        return asyncio.run(extract_measurements(text))
                except RuntimeError:
                    # æ— æ³•è·å–äº‹ä»¶å¾ªç¯ï¼Œåˆ›å»ºä¸€ä¸ªæ–°çš„
                    return asyncio.run(extract_measurements(text))
                except Exception as e:
                    logger.error(f"âŒ æ•°å€¼æå–åŒ…è£…å¤±è´¥: {e}")
                    return []
            
            return sync_wrapper()

        except Exception as e:
            logger.error(f"âŒ æ•°å€¼æå–å¤±è´¥: {e}")
            return []

    async def extract_measurements_async(self, text: str) -> List[float]:
        """å¼‚æ­¥æå–æ•°å€¼"""
        if self.use_async:
            return await extract_measurements(text)
        else:
            # åŒæ­¥æ¨¡å¼çš„å¼‚æ­¥åŒ…è£…
            # ç”±äºextract_measurementsæ˜¯å¼‚æ­¥å‡½æ•°ï¼Œéœ€è¦åœ¨åŒæ­¥ç¯å¢ƒä¸­ä½¿ç”¨runæ¥æ‰§è¡Œ
            def sync_wrapper():
                try:
                    # æ£€æŸ¥æ˜¯å¦æœ‰æ­£åœ¨è¿è¡Œçš„äº‹ä»¶å¾ªç¯
                    loop = asyncio.get_event_loop()
                    if loop.is_running():
                        # å¦‚æœäº‹ä»¶å¾ªç¯æ­£åœ¨è¿è¡Œï¼Œä½¿ç”¨åˆ›å»ºä»»åŠ¡çš„æ–¹å¼
                        future = asyncio.run_coroutine_threadsafe(extract_measurements(text), loop)
                        return future.result()
                    else:
                        # å¦‚æœæ²¡æœ‰è¿è¡Œçš„äº‹ä»¶å¾ªç¯ï¼Œç›´æ¥è¿è¡Œ
                        return asyncio.run(extract_measurements(text))
                except RuntimeError:
                    # æ— æ³•è·å–äº‹ä»¶å¾ªç¯ï¼Œåˆ›å»ºä¸€ä¸ªæ–°çš„
                    return asyncio.run(extract_measurements(text))
            
            return await asyncio.to_thread(sync_wrapper)

    def get_state(self) -> AudioProcessorState:
        """è·å–å½“å‰çŠ¶æ€"""
        if self.use_async and self._async_initialized:
            return self._async_capture.get_state()
        else:
            # æ˜ å°„åŒæ­¥çŠ¶æ€åˆ°æ¥å£çŠ¶æ€
            sync_state = self._sync_capture.state
            state_mapping = {
                "idle": AudioProcessorState.IDLE,
                "running": AudioProcessorState.RECORDING,  # ä½¿ç”¨RECORDINGæ›¿ä»£RUNNING
                "paused": AudioProcessorState.PAUSED,
                "stopped": AudioProcessorState.STOPPED
            }
            return state_mapping.get(sync_state, AudioProcessorState.IDLE)

    def is_initialized(self) -> bool:
        """æ£€æŸ¥æ˜¯å¦å·²åˆå§‹åŒ–"""
        if self.use_async:
            return self._async_initialized
        else:
            # åŒæ­¥æ¨¡å¼æ²¡æœ‰æ˜ç¡®çš„åˆå§‹åŒ–çŠ¶æ€
            return True

    def add_recognition_callback(self, callback: Callable[[RecognitionResult], None]):
        """æ·»åŠ è¯†åˆ«ç»“æœå›è°ƒ"""
        self._recognition_callbacks.append(callback)

        # å¦‚æœæ˜¯å¼‚æ­¥æ¨¡å¼ä¸”å·²åˆå§‹åŒ–ï¼Œä¹Ÿæ·»åŠ åˆ°å¼‚æ­¥å¤„ç†å™¨
        if self.use_async and self._async_initialized:
            self._async_capture.add_recognition_callback(callback)

    def add_state_change_callback(self, callback: Callable[[AudioProcessorState], None]):
        """æ·»åŠ çŠ¶æ€å˜æ›´å›è°ƒ"""
        self._state_change_callbacks.append(callback)

        # å¦‚æœæ˜¯å¼‚æ­¥æ¨¡å¼ä¸”å·²åˆå§‹åŒ–ï¼Œä¹Ÿæ·»åŠ åˆ°å¼‚æ­¥å¤„ç†å™¨
        if self.use_async and self._async_initialized:
            self._async_capture.add_state_change_callback(callback)

    # æ‰©å±•åŠŸèƒ½

    def set_async_mode(self, use_async: bool):
        """è®¾ç½®å¼‚æ­¥æ¨¡å¼"""
        if use_async != self.use_async:
            logger.info(f"ğŸ”„ åˆ‡æ¢å¼‚æ­¥æ¨¡å¼: {self.use_async} â†’ {use_async}")
            self.use_async = use_async

            # å¦‚æœåˆ‡æ¢åˆ°å¼‚æ­¥æ¨¡å¼ï¼Œè§¦å‘åˆå§‹åŒ–
            if use_async and not self._async_initialized:
                # æ³¨æ„ï¼šè¿™é‡Œä¸èƒ½ç›´æ¥awaitï¼Œéœ€è¦åœ¨å¼‚æ­¥ä¸Šä¸‹æ–‡ä¸­è°ƒç”¨
                logger.info("âš ï¸ éœ€è¦åœ¨å¼‚æ­¥ä¸Šä¸‹æ–‡ä¸­è°ƒç”¨ async_initialize()")

    async def switch_to_async_mode(self) -> bool:
        """åˆ‡æ¢åˆ°å¼‚æ­¥æ¨¡å¼ï¼ˆå¼‚æ­¥æ–¹æ³•ï¼‰"""
        if not self.use_async:
            self.set_async_mode(True)
            return await self.async_initialize()
        return self._async_initialized

    async def switch_to_sync_mode(self) -> bool:
        """åˆ‡æ¢åˆ°åŒæ­¥æ¨¡å¼ï¼ˆå¼‚æ­¥æ–¹æ³•ï¼‰"""
        if self.use_async:
            # åœæ­¢å¼‚æ­¥å¤„ç†å™¨
            if self._async_initialized:
                await self._async_capture.stop_recognition()
                await self._async_capture.cleanup()
                self._async_initialized = False

            self.set_async_mode(False)
            return True
        return True

    def get_statistics(self) -> Dict[str, Any]:
        """è·å–ç»Ÿè®¡ä¿¡æ¯"""
        stats = {
            "use_async": self.use_async,
            "async_initialized": self._async_initialized,
            "current_state": self.get_state().name
        }

        if self.use_async and self._async_initialized:
            async_stats = self._async_capture.get_statistics()
            stats["async_stats"] = async_stats

        return stats

    def get_diagnostics_info(self) -> Dict[str, Any]:
        """è·å–è¯Šæ–­ä¿¡æ¯"""
        diagnostics = {
            "adapter_type": "AsyncAudioProcessorAdapter",
            "async_mode": self.use_async,
            "async_initialized": self._async_initialized,
            "state": self.get_state().name,
            "callback_count": len(self._recognition_callbacks) + len(self._state_change_callbacks)
        }

        if self.use_async and self._async_initialized:
            # åœ¨åŒæ­¥æ–¹æ³•ä¸­è·å–å¼‚æ­¥å¤„ç†å™¨çš„è¯Šæ–­ä¿¡æ¯
            # æ³¨æ„ï¼šè¿™é‡Œå‡è®¾get_statisticsæ˜¯åŒæ­¥æ–¹æ³•ï¼Œå¦‚æœæ˜¯å¼‚æ­¥çš„éœ€è¦é¢å¤–å¤„ç†
            try:
                async_diagnostics = self._async_capture.get_statistics()
                diagnostics["async_details"] = async_diagnostics
            except Exception:
                # å¦‚æœè·å–å¤±è´¥ï¼Œè®°å½•é”™è¯¯ä½†ä¸å½±å“æ•´ä½“åŠŸèƒ½
                diagnostics["async_details"] = {"error": "Failed to get async diagnostics"}

        return diagnostics

    # å†…éƒ¨å›è°ƒå¤„ç†

    def _on_recognition_result(self, result: RecognitionResult):
        """å¤„ç†è¯†åˆ«ç»“æœå›è°ƒ"""
        # è°ƒç”¨æ‰€æœ‰æ³¨å†Œçš„å›è°ƒ
        for callback in self._recognition_callbacks:
            try:
                callback(result)
            except Exception as e:
                logger.error(f"âŒ è¯†åˆ«å›è°ƒæ‰§è¡Œå¤±è´¥: {e}")

    def _on_state_change(self, new_state):
        """å¤„ç†çŠ¶æ€å˜æ›´å›è°ƒ"""
        # è°ƒç”¨æ‰€æœ‰æ³¨å†Œçš„å›è°ƒ
        for callback in self._state_change_callbacks:
            try:
                callback(new_state)
            except Exception as e:
                logger.error(f"âŒ çŠ¶æ€å˜æ›´å›è°ƒæ‰§è¡Œå¤±è´¥: {e}")

    # èµ„æºç®¡ç†

    async def cleanup_async(self):
        """å¼‚æ­¥æ¸…ç†èµ„æº"""
        logger.info("ğŸ§¹ æ¸…ç†å¼‚æ­¥éŸ³é¢‘å¤„ç†å™¨é€‚é…å™¨...")

        try:
            # æ¸…ç†å¼‚æ­¥å¤„ç†å™¨
            if self.use_async and self._async_initialized:
                await self._async_capture.cleanup()
                self._async_initialized = False

            # æ¸…ç†åŒæ­¥å¤„ç†å™¨
            if hasattr(self._sync_capture, 'cleanup'):
                self._sync_capture.cleanup()

            logger.info("âœ… å¼‚æ­¥éŸ³é¢‘å¤„ç†å™¨é€‚é…å™¨æ¸…ç†å®Œæˆ")

        except Exception as e:
            logger.error(f"âŒ å¼‚æ­¥éŸ³é¢‘å¤„ç†å™¨é€‚é…å™¨æ¸…ç†å¤±è´¥: {e}")

    # IAudioProcessor æ¥å£å®ç° - å®Œæ•´æ–¹æ³•é›†

    def load_model(self, model_path: Optional[str] = None) -> bool:
        """åŠ è½½è¯­éŸ³è¯†åˆ«æ¨¡å‹"""
        if self.use_async and self._async_initialized:
            # å¼‚æ­¥æ¨¡å¼çš„åŒæ­¥åŒ…è£…
            try:
                loop = asyncio.get_event_loop()
                if loop.is_running():
                    # å¦‚æœäº‹ä»¶å¾ªç¯æ­£åœ¨è¿è¡Œï¼Œåˆ›å»ºä»»åŠ¡
                    asyncio.create_task(self._async_load_model(model_path))
                    return True
                else:
                    # å¦‚æœæ²¡æœ‰äº‹ä»¶å¾ªç¯ï¼Œè¿è¡Œå¼‚æ­¥æ–¹æ³•
                    return loop.run_until_complete(self._async_load_model(model_path))
            except RuntimeError:
                # å¦‚æœæ— æ³•è·å–äº‹ä»¶å¾ªç¯ï¼Œå›é€€åˆ°åŒæ­¥æ¨¡å¼
                # AudioCapture.load_modelæ–¹æ³•æ²¡æœ‰å‚æ•°
                return self._sync_capture.load_model()
        else:
            # åŒæ­¥æ¨¡å¼
            # AudioCapture.load_modelæ–¹æ³•æ²¡æœ‰å‚æ•°
            return self._sync_capture.load_model()

    async def _async_load_model(self, model_path: Optional[str] = None) -> bool:
        """å¼‚æ­¥åŠ è½½æ¨¡å‹"""
        if not self.use_async or not self._async_initialized:
            return False

        try:
            # åœ¨çº¿ç¨‹æ± ä¸­æ‰§è¡Œæ¨¡å‹åŠ è½½
            # AudioCapture.load_modelæ–¹æ³•æ²¡æœ‰å‚æ•°
            success = await asyncio.to_thread(
                self._sync_capture.load_model
            )
            return success
        except Exception as e:
            logger.error(f"âŒ å¼‚æ­¥åŠ è½½æ¨¡å‹å¤±è´¥: {e}")
            return False

    def unload_model(self) -> None:
        """å¸è½½è¯­éŸ³è¯†åˆ«æ¨¡å‹ï¼Œé‡Šæ”¾å†…å­˜èµ„æº"""
        if self.use_async and self._async_initialized:
            # å¼‚æ­¥æ¨¡å¼çš„åŒæ­¥åŒ…è£…
            try:
                loop = asyncio.get_event_loop()
                if loop.is_running():
                    asyncio.create_task(self._async_unload_model())
                else:
                    loop.run_until_complete(self._async_unload_model())
            except RuntimeError:
                self._sync_capture.unload_model()
        else:
            self._sync_capture.unload_model()

    async def _async_unload_model(self) -> None:
        """å¼‚æ­¥å¸è½½æ¨¡å‹"""
        if not self.use_async or not self._async_initialized:
            return

        try:
            await asyncio.to_thread(self._sync_capture.unload_model)
        except Exception as e:
            logger.error(f"âŒ å¼‚æ­¥å¸è½½æ¨¡å‹å¤±è´¥: {e}")

    def is_model_loaded(self) -> bool:
        """æ£€æŸ¥æ¨¡å‹æ˜¯å¦å·²åŠ è½½"""
        if self.use_async and self._async_initialized:
            # å¼‚æ­¥æ¨¡å¼çš„åŒæ­¥æ£€æŸ¥
            return self._async_capture.recognizer.is_initialized
        else:
            # åŒæ­¥æ¨¡å¼
            return hasattr(self._sync_capture, 'recognizer') and self._sync_capture.recognizer is not None

    def start_recognition(self, callback: Optional[Callable[[List[float]], None]] = None) -> Dict[str, Any]:
        """å¼€å§‹è¯­éŸ³è¯†åˆ«ï¼ˆåŒæ­¥æ¨¡å¼ï¼‰"""
        if self.use_async and self._async_initialized:
            # å¼‚æ­¥æ¨¡å¼çš„åŒæ­¥åŒ…è£…
            try:
                loop = asyncio.get_event_loop()
                if loop.is_running():
                    # å¦‚æœäº‹ä»¶å¾ªç¯æ­£åœ¨è¿è¡Œï¼Œè¿”å›é”™è¯¯ä¿¡æ¯
                    return {
                        "success": False,
                        "error": "Cannot use sync method when async mode is enabled and event loop is running",
                        "timestamp": time.time()
                    }
                else:
                    # å¦‚æœæ²¡æœ‰äº‹ä»¶å¾ªç¯ï¼Œè¿è¡Œå¼‚æ­¥æ–¹æ³•
                    result = loop.run_until_complete(self.start_recognition_async())
                    # RecognitionResultç±»æ²¡æœ‰successã€textã€error_messageå’Œtimestampå±æ€§
                    # ä½¿ç”¨æ­£ç¡®çš„å±æ€§æ¥æ„å»ºè¿”å›å€¼
                    return {
                        "success": True,  # å‡è®¾è¯†åˆ«æˆåŠŸ
                        "text": result.final_text,
                        "error": None,  # æ— æ³•ä»RecognitionResultä¸­ç›´æ¥è·å–é”™è¯¯ä¿¡æ¯
                        "timestamp": time.time()  # ä½¿ç”¨å½“å‰æ—¶é—´æˆ³
                    }
            except RuntimeError:
                # å¦‚æœæ— æ³•è·å–äº‹ä»¶å¾ªç¯ï¼Œå›é€€åˆ°åŒæ­¥æ¨¡å¼
                return self._sync_capture.listen_realtime_vosk()
        else:
            # åŒæ­¥æ¨¡å¼
            return self._sync_capture.listen_realtime_vosk()

    def pause_recognition(self) -> None:
        """æš‚åœè¯­éŸ³è¯†åˆ«"""
        if self.use_async and self._async_initialized:
            # å¼‚æ­¥æ¨¡å¼çš„åŒæ­¥åŒ…è£…
            try:
                loop = asyncio.get_event_loop()
                if loop.is_running():
                    asyncio.create_task(self.pause_recognition_async())
                else:
                    loop.run_until_complete(self.pause_recognition_async())
            except RuntimeError:
                pass  # é™é»˜å¤„ç†
        else:
            # åŒæ­¥æ¨¡å¼å¯èƒ½ä¸æ”¯æŒæš‚åœ
            pass

    def resume_recognition(self) -> None:
        """æ¢å¤è¯­éŸ³è¯†åˆ«"""
        if self.use_async and self._async_initialized:
            # å¼‚æ­¥æ¨¡å¼çš„åŒæ­¥åŒ…è£…
            try:
                loop = asyncio.get_event_loop()
                if loop.is_running():
                    asyncio.create_task(self.resume_recognition_async())
                else:
                    loop.run_until_complete(self.resume_recognition_async())
            except RuntimeError:
                pass  # é™é»˜å¤„ç†
        else:
            # åŒæ­¥æ¨¡å¼å¯èƒ½ä¸æ”¯æŒæ¢å¤
            pass

    def stop_recognition(self) -> None:
        """åœæ­¢è¯­éŸ³è¯†åˆ«"""
        if self.use_async and self._async_initialized:
            # å¼‚æ­¥æ¨¡å¼çš„åŒæ­¥åŒ…è£…
            try:
                loop = asyncio.get_event_loop()
                if loop.is_running():
                    asyncio.create_task(self.stop_recognition_async())
                else:
                    loop.run_until_complete(self.stop_recognition_async())
            except RuntimeError:
                pass  # é™é»˜å¤„ç†
        else:
            # åŒæ­¥æ¨¡å¼
            if hasattr(self._sync_capture, 'state') and self._sync_capture.state == "running":
                self._sync_capture.state = "stopped"

    def set_callback(self, callback: Callable[[List[float]], None]) -> None:
        """è®¾ç½®æ•°å€¼æ£€æµ‹å›è°ƒå‡½æ•°"""
        # è½¬æ¢ä¸ºRecognitionResultå›è°ƒ
        def converted_callback(result: RecognitionResult):
            # RecognitionResultæ²¡æœ‰successå’Œtextå±æ€§ï¼Œä½¿ç”¨æ­£ç¡®çš„å±æ€§
            if result.final_text and self.use_async:
                # æå–æ•°å€¼
                measurements = self.extract_measurements(result.final_text)
                if measurements:
                    callback(measurements)

        self.add_recognition_callback(converted_callback)

        # åŒæ—¶è®¾ç½®åˆ°åŒæ­¥å¤„ç†å™¨
        if hasattr(self._sync_capture, 'set_callback'):
            self._sync_capture.set_callback(callback)

    def process_voice_commands(self, text: str) -> Optional[VoiceCommand]:
        """å¤„ç†è¯­éŸ³æ§åˆ¶å‘½ä»¤"""
        try:
            # ç®€å•çš„è¯­éŸ³å‘½ä»¤è¯†åˆ«
            text_lower = text.lower().strip()

            # åœæ­¢å‘½ä»¤
            if any(keyword in text_lower for keyword in ['åœæ­¢', 'ç»“æŸ', 'åœæ­¢è¯†åˆ«']):
                return VoiceCommand(
                    command_type=VoiceCommandType.STOP,
                    original_text=text,
                    confidence=0.9
                )

            # æš‚åœå‘½ä»¤
            elif any(keyword in text_lower for keyword in ['æš‚åœ', 'æš‚åœè¯†åˆ«']):
                return VoiceCommand(
                    command_type=VoiceCommandType.PAUSE,
                    original_text=text,
                    confidence=0.9
                )

            # æ¢å¤å‘½ä»¤
            elif any(keyword in text_lower for keyword in ['ç»§ç»­', 'æ¢å¤', 'æ¢å¤è¯†åˆ«']):
                return VoiceCommand(
                    command_type=VoiceCommandType.RESUME,
                    original_text=text,
                    confidence=0.9
                )

            # æ¸…ç©ºå‘½ä»¤ - ä½¿ç”¨UNKNOWNç±»å‹ï¼Œå› ä¸ºVoiceCommandTypeä¸­æ²¡æœ‰CLEARæšä¸¾
            elif any(keyword in text_lower for keyword in ['æ¸…ç©º', 'æ¸…é™¤', 'æ¸…ç©ºæ•°æ®']):
                return VoiceCommand(
                    command_type=VoiceCommandType.UNKNOWN,
                    original_text=text,
                    confidence=0.8
                )

            return None

        except Exception as e:
            logger.error(f"âŒ å¤„ç†è¯­éŸ³å‘½ä»¤å¤±è´¥: {e}")
            return None

    def get_buffered_values(self) -> List[float]:
        """è·å–ç¼“å†²çš„æ•°å€¼åˆ—è¡¨"""
        if self.use_async and self._async_initialized:
            # ä»å¼‚æ­¥å¤„ç†å™¨çš„ç»Ÿè®¡ä¿¡æ¯ä¸­è·å–
            stats = self._async_capture.get_statistics()
            # è¿™é‡Œéœ€è¦å®ç°å®é™…çš„ç¼“å†²åŒºç®¡ç†
            # ç›®å‰è¿”å›ç©ºåˆ—è¡¨
            return []
        else:
            # åŒæ­¥æ¨¡å¼
            if hasattr(self._sync_capture, 'buffered_values'):
                # ç¡®ä¿è¿”å›çš„æ˜¯listç±»å‹ï¼Œå³ä½¿åŸå§‹ç±»å‹æ˜¯deque
                return list(self._sync_capture.buffered_values)
            return []

    def get_session_data(self) -> List[Tuple[int, float, str]]:
        """è·å–æœ¬æ¬¡ä¼šè¯çš„æ•°æ®"""
        if self.use_async and self._async_initialized:
            # ä»å¼‚æ­¥å¤„ç†å™¨çš„ä¼šè¯æ•°æ®ä¸­è·å–
            # è¿™é‡Œéœ€è¦å®ç°å®é™…çš„ä¼šè¯æ•°æ®ç®¡ç†
            # ç›®å‰è¿”å›ç©ºåˆ—è¡¨
            return []
        else:
            # åŒæ­¥æ¨¡å¼
            if hasattr(self._sync_capture, 'session_data'):
                return self._sync_capture.session_data
            return []

    def clear_buffer(self) -> None:
        """æ¸…ç©ºæ•°å€¼ç¼“å†²åŒº"""
        if self.use_async and self._async_initialized:
            # æ¸…ç©ºå¼‚æ­¥å¤„ç†å™¨çš„ç¼“å†²åŒº
            # è¿™é‡Œéœ€è¦å®ç°å®é™…çš„ç¼“å†²åŒºæ¸…ç†
            pass
        else:
            # åŒæ­¥æ¨¡å¼
            if hasattr(self._sync_capture, 'clear_buffer'):
                self._sync_capture.clear_buffer()

    def set_audio_parameters(
        self,
        sample_rate: int = 16000,
        chunk_size: int = 8000,
        channels: int = 1,
        format_type: str = "int16"
    ) -> None:
        """è®¾ç½®éŸ³é¢‘å¤„ç†å‚æ•°"""
        if self.use_async and self._async_initialized:
            # å¼‚æ­¥æ¨¡å¼å‚æ•°è®¾ç½®
            logger.warning("âš ï¸ å¼‚æ­¥æ¨¡å¼ä¸‹è¿è¡Œæ—¶å‚æ•°æ›´æ”¹éœ€è¦é‡æ–°åˆå§‹åŒ–")
            # è®°å½•æ–°å‚æ•°ï¼Œä¸‹æ¬¡åˆå§‹åŒ–æ—¶ä½¿ç”¨
            self._kwargs.update({
                'sample_rate': sample_rate,
                'chunk_size': chunk_size,
                'channels': channels,
                'format_type': format_type
            })
        else:
            # åŒæ­¥æ¨¡å¼å‚æ•°è®¾ç½®
            if hasattr(self._sync_capture, 'set_audio_parameters'):
                self._sync_capture.set_audio_parameters(
                    sample_rate=sample_rate,
                    chunk_size=chunk_size,
                    channels=channels,
                    format_type=format_type
                )

    def get_audio_parameters(self) -> Dict[str, Any]:
        """è·å–å½“å‰éŸ³é¢‘å¤„ç†å‚æ•°"""
        if self.use_async and self._async_initialized:
            # å¼‚æ­¥æ¨¡å¼å‚æ•°è·å–
            return {
                'sample_rate': self._async_capture.sample_rate,
                'chunk_size': self._async_capture.chunk_size,
                'model_path': self._async_capture.model_path,
                'timeout_seconds': self._async_capture.timeout_seconds,
                'test_mode': self._async_capture.test_mode
            }
        else:
            # åŒæ­¥æ¨¡å¼å‚æ•°è·å–
            params = {
                'timeout_seconds': self._sync_capture.timeout_seconds
            }
            if hasattr(self._sync_capture, 'audio_chunk_size'):
                params['chunk_size'] = self._sync_capture.audio_chunk_size
            return params

    # TTSç›¸å…³æ–¹æ³•

    def enable_tts(self) -> None:
        """å¯ç”¨TTSåŠŸèƒ½"""
        if self.use_async and self._async_initialized:
            # å¼‚æ­¥æ¨¡å¼å¯ç”¨TTS
            logger.info("ğŸ”Š å¯ç”¨å¼‚æ­¥TTSåŠŸèƒ½")
            # è¿™é‡Œéœ€è¦å®ç°å®é™…çš„TTSå¯ç”¨é€»è¾‘
        else:
            # åŒæ­¥æ¨¡å¼å¯ç”¨TTS
            if hasattr(self._sync_capture, 'enable_tts'):
                self._sync_capture.enable_tts()

    def disable_tts(self) -> None:
        """ç¦ç”¨TTSåŠŸèƒ½"""
        if self.use_async and self._async_initialized:
            # å¼‚æ­¥æ¨¡å¼ç¦ç”¨TTS
            logger.info("ğŸ”‡ ç¦ç”¨å¼‚æ­¥TTSåŠŸèƒ½")
            # è¿™é‡Œéœ€è¦å®ç°å®é™…çš„TTSç¦ç”¨é€»è¾‘
        else:
            # åŒæ­¥æ¨¡å¼ç¦ç”¨TTS
            if hasattr(self._sync_capture, 'disable_tts'):
                self._sync_capture.disable_tts()

    def toggle_tts(self) -> bool:
        """åˆ‡æ¢TTSå¼€å…³çŠ¶æ€"""
        if self.use_async and self._async_initialized:
            # å¼‚æ­¥æ¨¡å¼åˆ‡æ¢TTS
            current_state = self.is_tts_enabled()
            if current_state:
                self.disable_tts()
            else:
                self.enable_tts()
            return not current_state
        else:
            # åŒæ­¥æ¨¡å¼åˆ‡æ¢TTS
            if hasattr(self._sync_capture, 'toggle_tts'):
                try:
                    self._sync_capture.toggle_tts()
                    return True
                except Exception as e:
                    logger.error(f"âŒ åŒæ­¥æ¨¡å¼åˆ‡æ¢TTSå¤±è´¥: {e}")
                    return False
            return False

    def is_tts_enabled(self) -> bool:
        """è·å–TTSå½“å‰çŠ¶æ€"""
        if self.use_async and self._async_initialized:
            # å¼‚æ­¥æ¨¡å¼TTSçŠ¶æ€
            # è¿™é‡Œéœ€è¦å®ç°å®é™…çš„TTSçŠ¶æ€æ£€æŸ¥
            return False  # é»˜è®¤ç¦ç”¨
        else:
            # åŒæ­¥æ¨¡å¼TTSçŠ¶æ€
            if hasattr(self._sync_capture, 'is_tts_enabled'):
                return self._sync_capture.is_tts_enabled()
            return False

    def speak_text(self, text: str) -> None:
        """TTSæ’­æŠ¥æ–‡æœ¬"""
        if self.use_async and self._async_initialized:
            # å¼‚æ­¥æ¨¡å¼çš„åŒæ­¥åŒ…è£…
            try:
                loop = asyncio.get_event_loop()
                if loop.is_running():
                    # å¦‚æœäº‹ä»¶å¾ªç¯æ­£åœ¨è¿è¡Œï¼Œåˆ›å»ºä»»åŠ¡
                    asyncio.create_task(self.speak_text_async(text))
                else:
                    # å¦‚æœæ²¡æœ‰äº‹ä»¶å¾ªç¯ï¼Œè¿è¡Œå¼‚æ­¥æ–¹æ³•
                    loop.run_until_complete(self.speak_text_async(text))
            except RuntimeError:
                # å¦‚æœæ— æ³•è·å–äº‹ä»¶å¾ªç¯ï¼Œå›é€€åˆ°åŒæ­¥æ¨¡å¼
                if hasattr(self._sync_capture, 'speak_text'):
                    self._sync_capture.speak_text(text)
        else:
            # åŒæ­¥æ¨¡å¼
            if hasattr(self._sync_capture, 'speak_text'):
                self._sync_capture.speak_text(text)

    async def speak_text_async(self, text: str) -> None:
        """å¼‚æ­¥TTSæ’­æŠ¥æ–‡æœ¬"""
        if self.use_async and self._async_initialized:
            # å¼‚æ­¥æ¨¡å¼TTSæ’­æŠ¥
            try:
                success = await self._async_capture.tts_player.speak_async(text)
                if not success:
                    logger.warning(f"âš ï¸ TTSæ’­æŠ¥å¤±è´¥: {text}")
            except Exception as e:
                logger.error(f"âŒ å¼‚æ­¥TTSæ’­æŠ¥å¤±è´¥: {e}")
        else:
            # åŒæ­¥æ¨¡å¼çš„å¼‚æ­¥åŒ…è£…
            await asyncio.to_thread(self.speak_text, text)

    def test_audio_pipeline(self) -> Dict[str, Any]:
        """æµ‹è¯•éŸ³é¢‘å¤„ç†ç®¡é“"""
        test_results: Dict[str, Any] = {
            "adapter_type": "AsyncAudioProcessorAdapter",
            "async_mode": self.use_async,
            "test_time": time.time(),
            "tests": {}
        }
        # æ˜ç¡®æŒ‡å®štestsæ˜¯å­—å…¸ç±»å‹
        tests: Dict[str, Dict[str, Any]] = test_results["tests"]

        try:
            # æµ‹è¯•æ•°å€¼æå–
            test_text = "äºŒåäº”ç‚¹äº”"
            measurements = self.extract_measurements(test_text)
            tests["number_extraction"] = {
                "input": test_text,
                "output": measurements,
                "success": len(measurements) > 0
            }

            # æµ‹è¯•çŠ¶æ€è·å–
            state = self.get_state()
            tests["state_check"] = {
                "state": state.name,
                "success": True
            }

            # æµ‹è¯•éŸ³é¢‘å‚æ•°
            params = self.get_audio_parameters()
            tests["audio_parameters"] = {
                "parameters": params,
                "success": len(params) > 0
            }

            # æµ‹è¯•TTSçŠ¶æ€
            tts_enabled = self.is_tts_enabled()
            tests["tts_status"] = {
                "enabled": tts_enabled,
                "success": True
            }

            # å¼‚æ­¥æ¨¡å¼é¢å¤–æµ‹è¯•
            if self.use_async and self._async_initialized:
                stats = self._async_capture.get_statistics()
                tests["async_stats"] = {
                    "statistics": stats,
                    "success": True
                }

            test_results["overall_success"] = all(
                test["success"] for test in tests.values()
            )

        except Exception as e:
            test_results["error"] = str(e)
            test_results["overall_success"] = False

        return test_results

    def cleanup(self):
        """åŒæ­¥æ¸…ç†èµ„æºï¼ˆå…¼å®¹æ€§ï¼‰"""
        try:
            # æ£€æŸ¥æ˜¯å¦æœ‰äº‹ä»¶å¾ªç¯åœ¨è¿è¡Œ
            try:
                loop = asyncio.get_event_loop()
                if loop.is_running():
                    # å¦‚æœæœ‰äº‹ä»¶å¾ªç¯åœ¨è¿è¡Œï¼Œåˆ›å»ºæ¸…ç†ä»»åŠ¡
                    asyncio.create_task(self.cleanup_async())
                else:
                    # å¦‚æœæ²¡æœ‰äº‹ä»¶å¾ªç¯ï¼Œè¿è¡Œæ¸…ç†
                    loop.run_until_complete(self.cleanup_async())
            except RuntimeError:
                # å¦‚æœæ²¡æœ‰äº‹ä»¶å¾ªç¯ï¼Œåˆ›å»ºæ–°çš„æ¥æ‰§è¡Œæ¸…ç†
                asyncio.run(self.cleanup_async())

        except Exception as e:
            logger.error(f"âŒ åŒæ­¥æ¸…ç†å¤±è´¥: {e}")

    async def __aenter__(self):
        """å¼‚æ­¥ä¸Šä¸‹æ–‡ç®¡ç†å™¨å…¥å£"""
        await self.async_initialize()
        return self

    async def __aexit__(self, exc_type, exc_val, exc_tb):
        """å¼‚æ­¥ä¸Šä¸‹æ–‡ç®¡ç†å™¨å‡ºå£"""
        await self.cleanup_async()


# ä¾¿æ·å‡½æ•°

async def create_async_audio_processor_adapter(
    sample_rate: int = 16000,
    chunk_size: int = 8000,
    model_path: Optional[str] = None,
    timeout_seconds: int = 30,
    test_mode: bool = False,
    **kwargs
) -> AsyncAudioProcessorAdapter:
    """åˆ›å»ºå¼‚æ­¥éŸ³é¢‘å¤„ç†å™¨é€‚é…å™¨çš„ä¾¿æ·å‡½æ•°"""
    adapter = AsyncAudioProcessorAdapter(
        use_async=True,
        sample_rate=sample_rate,
        chunk_size=chunk_size,
        model_path=model_path,
        timeout_seconds=timeout_seconds,
        test_mode=test_mode,
        **kwargs
    )

    await adapter.async_initialize()
    return adapter


def create_hybrid_audio_processor_adapter(
    use_async: bool = True,
    **kwargs
) -> AsyncAudioProcessorAdapter:
    """åˆ›å»ºæ··åˆæ¨¡å¼éŸ³é¢‘å¤„ç†å™¨é€‚é…å™¨çš„ä¾¿æ·å‡½æ•°"""
    return AsyncAudioProcessorAdapter(
        use_async=use_async,
        **kwargs
    )