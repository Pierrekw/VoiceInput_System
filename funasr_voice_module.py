#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
FunASRè¯­éŸ³è¯†åˆ«æ¨¡å—
åŸºäºFunASRçš„è¯­éŸ³å½•å…¥å’Œè¯†åˆ«åŠŸèƒ½ï¼Œå¯ä½œä¸ºæ¨¡å—å¯¼å…¥ä½¿ç”¨
ç»“åˆVADã€æµå¼è¯†åˆ«å’Œå¤šç§ä¼˜åŒ–ç­–ç•¥

ä½¿ç”¨ç¤ºä¾‹:
    from funasr_voice_module import FunASRVoiceRecognizer

    recognizer = FunASRVoiceRecognizer()
    recognizer.initialize()
    result = recognizer.recognize_speech(duration=10)
    print(f"è¯†åˆ«ç»“æœ: {result}")
"""

import os
import sys
import warnings

# å½»åº•æŠ‘åˆ¶FunASRçš„è¿›åº¦æ¡å’Œè°ƒè¯•è¾“å‡º
os.environ['TQDM_DISABLE'] = '1'
os.environ['PYTHONWARNINGS'] = 'ignore'
os.environ['HIDE_PROGRESS'] = '1'
os.environ['FUNASR_LOG_LEVEL'] = 'ERROR'

# é…ç½®æ—¥å¿—çº§åˆ«ï¼Œåªæ˜¾ç¤ºé”™è¯¯
import logging
logging.getLogger("funasr").setLevel(logging.ERROR)
logging.getLogger("modelscope").setLevel(logging.ERROR)
logging.getLogger("transformers").setLevel(logging.ERROR)

warnings.filterwarnings('ignore')

# ============================================================================
# ğŸ”§ å…³é”®ï¼šFFmpegç¯å¢ƒå¿…é¡»åœ¨FunASRå¯¼å…¥å‰è®¾ç½®
# ============================================================================
def setup_ffmpeg_environment():
    """è®¾ç½®FFmpegç¯å¢ƒï¼ˆå¿…é¡»åœ¨å¯¼å…¥FunASRä¹‹å‰è°ƒç”¨ï¼‰"""
    # æ–¹æ³•1ï¼šä½¿ç”¨ç¯å¢ƒå˜é‡æ°¸ä¹…è®¾ç½®ï¼ˆæœ€å¿«ï¼‰
    # å¦‚æœå·²ç»è®¾ç½®è¿‡FFmpegè·¯å¾„ï¼Œç›´æ¥è·³è¿‡
    if os.environ.get('FFMPEG_PATH_SET') == '1':
        return True
    
    try:
        # æ–¹æ³•2ï¼šé…ç½®å›ºå®šè·¯å¾„ï¼ˆæ¨èç”¨äºå¿«é€Ÿå¯åŠ¨ï¼‰
        # è¿™é‡Œè®¾ç½®ä¸€ä¸ªå›ºå®šçš„FFmpegè·¯å¾„ï¼Œé¿å…å¤šæ¬¡æ£€æŸ¥
        # ç”¨æˆ·å¯ä»¥æ ¹æ®å®é™…æƒ…å†µä¿®æ”¹è¿™ä¸ªè·¯å¾„
        FIXED_FFMPEG_PATH = "F:/onnx_deps/ffmpeg-master-latest-win64-gpl-shared/bin"
        
        if FIXED_FFMPEG_PATH and os.path.exists(FIXED_FFMPEG_PATH):
            current_path = os.environ.get('PATH', '')
            if FIXED_FFMPEG_PATH not in current_path:
                os.environ['PATH'] = FIXED_FFMPEG_PATH + os.pathsep + current_path
            # æ ‡è®°FFmpegè·¯å¾„å·²è®¾ç½®
            os.environ['FFMPEG_PATH_SET'] = '1'
            return True
        
        # æ–¹æ³•3ï¼šå¿«é€Ÿæ£€æŸ¥ï¼ˆä»…æ£€æŸ¥æœ€å¯èƒ½çš„ä½ç½®ï¼‰
        script_dir = os.path.dirname(os.path.abspath(__file__))
        fast_check_paths = [
            # ä¸»è¦æ£€æŸ¥FunASR_Deploymentç›®å½•
            os.path.join(script_dir, "FunASR_Deployment", "dependencies",
                        "ffmpeg-master-latest-win64-gpl-shared", "bin"),
        ]
        
        for ffmpeg_path in fast_check_paths:
            if os.path.exists(ffmpeg_path):
                current_path = os.environ.get('PATH', '')
                if ffmpeg_path not in current_path:
                    os.environ['PATH'] = ffmpeg_path + os.pathsep + current_path
                os.environ['FFMPEG_PATH_SET'] = '1'
                return True
        
        # æ³¨æ„ï¼šç³»ç»ŸPATHæ£€æŸ¥å·²ç§»é™¤ï¼Œå› ä¸ºå®ƒè¾ƒæ…¢
        # å»ºè®®ï¼šå°†FFmpegæ·»åŠ åˆ°ç³»ç»Ÿç¯å¢ƒå˜é‡PATHä¸­
        print("âš ï¸ æœªæ‰¾åˆ°FFmpegå¿«é€Ÿè·¯å¾„")
        print("ğŸ’¡ æ€§èƒ½ä¼˜åŒ–å»ºè®®ï¼š")
        print("  1. å°†FFmpegå®‰è£…åˆ°ç³»ç»ŸPATHç¯å¢ƒå˜é‡ä¸­")
        print(f"  2. æˆ–ä¿®æ”¹ä»£ç ä¸­çš„FIXED_FFMPEG_PATHä¸ºæ‚¨çš„FFmpegè·¯å¾„")
        
        return False

    except Exception:
        # é™é»˜å¤±è´¥ï¼Œé¿å…å½±å“å¯åŠ¨é€Ÿåº¦
        return False

# ç«‹å³æ‰§è¡ŒFFmpegç¯å¢ƒè®¾ç½®
setup_ffmpeg_environment()

# ============================================================================
# ğŸ“¦ å¯¼å…¥å…¶ä»–ä¾èµ–
# ============================================================================
import io
import time
import logging
import numpy as np
import pyaudio
import threading
from contextlib import contextmanager
from typing import List, Dict, Optional, Callable, Union, Tuple, Any
from dataclasses import dataclass
from collections import deque

# é…ç½®æ—¥å¿—
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s',
    datefmt='%Y-%m-%d %H:%M:%S'
)
logger = logging.getLogger(__name__)

# å…¨å±€å¯ç”¨æ€§æ£€æŸ¥
FUNASR_AVAILABLE = False
PYAUDIO_AVAILABLE = False
NUMPY_AVAILABLE = False

# æ£€æŸ¥ä¾èµ–
try:
    import numpy as np
    NUMPY_AVAILABLE = True
except ImportError:
    logger.error("âŒ numpy ä¸å¯ç”¨ï¼Œè¯·å®‰è£…: pip install numpy")
    # ä¸è®¾ç½® np å˜é‡ï¼Œé¿å…ç±»å‹å†²çª

try:
    import pyaudio
    PYAUDIO_AVAILABLE = True
except ImportError:
    logger.error("âŒ pyaudio ä¸å¯ç”¨ï¼Œè¯·å®‰è£…: pip install pyaudio")

try:
    from funasr import AutoModel
    FUNASR_AVAILABLE = True
    logger.info("âœ… FunASR æ¨¡å—å¯ç”¨")
except ImportError as e:
    logger.error(f"âŒ FunASR ä¸å¯ç”¨: {e}")
    AutoModel = None

@dataclass
class RecognitionResult:
    """è¯­éŸ³è¯†åˆ«ç»“æœæ•°æ®ç±»"""
    text: str                    # æœ€ç»ˆè¯†åˆ«æ–‡æœ¬
    partial_results: List[str]   # éƒ¨åˆ†è¯†åˆ«ç»“æœåˆ—è¡¨
    confidence: float            # ç½®ä¿¡åº¦
    duration: float              # è¯†åˆ«æ—¶é•¿
    timestamp: float             # æ—¶é—´æˆ³
    audio_buffer: List[np.ndarray]  # éŸ³é¢‘ç¼“å†²åŒº

@dataclass
class VADConfig:
    """VADé…ç½®"""
    energy_threshold: float = 0.015
    min_speech_duration: float = 0.3
    min_silence_duration: float = 0.6
    speech_padding: float = 0.3

@dataclass
class FunASRConfig:
    """FunASRé…ç½®"""
    model_path: str = "f:/04_AI/01_Workplace/Voice_Input/model/fun"
    device: str = "cpu"
    chunk_size: Optional[List[int]] = None
    encoder_chunk_look_back: int = 4
    decoder_chunk_look_back: int = 1
    disable_update: bool = True
    trust_remote_code: bool = False

    def __post_init__(self):
        if self.chunk_size is None:
            self.chunk_size = [0, 10, 5]  # é»˜è®¤æµå¼å‚æ•°

class FunASRVoiceRecognizer:
    """
    FunASRè¯­éŸ³è¯†åˆ«å™¨ä¸»ç±»
    æä¾›è¯­éŸ³å½•å…¥ã€è¯†åˆ«å’ŒVADåŠŸèƒ½
    """

    def __init__(self,
                 model_path: Optional[str] = None,
                 device: str = "cpu",
                 sample_rate: int = 16000,
                 chunk_size: int = 1600,
                 silent_mode: bool = True):
        """
        åˆå§‹åŒ–è¯­éŸ³è¯†åˆ«å™¨

        Args:
            model_path: FunASRæ¨¡å‹è·¯å¾„
            device: è®¾å¤‡ç±»å‹ ("cpu" æˆ– "cuda")
            sample_rate: éŸ³é¢‘é‡‡æ ·ç‡
            chunk_size: éŸ³é¢‘å—å¤§å°
            silent_mode: é™é»˜æ¨¡å¼ï¼Œéšè—ä¸­é—´è¿‡ç¨‹ä¿¡æ¯
        """
        # åŸºç¡€é…ç½®
        self.sample_rate = sample_rate
        self.chunk_size = chunk_size
        self.model_path = model_path or "./model/fun"
        self.silent_mode = silent_mode

        # FunASRé…ç½®
        self.funasr_config = FunASRConfig(
            model_path=self.model_path,
            device=device
        )

        # VADé…ç½®
        self.vad_config = VADConfig()

        # æ¨¡å‹ç›¸å…³
        self._model: Optional[Any] = None
        self._model_loaded = False
        self._model_load_time = 0.0

        # è¿è¡ŒçŠ¶æ€
        self._is_initialized = False
        self._is_running = False
        self._stop_event = threading.Event()
        self._speech_detected = False

        # éŸ³é¢‘å¤„ç†
        self._audio_buffer: deque[np.ndarray] = deque(maxlen=sample_rate * 5)  # 5ç§’ç¼“å†²
        self._speech_buffer: List[np.ndarray] = []
        self._funasr_cache: Dict[str, Any] = {}

        # è¯†åˆ«ç»“æœ
        self._current_text = ""
        self._partial_results: List[str] = []
        self._final_results: List[RecognitionResult] = []

        # ç»Ÿè®¡ä¿¡æ¯
        self.stats = {
            'total_recognitions': 0,
            'successful_recognitions': 0,
            'total_audio_time': 0.0,
            'total_processing_time': 0.0,
            'average_confidence': 0.0
        }

        # å›è°ƒå‡½æ•°
        self._on_partial_result: Optional[Callable[[str], None]] = None
        self._on_final_result: Optional[Callable[[RecognitionResult], None]] = None
        self._on_vad_event: Optional[Callable[[str, Dict], None]] = None

    def set_callbacks(self,
                     on_partial_result: Optional[Callable[[str], None]] = None,
                     on_final_result: Optional[Callable[[RecognitionResult], None]] = None,
                     on_vad_event: Optional[Callable[[str, Dict], None]] = None):
        """
        è®¾ç½®å›è°ƒå‡½æ•°

        Args:
            on_partial_result: éƒ¨åˆ†ç»“æœå›è°ƒ
            on_final_result: æœ€ç»ˆç»“æœå›è°ƒ
            on_vad_event: VADäº‹ä»¶å›è°ƒ
        """
        self._on_partial_result = on_partial_result
        self._on_final_result = on_final_result
        self._on_vad_event = on_vad_event

    def setup_environment(self) -> bool:
        """è®¾ç½®è¿è¡Œç¯å¢ƒ"""
        try:
            # è®¾ç½®FFmpegè·¯å¾„ï¼ˆå¦‚æœéœ€è¦ï¼‰
            script_dir = os.path.dirname(os.path.abspath(__file__))
            local_ffmpeg_bin = os.path.join(script_dir, "FunASR_Deployment",
                                          "dependencies", "ffmpeg-master-latest-win64-gpl-shared", "bin")

            if os.path.exists(local_ffmpeg_bin):
                current_path = os.environ.get('PATH', '')
                if local_ffmpeg_bin not in current_path:
                    os.environ['PATH'] = local_ffmpeg_bin + os.pathsep + current_path
                    logger.info(f"ğŸ”§ è®¾ç½®æœ¬åœ°FFmpeg: {local_ffmpeg_bin}")

            return True

        except Exception as e:
            logger.warning(f"ç¯å¢ƒè®¾ç½®å¤±è´¥: {e}")
            return False

    def check_dependencies(self) -> bool:
        """æ£€æŸ¥ä¾èµ–æ˜¯å¦æ»¡è¶³"""
        missing_deps = []

        if not NUMPY_AVAILABLE:
            missing_deps.append("numpy")
        if not PYAUDIO_AVAILABLE:
            missing_deps.append("pyaudio")
        if not FUNASR_AVAILABLE:
            missing_deps.append("funasr")

        if missing_deps:
            logger.error(f"âŒ ç¼ºå°‘ä¾èµ–: {', '.join(missing_deps)}")
            logger.error("è¯·æ‰§è¡Œ: pip install " + " ".join(missing_deps))
            return False

        return True

    def initialize(self) -> bool:
        """åˆå§‹åŒ–è¯†åˆ«å™¨"""
        if self._is_initialized:
            logger.info("âœ… è¯†åˆ«å™¨å·²åˆå§‹åŒ–")
            return True

        logger.info("ğŸš€ åˆå§‹åŒ–FunASRè¯­éŸ³è¯†åˆ«å™¨...")

        # æ£€æŸ¥ä¾èµ–
        if not self.check_dependencies():
            return False

        # è®¾ç½®ç¯å¢ƒ
        self.setup_environment()

        # åŠ è½½æ¨¡å‹
        if not self._load_model():
            return False

        self._is_initialized = True
        logger.info("âœ… FunASRè¯­éŸ³è¯†åˆ«å™¨åˆå§‹åŒ–å®Œæˆ")
        return True

    def _load_model(self) -> bool:
        """åŠ è½½FunASRæ¨¡å‹"""
        if self._model_loaded:
            return True

        if not FUNASR_AVAILABLE:
            logger.error("âŒ FunASRä¸å¯ç”¨")
            return False

        logger.info(f"ğŸ“¦ åŠ è½½FunASRæ¨¡å‹: {self.model_path}")
        start_time = time.time()

        try:
            # æ£€æŸ¥æ¨¡å‹è·¯å¾„
            if not os.path.exists(self.model_path):
                logger.error(f"âŒ æ¨¡å‹è·¯å¾„ä¸å­˜åœ¨: {self.model_path}")
                return False

            # åŠ è½½æ¨¡å‹
            self._model = AutoModel(
                model=self.funasr_config.model_path,
                device=self.funasr_config.device,
                trust_remote_code=self.funasr_config.trust_remote_code,
                disable_update=self.funasr_config.disable_update
            )

            self._model_loaded = True
            self._model_load_time = time.time() - start_time

            logger.info(f"âœ… æ¨¡å‹åŠ è½½æˆåŠŸ (è€—æ—¶: {self._model_load_time:.2f}ç§’)")
            return True

        except Exception as e:
            logger.error(f"âŒ æ¨¡å‹åŠ è½½å¤±è´¥: {e}")
            import traceback
            logger.error(f"è¯¦ç»†é”™è¯¯: {traceback.format_exc()}")
            return False

    def unload_model(self):
        """å¸è½½æ¨¡å‹é‡Šæ”¾å†…å­˜"""
        if self._model:
            self._model = None
            self._model_loaded = False
            import gc
            gc.collect()
            logger.info("ğŸ§¹ æ¨¡å‹å·²å¸è½½")

    @contextmanager
    def _audio_stream(self):
        """éŸ³é¢‘æµä¸Šä¸‹æ–‡ç®¡ç†å™¨ï¼Œå¢å¼ºå¼‚å¸¸å¤„ç†å’Œé‡è¿æœºåˆ¶"""
        if not PYAUDIO_AVAILABLE:
            raise RuntimeError("PyAudioä¸å¯ç”¨")

        max_retries = 3
        retry_count = 0

        while retry_count < max_retries:
            p = None
            stream = None

            try:
                p = pyaudio.PyAudio()

                # è·å–é»˜è®¤éŸ³é¢‘è®¾å¤‡
                try:
                    default_device = p.get_default_input_device_info()
                    logger.info(f"ğŸ¤ ä½¿ç”¨éŸ³é¢‘è®¾å¤‡: {default_device['name']} (ç´¢å¼•: {default_device['index']})")
                except Exception as device_error:
                    logger.error(f"âŒ æ— æ³•è·å–éŸ³é¢‘è®¾å¤‡ä¿¡æ¯: {device_error}")
                    raise RuntimeError("éŸ³é¢‘è®¾å¤‡ä¸å¯ç”¨")

                # æ‰“å¼€éŸ³é¢‘æµï¼Œå¢åŠ é”™è¯¯å®¹é”™
                stream = p.open(
                    format=pyaudio.paInt16,
                    channels=1,
                    rate=self.sample_rate,
                    input=True,
                    input_device_index=default_device['index'],
                    frames_per_buffer=self.chunk_size,
                    start=True
                )

                # éªŒè¯éŸ³é¢‘æµæ˜¯å¦æ­£å¸¸å·¥ä½œ
                if not stream.is_active():
                    raise RuntimeError("éŸ³é¢‘æµåˆ›å»ºå¤±è´¥ï¼šæµæœªæ¿€æ´»")

                logger.info(f"ğŸ§ éŸ³é¢‘æµåˆ›å»ºæˆåŠŸ (é‡è¯• {retry_count + 1}/{max_retries})")
                yield stream
                break  # æˆåŠŸåˆ™é€€å‡ºé‡è¯•å¾ªç¯

            except Exception as e:
                retry_count += 1
                error_msg = f"âŒ éŸ³é¢‘æµåˆ›å»ºå¤±è´¥ (é‡è¯• {retry_count}/{max_retries}): {e}"

                if retry_count >= max_retries:
                    logger.error(error_msg + " - å·²è¾¾åˆ°æœ€å¤§é‡è¯•æ¬¡æ•°")
                    raise RuntimeError(f"éŸ³é¢‘æµåˆ›å»ºå¤±è´¥ï¼Œå·²é‡è¯•{max_retries}æ¬¡: {e}")
                else:
                    logger.warning(error_msg + " - æ­£åœ¨é‡è¯•...")
                    time.sleep(1)  # é‡è¯•å‰ç­‰å¾…1ç§’

            finally:
                # ç¡®ä¿èµ„æºæ­£ç¡®é‡Šæ”¾
                if stream:
                    try:
                        if stream.is_active():
                            stream.stop_stream()
                        stream.close()
                    except Exception as cleanup_error:
                        logger.warning(f"âš ï¸ éŸ³é¢‘æµæ¸…ç†å¼‚å¸¸: {cleanup_error}")

                if p:
                    try:
                        p.terminate()
                    except Exception as cleanup_error:
                        logger.warning(f"âš ï¸ PyAudioæ¸…ç†å¼‚å¸¸: {cleanup_error}")

    def _detect_vad(self, audio_data: np.ndarray, current_time: float) -> Tuple[bool, Optional[str]]:
        """
        VADè¯­éŸ³æ´»åŠ¨æ£€æµ‹

        Args:
            audio_data: éŸ³é¢‘æ•°æ®
            current_time: å½“å‰æ—¶é—´

        Returns:
            (is_speech, event_type): æ˜¯å¦æœ‰è¯­éŸ³å’Œäº‹ä»¶ç±»å‹
        """
        # è®¡ç®—éŸ³é¢‘èƒ½é‡
        energy = np.sqrt(np.mean(audio_data ** 2))

        # ç®€å•çš„èƒ½é‡é˜ˆå€¼VAD
        is_speech = energy > self.vad_config.energy_threshold

        event_type = None
        if is_speech:
            if not hasattr(self, '_speech_detected') or not self._speech_detected:
                event_type = "speech_start"
                self._speech_detected = True
                self._speech_start_time = current_time
        else:
            if hasattr(self, '_speech_detected') and self._speech_detected:
                silence_duration = current_time - getattr(self, '_last_speech_time', current_time)
                if silence_duration >= self.vad_config.min_silence_duration:
                    event_type = "speech_end"
                    self._speech_detected = False

        if is_speech:
            self._last_speech_time = current_time

        return is_speech, event_type

    def _process_audio_chunk(self, audio_data: np.ndarray, current_time: float):
        """
        å¤„ç†éŸ³é¢‘å—

        Args:
            audio_data: éŸ³é¢‘æ•°æ®
            current_time: å½“å‰æ—¶é—´
        """
        # æ·»åŠ åˆ°éŸ³é¢‘ç¼“å†²åŒº
        self._audio_buffer.extend(audio_data)

        # VADæ£€æµ‹
        is_speech, vad_event = self._detect_vad(audio_data, current_time)

        if vad_event and self._on_vad_event:
            self._on_vad_event(vad_event, {
                'time': current_time,
                'energy': np.sqrt(np.mean(audio_data ** 2))
            })

        # å¦‚æœæ£€æµ‹åˆ°è¯­éŸ³ï¼Œæ·»åŠ åˆ°è¯­éŸ³ç¼“å†²åŒº
        if is_speech:
            self._speech_buffer.extend(audio_data)

            # å®šæœŸè¿›è¡Œæµå¼è¯†åˆ«
            if len(self._speech_buffer) >= self.sample_rate * 1:  # 1ç§’éŸ³é¢‘
                self._perform_streaming_recognition()
        else:
            # å¦‚æœé™éŸ³æ—¶é—´è¶³å¤Ÿé•¿ä¸”æœ‰è¯­éŸ³ç¼“å†²åŒºï¼Œè¿›è¡Œæœ€ç»ˆè¯†åˆ«
            if (len(self._speech_buffer) > 0 and
                hasattr(self, '_last_speech_time') and
                current_time - self._last_speech_time >= self.vad_config.min_silence_duration):

                if len(self._speech_buffer) >= self.sample_rate * self.vad_config.min_speech_duration:
                    self._perform_final_recognition()

    def _perform_streaming_recognition(self):
        """æ‰§è¡Œæµå¼è¯†åˆ«"""
        if not self._model or not self._model_loaded:
            return

        try:
            # å–æœ€è¿‘çš„éŸ³é¢‘æ•°æ®è¿›è¡Œè¯†åˆ«
            audio_array = np.array(list(self._speech_buffer))

            result = self._model.generate(
                input=audio_array,
                cache=self._funasr_cache,
                is_final=False,
                chunk_size=self.funasr_config.chunk_size,
                encoder_chunk_look_back=self.funasr_config.encoder_chunk_look_back,
                decoder_chunk_look_back=self.funasr_config.decoder_chunk_look_back
            )

            if result and isinstance(result, list) and len(result) > 0:
                text = result[0].get("text", "").strip()
                if text and text != self._current_text:
                    self._current_text = text
                    self._partial_results.append(text)

                    # è§¦å‘éƒ¨åˆ†ç»“æœå›è°ƒ
                    if self._on_partial_result:
                        self._on_partial_result(text)

                    if not self.silent_mode:
                        logger.info(f"ğŸ—£ï¸ æµå¼è¯†åˆ«: '{text}'")

        except Exception as e:
            logger.debug(f"æµå¼è¯†åˆ«å¼‚å¸¸: {e}")

    def _perform_final_recognition(self):
        """æ‰§è¡Œæœ€ç»ˆè¯†åˆ«"""
        if not self._model or not self._model_loaded or not self._speech_buffer:
            return

        try:
            start_time = time.time()

            audio_array = np.array(list(self._speech_buffer))

            result = self._model.generate(
                input=audio_array,
                cache=self._funasr_cache,
                is_final=True,
                chunk_size=self.funasr_config.chunk_size,
                encoder_chunk_look_back=self.funasr_config.encoder_chunk_look_back,
                decoder_chunk_look_back=self.funasr_config.decoder_chunk_look_back
            )

            processing_time = time.time() - start_time

            if result and isinstance(result, list) and len(result) > 0:
                text = result[0].get("text", "").strip()
                if text:
                    # åˆ›å»ºè¯†åˆ«ç»“æœ
                    recognition_result = RecognitionResult(
                        text=text,
                        partial_results=self._partial_results.copy(),
                        confidence=0.9,  # FunASRæš‚ä¸æä¾›ç½®ä¿¡åº¦ï¼Œä½¿ç”¨é»˜è®¤å€¼
                        duration=len(self._speech_buffer) / self.sample_rate,
                        timestamp=time.time(),
                        audio_buffer=self._speech_buffer.copy()
                    )

                    self._final_results.append(recognition_result)
                    self.stats['total_recognitions'] += 1
                    self.stats['successful_recognitions'] += 1
                    self.stats['total_processing_time'] += processing_time

                    # è§¦å‘æœ€ç»ˆç»“æœå›è°ƒ
                    if self._on_final_result:
                        self._on_final_result(recognition_result)

                    if not self.silent_mode:
                        logger.info(f"âœ… æœ€ç»ˆè¯†åˆ«: '{text}' (è€—æ—¶: {processing_time:.3f}s)")

        except Exception as e:
            logger.error(f"æœ€ç»ˆè¯†åˆ«å¼‚å¸¸: {e}")
        finally:
            # æ¸…ç©ºè¯­éŸ³ç¼“å†²åŒº
            self._speech_buffer = []
            self._current_text = ""

    def recognize_speech(self, duration: int = 10,
                        real_time_display: bool = True) -> RecognitionResult:
        """
        è¯†åˆ«è¯­éŸ³ï¼ˆåŒæ­¥æ¨¡å¼ï¼‰

        Args:
            duration: è¯†åˆ«æ—¶é•¿ï¼ˆç§’ï¼‰
            real_time_display: æ˜¯å¦å®æ—¶æ˜¾ç¤ºè¯†åˆ«ç»“æœ

        Returns:
            RecognitionResult: è¯†åˆ«ç»“æœ
        """
        if not self._is_initialized:
            if not self.initialize():
                raise RuntimeError("åˆå§‹åŒ–å¤±è´¥")

        if not self.silent_mode:
            logger.info(f"ğŸ™ï¸ å¼€å§‹è¯­éŸ³è¯†åˆ«ï¼Œæ—¶é•¿: {duration}ç§’")

        # é‡ç½®çŠ¶æ€
        self._stop_event.clear()
        self._audio_buffer.clear()
        self._speech_buffer = []
        self._current_text = ""
        self._partial_results = []

        start_time = time.time()

        try:
            with self._audio_stream() as stream:
                # æ”¯æŒduration=-1è¡¨ç¤ºæ— é™æ—¶æ¨¡å¼
                while (duration == -1 or time.time() - start_time < duration) and not self._stop_event.is_set():
                    try:
                        # è¯»å–éŸ³é¢‘æ•°æ®
                        data = stream.read(self.chunk_size, exception_on_overflow=False)
                        current_time = time.time() - start_time

                        # è½¬æ¢ä¸ºnumpyæ•°ç»„
                        audio_data = np.frombuffer(data, dtype=np.int16).astype(np.float32) / 32768.0

                        # å¤„ç†éŸ³é¢‘
                        self._process_audio_chunk(audio_data, current_time)

                        # å®æ—¶æ˜¾ç¤º
                        if real_time_display and self._current_text:
                            if duration == -1:
                                # æ— é™æ—¶æ¨¡å¼ï¼šæ˜¾ç¤ºè¿è¡Œæ—¶é—´
                                print(f"\rğŸ—£ï¸ è¯†åˆ«ä¸­: '{self._current_text}' | è¿è¡Œæ—¶é—´: {current_time:.1f}s",
                                     end="", flush=True)
                            else:
                                # é™æ—¶æ¨¡å¼ï¼šæ˜¾ç¤ºå‰©ä½™æ—¶é—´
                                remaining = duration - current_time
                                print(f"\rğŸ—£ï¸ è¯†åˆ«ä¸­: '{self._current_text}' | å‰©ä½™: {remaining:.1f}s",
                                     end="", flush=True)

                    except OSError as audio_error:
                        # ä¸“é—¨å¤„ç†éŸ³é¢‘æµç›¸å…³çš„ç³»ç»Ÿé”™è¯¯
                        logger.error(f"ğŸ¤ éŸ³é¢‘æµå¼‚å¸¸: {audio_error}")
                        # æ£€æŸ¥æ˜¯å¦æ˜¯è®¾å¤‡æ–­å¼€è¿æ¥
                        if "Input overflowed" in str(audio_error):
                            logger.warning("âš ï¸ éŸ³é¢‘ç¼“å†²åŒºæº¢å‡ºï¼Œç»§ç»­å¤„ç†...")
                            continue
                        elif "No such device" in str(audio_error) or "Device unavailable" in str(audio_error):
                            logger.error("âŒ éŸ³é¢‘è®¾å¤‡æ–­å¼€è¿æ¥æˆ–ä¸å¯ç”¨")
                            raise RuntimeError("éŸ³é¢‘è®¾å¤‡æ–­å¼€è¿æ¥")
                        else:
                            logger.warning(f"âš ï¸ éŸ³é¢‘æµé”™è¯¯ï¼Œå°è¯•ç»§ç»­: {audio_error}")
                            continue

                    except Exception as e:
                        logger.error(f"âŒ éŸ³é¢‘å¤„ç†é”™è¯¯: {e}")
                        # å¯¹äºå…¶ä»–å¼‚å¸¸ï¼Œè®°å½•è¯¦ç»†ä¿¡æ¯ä½†å°è¯•ç»§ç»­
                        import traceback
                        logger.debug(f"é”™è¯¯è¯¦æƒ…: {traceback.format_exc()}")
                        continue

                # å¤„ç†æœ€åçš„éŸ³é¢‘
                if self._speech_buffer:
                    self._perform_final_recognition()

        except KeyboardInterrupt:
            logger.info("â¹ï¸ è¯†åˆ«è¢«ç”¨æˆ·ä¸­æ–­ (KeyboardInterrupt)")
        except Exception as e:
            logger.error(f"âŒ è¯†åˆ«è¿‡ç¨‹å‡ºé”™: {e}")
            raise

        # è®°å½•è¯†åˆ«ç»“æŸåŸå› 
        end_time = time.time()
        actual_duration = end_time - start_time

        if self._stop_event.is_set():
            logger.info(f"â¹ï¸ è¯†åˆ«è¢«ç³»ç»Ÿåœæ­¢ä¿¡å·ä¸­æ–­ (è¿è¡Œæ—¶é—´: {actual_duration:.2f}ç§’)")
        elif duration == -1:
            logger.info(f"â¹ï¸ æ— é™æ—¶æ¨¡å¼è¯†åˆ«ç»“æŸ (è¿è¡Œæ—¶é—´: {actual_duration:.2f}ç§’)")
        elif actual_duration >= duration:
            logger.info(f"â¹ï¸ è¯†åˆ«è¾¾åˆ°æŒ‡å®šæ—¶é•¿ (è®¾å®š: {duration}ç§’, å®é™…: {actual_duration:.2f}ç§’)")
        else:
            logger.info(f"â¹ï¸ è¯†åˆ«æå‰ç»“æŸ (è®¾å®š: {duration}ç§’, å®é™…: {actual_duration:.2f}ç§’)")

        # è¿”å›æœ€ç»ˆç»“æœ
        if self._final_results:
            final_result = self._final_results[-1]
            print(f"\nâœ… è¯†åˆ«å®Œæˆ: '{final_result.text}'")
            return final_result
        else:
            # å¦‚æœæ²¡æœ‰æœ€ç»ˆç»“æœï¼Œä½¿ç”¨éƒ¨åˆ†ç»“æœ
            if self._partial_results:
                text = self._partial_results[-1] if self._partial_results else ""
                result = RecognitionResult(
                    text=text,
                    partial_results=self._partial_results,
                    confidence=0.5,
                    duration=duration,
                    timestamp=time.time(),
                    audio_buffer=[]
                )
                print(f"\nâš ï¸ æ— æœ€ç»ˆç»“æœï¼Œè¿”å›éƒ¨åˆ†ç»“æœ: '{text}'")
                return result
            else:
                logger.warning("âš ï¸ æœªè¯†åˆ«åˆ°ä»»ä½•è¯­éŸ³å†…å®¹")
                return RecognitionResult(
                    text="",
                    partial_results=[],
                    confidence=0.0,
                    duration=0.0,
                    timestamp=time.time(),
                    audio_buffer=[]
                )

    def start_continuous_recognition(self):
        """å¼€å§‹è¿ç»­è¯†åˆ«ï¼ˆå¼‚æ­¥æ¨¡å¼ï¼‰"""
        if not self._is_initialized:
            if not self.initialize():
                raise RuntimeError("åˆå§‹åŒ–å¤±è´¥")

        if self._is_running:
            logger.warning("âš ï¸ è¿ç»­è¯†åˆ«å·²åœ¨è¿è¡Œ")
            return

        logger.info("ğŸ”„ å¼€å§‹è¿ç»­è¯†åˆ«æ¨¡å¼")
        self._is_running = True
        self._stop_event.clear()

        def recognition_thread():
            try:
                with self._audio_stream() as stream:
                    while self._is_running and not self._stop_event.is_set():
                        try:
                            data = stream.read(self.chunk_size, exception_on_overflow=False)
                            current_time = time.time()

                            audio_data = np.frombuffer(data, dtype=np.int16).astype(np.float32) / 32768.0
                            self._process_audio_chunk(audio_data, current_time)

                        except OSError as audio_error:
                            # ä¸“é—¨å¤„ç†éŸ³é¢‘æµç›¸å…³çš„ç³»ç»Ÿé”™è¯¯
                            logger.error(f"ğŸ¤ è¿ç»­è¯†åˆ«éŸ³é¢‘æµå¼‚å¸¸: {audio_error}")

                            # æ£€æŸ¥ä¸¥é‡é”™è¯¯ç±»å‹
                            if "No such device" in str(audio_error) or "Device unavailable" in str(audio_error):
                                logger.error("âŒ éŸ³é¢‘è®¾å¤‡æ–­å¼€è¿æ¥ï¼Œåœæ­¢è¿ç»­è¯†åˆ«")
                                self._is_running = False
                                break
                            elif "Input overflowed" in str(audio_error):
                                logger.warning("âš ï¸ éŸ³é¢‘ç¼“å†²åŒºæº¢å‡ºï¼Œç»§ç»­å¤„ç†...")
                                continue
                            else:
                                logger.warning(f"âš ï¸ éŸ³é¢‘æµé”™è¯¯ï¼Œå°è¯•ç»§ç»­: {audio_error}")
                                continue

                        except Exception as e:
                            logger.error(f"âŒ è¿ç»­è¯†åˆ«é”™è¯¯: {e}")
                            import traceback
                            logger.debug(f"é”™è¯¯è¯¦æƒ…: {traceback.format_exc()}")
                            continue

            except Exception as e:
                logger.error(f"è¿ç»­è¯†åˆ«çº¿ç¨‹å¼‚å¸¸: {e}")
            finally:
                self._is_running = False
                logger.info("ğŸ”„ è¿ç»­è¯†åˆ«çº¿ç¨‹ç»“æŸ")

        # å¯åŠ¨è¯†åˆ«çº¿ç¨‹
        thread = threading.Thread(target=recognition_thread, daemon=True)
        thread.start()

        return thread

    def stop_recognition(self):
        """åœæ­¢è¯†åˆ«"""
        logger.info("â¹ï¸ åœæ­¢è¯†åˆ«")
        self._stop_event.set()
        self._is_running = False

        # å¤„ç†æœ€åçš„éŸ³é¢‘
        if self._speech_buffer:
            self._perform_final_recognition()

    def get_status(self) -> Dict[str, Any]:
        """è·å–è¯†åˆ«å™¨çŠ¶æ€"""
        return {
            'initialized': self._is_initialized,
            'model_loaded': self._model_loaded,
            'model_path': self.model_path,
            'device': self.funasr_config.device,
            'running': self._is_running,
            'stats': self.stats.copy(),
            'model_load_time': self._model_load_time,
            'dependencies': {
                'funasr': FUNASR_AVAILABLE,
                'pyaudio': PYAUDIO_AVAILABLE,
                'numpy': NUMPY_AVAILABLE
            }
        }

    def configure_vad(self, **kwargs):
        """é…ç½®VADå‚æ•°"""
        for key, value in kwargs.items():
            if hasattr(self.vad_config, key):
                setattr(self.vad_config, key, value)
                logger.info(f"ğŸ”§ VADé…ç½®æ›´æ–°: {key} = {value}")
            else:
                logger.warning(f"âš ï¸ æœªçŸ¥çš„VADå‚æ•°: {key}")

    def configure_funasr(self, **kwargs):
        """é…ç½®FunASRå‚æ•°"""
        for key, value in kwargs.items():
            if hasattr(self.funasr_config, key):
                setattr(self.funasr_config, key, value)
                logger.info(f"ğŸ”§ FunASRé…ç½®æ›´æ–°: {key} = {value}")
            else:
                logger.warning(f"âš ï¸ æœªçŸ¥çš„FunASRå‚æ•°: {key}")

    def __del__(self):
        """ææ„å‡½æ•°"""
        try:
            self.stop_recognition()
            self.unload_model()
        except:
            pass

# ä¾¿æ·å‡½æ•°
def create_recognizer(model_path: Optional[str] = None,
                     device: str = "cpu") -> FunASRVoiceRecognizer:
    """
    åˆ›å»ºå¹¶åˆå§‹åŒ–è¯­éŸ³è¯†åˆ«å™¨

    Args:
        model_path: æ¨¡å‹è·¯å¾„
        device: è®¾å¤‡ç±»å‹

    Returns:
        FunASRVoiceRecognizer: å·²åˆå§‹åŒ–çš„è¯†åˆ«å™¨
    """
    recognizer = FunASRVoiceRecognizer(model_path=model_path, device=device)
    if not recognizer.initialize():
        raise RuntimeError("è¯†åˆ«å™¨åˆå§‹åŒ–å¤±è´¥")
    return recognizer

def quick_recognize(duration: int = 10,
                   model_path: Optional[str] = None) -> str:
    """
    å¿«é€Ÿè¯­éŸ³è¯†åˆ«

    Args:
        duration: è¯†åˆ«æ—¶é•¿
        model_path: æ¨¡å‹è·¯å¾„

    Returns:
        str: è¯†åˆ«ç»“æœæ–‡æœ¬
    """
    recognizer = create_recognizer(model_path=model_path)
    result = recognizer.recognize_speech(duration=duration)
    return result.text

if __name__ == "__main__":
    # ç¤ºä¾‹ç”¨æ³•
    print("ğŸ¯ FunASRè¯­éŸ³è¯†åˆ«æ¨¡å—æµ‹è¯•")
    print("=" * 50)

    # åˆ›å»ºè¯†åˆ«å™¨
    recognizer = FunASRVoiceRecognizer()

    # è®¾ç½®å›è°ƒ
    def on_partial(text):
        print(f"ğŸ—£ï¸ å®æ—¶: {text}")

    def on_final(result):
        print(f"âœ… æœ€ç»ˆ: {result.text}")

    def on_vad(event, data):
        print(f"ğŸ¯ VAD: {event}")

    recognizer.set_callbacks(on_partial, on_final, on_vad)

    # åˆå§‹åŒ–
    if recognizer.initialize():
        print("âœ… è¯†åˆ«å™¨åˆå§‹åŒ–æˆåŠŸ")
        print(f"ğŸ“Š çŠ¶æ€: {recognizer.get_status()}")

        # è¿›è¡Œè¯†åˆ«æµ‹è¯•
        try:
            result = recognizer.recognize_speech(duration=15)
            print(f"\nğŸ¯ æœ€ç»ˆè¯†åˆ«ç»“æœ: '{result.text}'")
            print(f"ğŸ“Š è¯†åˆ«æ—¶é•¿: {result.duration:.2f}ç§’")
            print(f"ğŸ“Š éƒ¨åˆ†ç»“æœæ•°: {len(result.partial_results)}")
        except KeyboardInterrupt:
            print("\nâ¹ï¸ æµ‹è¯•è¢«ä¸­æ–­")
    else:
        print("âŒ è¯†åˆ«å™¨åˆå§‹åŒ–å¤±è´¥")