#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
FunASRæµ‹è¯•ç¨‹åº
ç”¨äºæµ‹è¯•FunASRæ¨¡å‹çš„åŠ è½½å’ŒåŸºæœ¬è¯­éŸ³è¯†åˆ«åŠŸèƒ½
"""

import os
import sys
import time
import logging
import pyaudio
import numpy as np
from contextlib import contextmanager

# é…ç½®æ—¥å¿—
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s',
    datefmt='%Y-%m-%d %H:%M:%S'
)
logger = logging.getLogger(__name__)

# å°è¯•å¯¼å…¥FunASR
FUNASR_AVAILABLE = False
try:
    from funasr import AutoModel
    from funasr.utils.postprocess_utils import rich_transcription_postprocess
    FUNASR_AVAILABLE = True
    logger.info("âœ… æˆåŠŸå¯¼å…¥FunASRæ¨¡å—")
except ImportError as e:
    logger.error(f"âŒ æ— æ³•å¯¼å…¥FunASRæ¨¡å—: {e}")
    logger.error("è¯·æ‰§è¡Œ: pip install funasr torch æˆ– uv add funasr torch å®‰è£…è¯¥æ¨¡å—")
    # å¯¼å…¥æ—¶ä½¿ç”¨ç±»å‹æ³¨è§£ï¼Œè¿è¡Œæ—¶ä¸å½±å“è¡Œä¸º
    AutoModel = None
    rich_transcription_postprocess = None

# éŸ³é¢‘æµä¸Šä¸‹æ–‡ç®¡ç†å™¨
@contextmanager
def audio_stream(sample_rate=16000, chunk_size=8000):
    """æ‰“å¼€PyAudioè¾“å…¥æµå¹¶è‡ªåŠ¨æ¸…ç†"""
    p = pyaudio.PyAudio()
    stream = None
    try:
        # è·å–é»˜è®¤éŸ³é¢‘è®¾å¤‡ä¿¡æ¯
        default_device = p.get_default_input_device_info()
        logger.info(f"ğŸ¤ ä½¿ç”¨éŸ³é¢‘è®¾å¤‡: {default_device['name']} (ç´¢å¼•: {default_device['index']})")

        # æ‰“å¼€éŸ³é¢‘æµ
        stream = p.open(
            format=pyaudio.paInt16,
            channels=1,
            rate=sample_rate,
            input=True,
            frames_per_buffer=chunk_size,
            start=True
        )
        logger.info(f"ğŸ§ éŸ³é¢‘æµåˆ›å»ºæˆåŠŸ - æ´»åŠ¨çŠ¶æ€: {stream.is_active()}")
        yield stream
    except Exception as e:
        logger.error(f"âŒ éŸ³é¢‘æµåˆ›å»ºå¤±è´¥: {e}")
        raise
    finally:
        # èµ„æºæ¸…ç†
        if stream:
            if stream.is_active():
                stream.stop_stream()
            stream.close()
        p.terminate()

class FunASRTest:
    """FunASRæµ‹è¯•ç±»"""
    
    def __init__(self, model_path="f:\\04_AI\\01_Workplace\\Voice_Input\\model\\fun", model_revision="v2.0.4"):
        """åˆå§‹åŒ–æµ‹è¯•ç±»
        
        Args:
            model_path: FunASRæ¨¡å‹è·¯å¾„
            model_revision: æ¨¡å‹ç‰ˆæœ¬
        """
        self.model_path = model_path
        self.model_revision = model_revision
        self._model = None
        self.model_loaded = False
        self.load_time = 0.0
        self.sample_rate = 16000
        self.chunk_size = 8000
        
    def load_model(self):
        """åŠ è½½FunASRæ¨¡å‹"""
        if not FUNASR_AVAILABLE:
            logger.error("âŒ FunASRæ¨¡å—ä¸å¯ç”¨ï¼Œæ— æ³•åŠ è½½æ¨¡å‹")
            return False
        
        if self.model_loaded and self._model is not None:
            logger.info("âœ… FunASRæ¨¡å‹å·²åŠ è½½ï¼Œæ— éœ€é‡å¤åŠ è½½")
            return True
        
        logger.info(f"ğŸ“¦ å¼€å§‹åŠ è½½FunASRæ¨¡å‹: {self.model_path} (ç‰ˆæœ¬: {self.model_revision})")
        start_time = time.time()
        
        try:
            # åˆ›å»ºFunASRæ¨¡å‹
            logger.info("ğŸ”„ æ­£åœ¨åˆå§‹åŒ–æ¨¡å‹...")
            logger.info(f"  - model: {self.model_path}")
            logger.info(f"  - model_revision: None (æœ¬åœ°æ¨¡å‹)")
            logger.info(f"  - device: cpu")
            logger.info("  - ä½¿ç”¨æœ¬åœ°æ¨¡å‹ï¼Œé¿å…ä¸‹è½½é¢å¤–æ–‡ä»¶")
            
            # ä½¿ç”¨æœ¬åœ°æ¨¡å‹ï¼Œä¸æŒ‡å®šé¢å¤–çš„vad_modelå’Œpunc_modelä»¥é¿å…ä¸‹è½½
            # æ ¹æ®configuration.jsonæ–‡ä»¶ï¼Œæ¨¡å‹åº”è¯¥å·²ç»åŒ…å«äº†æ‰€éœ€çš„ç»„ä»¶
            self._model = AutoModel(
                model=self.model_path,
                model_revision=None,  # æœ¬åœ°æ¨¡å‹ä¸éœ€è¦ç‰ˆæœ¬å·
                device="cpu",
                trust_remote_code=False  # ç¡®ä¿ä½¿ç”¨æœ¬åœ°ä»£ç 
            )
            
            self.model_loaded = True
            self.load_time = time.time() - start_time
            logger.info(f"âœ… FunASRæ¨¡å‹åŠ è½½å®Œæˆ (è€—æ—¶: {self.load_time:.2f}ç§’)")
            return True
            
        except Exception as e:
            logger.error(f"âŒ FunASRæ¨¡å‹åŠ è½½å¤±è´¥: {e}")
            import traceback
            logger.error(f"è¯¦ç»†é”™è¯¯ä¿¡æ¯:\n{traceback.format_exc()}")
            self._model = None
            self.model_loaded = False
            
            # åˆ†æå¯èƒ½çš„é”™è¯¯åŸå› 
            if "Could not find model" in str(e) or "No such file or directory" in str(e):
                logger.error("ğŸ’¡ å¯èƒ½çš„åŸå› : æ¨¡å‹è·¯å¾„ä¸å­˜åœ¨æˆ–æ¨¡å‹æœªä¸‹è½½")
                logger.error("   è¯·ç¡®ä¿æ¨¡å‹å·²æ­£ç¡®ä¸‹è½½åˆ°æŒ‡å®šè·¯å¾„")
            elif "CUDA" in str(e) or "GPU" in str(e).upper():
                logger.error("ğŸ’¡ å¯èƒ½çš„åŸå› : GPUç›¸å…³é”™è¯¯")
                logger.error("   è¯·ç¡®ä¿CUDAæ­£ç¡®å®‰è£…æˆ–å°è¯•ä½¿ç”¨device='cpu'")
            elif "memory" in str(e).lower() or "OOM" in str(e).upper():
                logger.error("ğŸ’¡ å¯èƒ½çš„åŸå› : å†…å­˜ä¸è¶³")
                logger.error("   è¯·å°è¯•ä½¿ç”¨æ›´å°çš„æ¨¡å‹æˆ–å¢åŠ å¯ç”¨å†…å­˜")
            
            return False
    
    def unload_model(self):
        """å¸è½½FunASRæ¨¡å‹"""
        if not FUNASR_AVAILABLE:
            return
        
        try:
            self._model = None
            self.model_loaded = False
            import gc
            gc.collect()
            logger.info(f"ğŸ§¹ FunASRæ¨¡å‹å·²å¸è½½")
        except KeyboardInterrupt:
            print("\nâ¹ï¸  æ¨¡å‹å¸è½½è¿‡ç¨‹è¢«ä¸­æ–­")
        except Exception as e:
            logger.error(f"âŒ æ¨¡å‹å¸è½½è¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯: {e}")
    
    def test_recognition(self, duration=60):
        """æµ‹è¯•è¯­éŸ³è¯†åˆ«åŠŸèƒ½ - ä¿®å¤ç‰ˆæœ¬ï¼Œæ”¯æŒå®æ—¶éº¦å…‹é£è¾“å…¥

        Args:
            duration: å½•éŸ³æµ‹è¯•æ—¶é•¿ï¼ˆç§’ï¼‰
        """
        if not FUNASR_AVAILABLE:
            logger.error("âŒ FunASRæ¨¡å—ä¸å¯ç”¨ï¼Œæ— æ³•è¿›è¡Œè¯†åˆ«æµ‹è¯•")
            return False

        if not self.model_loaded or self._model is None:
            logger.warning("âš ï¸ æ¨¡å‹æœªåŠ è½½ï¼Œå°è¯•åŠ è½½...")
            if not self.load_model():
                logger.error("âŒ æ— æ³•åŠ è½½æ¨¡å‹ï¼Œæµ‹è¯•ç»ˆæ­¢")
                return False

        logger.info("ğŸ¤ å‡†å¤‡è¿›è¡Œè¯­éŸ³è¯†åˆ«æµ‹è¯•...")

        # å¢åŠ æ›´æ˜æ˜¾çš„æç¤º
        print("=" * 60)
        print("ğŸ“¢ è¯­éŸ³è¯†åˆ«æµ‹è¯•å‡†å¤‡")
        print("=" * 60)
        print("ğŸ”Š è¯·ç¡®ä¿æ‚¨çš„éº¦å…‹é£å·²å¼€å¯å¹¶æ­£å¸¸å·¥ä½œ")
        print(f"â±ï¸  æµ‹è¯•å°†æŒç»­ {duration} ç§’")
        print("ğŸ’¬ è¯·åœ¨æç¤ºå¼€å§‹åå¯¹ç€éº¦å…‹é£è¯´è¯")
        print("ğŸ¯ æ‚¨å¯ä»¥è¯´ä¸€äº›ä¸­æ–‡å¥å­ï¼Œå¦‚'ä½ å¥½ä¸–ç•Œ'ã€'è¯­éŸ³è¯†åˆ«æµ‹è¯•'ç­‰")
        print("âš ï¸  æ³¨æ„: ç³»ç»Ÿä¼šæ£€æµ‹è¯­éŸ³æ´»åŠ¨ï¼Œåªåœ¨æ£€æµ‹åˆ°è¯´è¯æ—¶è¿›è¡Œè¯†åˆ«")
        print("=" * 60)
        print("\nè¯·æŒ‰Enteré”®å¼€å§‹æµ‹è¯•...")
        input()  # ç­‰å¾…ç”¨æˆ·ç¡®è®¤

        # å€’è®¡æ—¶
        countdown = 5
        print(f"\nâ° å½•éŸ³å°†åœ¨ {countdown} ç§’åå¼€å§‹...")
        for i in range(countdown, 0, -1):
            print(f"ğŸ”´ å‡†å¤‡ä¸­: {i}ç§’ ", end="\r")
            time.sleep(1)
        print()
        print("""
==================================================================
ğŸ”µ æ­£åœ¨å½•éŸ³ï¼è¯·å¯¹ç€éº¦å…‹é£è¯´è¯...ğŸ”µ
==================================================================
        """)
        logger.info(f"âœ… å¼€å§‹å½•éŸ³æµ‹è¯•ï¼ŒæŒç»­{duration}ç§’")

        # FunASRæµå¼å¤„ç†å‚æ•° - æ¨¡ä»¿Voskï¼Œå¤„ç†å®Œæ•´è¯­éŸ³æ®µ
        chunk_size = [0, 10, 5]  # [0ms, 200ms, 100ms] - æ¨èçš„æµå¼å¤„ç†å‚æ•°
        encoder_chunk_look_back = 4
        decoder_chunk_look_back = 1
        funasr_cache = {}  # FunASRç¼“å­˜ï¼Œéœ€è¦åœ¨æ•´ä¸ªä¼šè¯ä¸­ä¿æŒ

        # è¯­éŸ³æ´»åŠ¨æ£€æµ‹å‚æ•° - å¹³è¡¡å“åº”é€Ÿåº¦å’Œå®Œæ•´æ€§
        speech_energy_threshold = 0.015  # æé«˜é˜ˆå€¼ï¼Œé™ä½æ•æ„Ÿåº¦ï¼Œé¿å…è¯¯è¯†åˆ«
        min_speech_duration = 0.4  # æœ€å°è¯­éŸ³æ—¶é•¿ï¼Œç¡®è®¤æ˜¯çœŸæ­£çš„è¯­éŸ³
        min_silence_duration = 0.8  # å‡å°‘é™éŸ³æ—¶é•¿ï¼Œæé«˜å“åº”é€Ÿåº¦

        # è¯†åˆ«çŠ¶æ€æ§åˆ¶ - æ¨¡ä»¿Voskçš„AcceptWaveformé€»è¾‘
        speech_segment_audio = []  # å½“å‰è¯­éŸ³æ®µçš„éŸ³é¢‘æ•°æ®
        is_speech_segment = False  # æ˜¯å¦åœ¨è¯­éŸ³æ®µä¸­
        speech_start_time = 0
        last_speech_time = 0
        recognition_count = 0
        last_recognized_text = ""
        collected_text = []

        # å»é‡å’Œç›¸ä¼¼åº¦æ£€æµ‹
        text_similarity_threshold = 0.7  # ç¨å¾®é™ä½ç›¸ä¼¼åº¦é˜ˆå€¼ï¼Œé¿å…è¿‡åº¦è¿‡æ»¤

        start_time = time.time()
        frames_processed = 0
        speech_frames = 0

        # æ–‡æœ¬åå¤„ç†å‡½æ•°
        def calculate_text_similarity(text1, text2):
            """è®¡ç®—ä¸¤ä¸ªæ–‡æœ¬çš„ç›¸ä¼¼åº¦"""
            if not text1 or not text2:
                return 0.0

            # ç§»é™¤ç©ºæ ¼å’Œæ ‡ç‚¹ç¬¦å·è¿›è¡Œæ¯”è¾ƒ
            import re
            clean1 = re.sub(r'[^\w]', '', text1.lower())
            clean2 = re.sub(r'[^\w]', '', text2.lower())

            if not clean1 or not clean2:
                return 0.0

            # è®¡ç®—Jaccardç›¸ä¼¼åº¦
            set1 = set(clean1)
            set2 = set(clean2)
            intersection = len(set1.intersection(set2))
            union = len(set1.union(set2))

            return intersection / union if union > 0 else 0.0

        def is_duplicate_text(new_text, previous_text):
            """åˆ¤æ–­æ˜¯å¦ä¸ºé‡å¤æ–‡æœ¬"""
            if not previous_text:
                return False

            similarity = calculate_text_similarity(new_text, previous_text)
            return similarity >= text_similarity_threshold

        def remove_duplicate_chars(text):
            """ç§»é™¤æ–‡æœ¬ä¸­çš„é‡å¤å­—ç¬¦"""
            if not text:
                return text

            result = []
            prev_char = None
            for char in text:
                if char != prev_char:
                    result.append(char)
                prev_char = char
            return ''.join(result)

        def is_valid_text(text):
            """æ£€æŸ¥æ–‡æœ¬æ˜¯å¦æœ‰æ•ˆï¼Œè¿‡æ»¤ä½è´¨é‡è¯†åˆ«ç»“æœ"""
            if not text or len(text.strip()) < 2:
                return False

            # è¿‡æ»¤æ˜æ˜¾çš„è¯¯è¯†åˆ«ç»“æœ
            invalid_patterns = ['e', 'yeah', 'å—¯', 'å•Š', 'å“¦', 'å‘ƒ', 'é¢', 'å˜¿å˜¿', 'å“ˆå“ˆ']
            text_clean = text.strip().lower()
            for pattern in invalid_patterns:
                if text_clean == pattern or text_clean.count(pattern) > 2:
                    return False

            # æ£€æŸ¥æ˜¯å¦æœ‰å®é™…å†…å®¹å­—ç¬¦ï¼ˆä¸­æ–‡ã€æ•°å­—ã€è‹±æ–‡ï¼‰
            import re
            meaningful_chars = re.findall(r'[\u4e00-\u9fff\w]', text)
            if len(meaningful_chars) < 2:
                return False

            return True

        def post_process_text(text):
            """åå¤„ç†è¯†åˆ«ç»“æœ"""
            if not text:
                return text

            # ç§»é™¤é‡å¤å­—ç¬¦
            text = remove_duplicate_chars(text)

            # ç§»é™¤å¤šä½™ç©ºæ ¼
            text = ' '.join(text.split())

            return text

        try:
            with audio_stream(sample_rate=self.sample_rate, chunk_size=self.chunk_size) as stream:
                while time.time() - start_time < duration:
                    try:
                        # è¯»å–éŸ³é¢‘æ•°æ®
                        data = stream.read(self.chunk_size, exception_on_overflow=False)
                        frames_processed += 1

                        # è½¬æ¢ä¸ºnumpyæ•°ç»„
                        audio_data = np.frombuffer(data, dtype=np.int16).astype(np.float32) / 32768.0

                        # è®¡ç®—éŸ³é¢‘èƒ½é‡
                        audio_energy = np.sqrt(np.mean(audio_data**2))
                        current_time = time.time() - start_time

                        # === æ¨¡ä»¿Voskçš„è¯­éŸ³æ´»åŠ¨æ£€æµ‹é€»è¾‘ ===
                        is_speech = audio_energy > speech_energy_threshold

                        if is_speech and not is_speech_segment:
                            # å¼€å§‹æ–°çš„è¯­éŸ³æ®µ
                            is_speech_segment = True
                            speech_start_time = current_time
                            speech_segment_audio = []  # æ¸…ç©ºä¹‹å‰çš„éŸ³é¢‘æ®µ
                            logger.info(f"ğŸ¯ å¼€å§‹è¯­éŸ³æ®µï¼Œèƒ½é‡: {audio_energy:.4f}")

                        elif is_speech and is_speech_segment:
                            # åœ¨è¯­éŸ³æ®µä¸­ï¼Œç»§ç»­æ”¶é›†éŸ³é¢‘
                            last_speech_time = current_time

                        elif not is_speech and is_speech_segment:
                            # è¯­éŸ³å¯èƒ½ç»“æŸï¼Œæ£€æŸ¥é™éŸ³æ—¶é•¿
                            silence_duration = current_time - last_speech_time
                            speech_duration = current_time - speech_start_time

                            # æ™ºèƒ½åˆ¤æ–­ï¼šå¦‚æœè¯­éŸ³æ®µè¶³å¤Ÿé•¿(>2ç§’)æˆ–é™éŸ³æ—¶é—´è¶³å¤Ÿé•¿ï¼Œå°±ç»“æŸè¯†åˆ«
                            should_end = (
                                silence_duration >= min_silence_duration or  # é™éŸ³æ—¶é—´è¶³å¤Ÿ
                                (silence_duration >= 0.5 and speech_duration >= 2.0)  # è¯­éŸ³è¾ƒé•¿ä¸”çŸ­æš‚åœé¡¿
                            )

                            if should_end:
                                # ç¡®è®¤è¯­éŸ³æ®µç»“æŸï¼Œè¿›è¡Œè¯†åˆ«ï¼ˆæ¨¡ä»¿Voskçš„AcceptWaveformï¼‰
                                is_speech_segment = False

                                # æ£€æŸ¥è¯­éŸ³æ®µæ—¶é•¿æ˜¯å¦è¶³å¤Ÿ
                                if speech_duration >= min_speech_duration and len(speech_segment_audio) > 0:
                                    recognition_count += 1
                                    logger.info(f"è¯­éŸ³æ®µç»“æŸï¼Œæ—¶é•¿: {speech_duration:.2f}sï¼ŒéŸ³é¢‘æ ·æœ¬: {len(speech_segment_audio)}")

                                    # è¿›è¡Œè¯†åˆ«
                                    try:
                                        result = self._model.generate(
                                            input=np.array(speech_segment_audio),
                                            cache=funasr_cache,
                                            is_final=False,
                                            chunk_size=chunk_size,
                                            encoder_chunk_look_back=encoder_chunk_look_back,
                                            decoder_chunk_look_back=decoder_chunk_look_back
                                        )

                                        if result and isinstance(result, list) and len(result) > 0 and "text" in result[0]:
                                            raw_text = result[0]["text"].strip()
                                            if raw_text:
                                                processed_text = post_process_text(raw_text)

                                                # æ–‡æœ¬è´¨é‡æ£€æŸ¥
                                                if is_valid_text(processed_text):
                                                    # æ£€æŸ¥æ˜¯å¦ä¸ºé‡å¤æ–‡æœ¬
                                                    if not is_duplicate_text(processed_text, last_recognized_text):
                                                        last_recognized_text = processed_text
                                                        collected_text.append(processed_text)

                                                        # æ˜¾ç¤ºè¯†åˆ«ç»“æœ
                                                        print(f"\nğŸ¯ è¯†åˆ«: {processed_text}")
                                                        logger.info(f"FunASRè¯†åˆ«ç»“æœ: '{processed_text}' (åŸå§‹: '{raw_text}')")
                                                    else:
                                                        logger.debug(f"è·³è¿‡é‡å¤æ–‡æœ¬: {processed_text}")
                                                else:
                                                    logger.debug(f"è·³è¿‡ä½è´¨é‡æ–‡æœ¬: {processed_text}")

                                    except Exception as e:
                                        logger.debug(f"FunASRè¯†åˆ«å¼‚å¸¸: {e}")
                                else:
                                    logger.info(f"âš ï¸ è¯­éŸ³æ®µè¿‡çŸ­ï¼Œè·³è¿‡è¯†åˆ«: æ—¶é•¿={speech_duration:.2f}s < {min_speech_duration}s, æ ·æœ¬æ•°={len(speech_segment_audio)}")

                        # å¦‚æœåœ¨è¯­éŸ³æ®µä¸­ï¼Œæ”¶é›†éŸ³é¢‘æ•°æ®
                        if is_speech_segment:
                            speech_segment_audio.extend(audio_data)
                            speech_frames += 1

                        # å®æ—¶çŠ¶æ€æ˜¾ç¤º
                        remaining_time = duration - current_time
                        if frames_processed % 50 == 0:  # æ¯50å¸§æ›´æ–°ä¸€æ¬¡çŠ¶æ€
                            if is_speech_segment:
                                status = "ğŸ—£ï¸ è¯´è¯ä¸­"
                                speech_duration = current_time - speech_start_time
                                extra_info = f"({speech_duration:.1f}s)"
                            else:
                                status = "ğŸ”‡ é™éŸ³"
                                extra_info = ""

                            speech_rate = (speech_frames / max(1, frames_processed)) * 100
                            print(f"\r{status}{extra_info} | èƒ½é‡:{audio_energy:.4f} | è¯­éŸ³æ´»åŠ¨ç‡:{speech_rate:.1f}% | å‰©ä½™:{remaining_time:.1f}s | è¯†åˆ«æ¬¡æ•°:{recognition_count} | ", end="", flush=True)

                    except Exception as e:
                        logger.error(f"âŒ éŸ³é¢‘å¤„ç†é”™è¯¯: {e}")
                        continue

                # å¤„ç†ç»“æŸæ—¶çš„æœ€ç»ˆè¯†åˆ«
                print(f"\nğŸ å½•éŸ³ç»“æŸï¼Œå¤„ç†æœ€ç»ˆè¯†åˆ«ç»“æœ...")

                # å¦‚æœè¿˜æœ‰æœªå¤„ç†çš„è¯­éŸ³æ®µï¼Œè¿›è¡Œæœ€ç»ˆè¯†åˆ«
                if is_speech_segment and len(speech_segment_audio) > 0:
                    speech_duration = time.time() - start_time - speech_start_time
                    if speech_duration >= min_speech_duration:
                        try:
                            final_result = self._model.generate(
                                input=np.array(speech_segment_audio),
                                cache=funasr_cache,
                                is_final=True,
                                chunk_size=chunk_size,
                                encoder_chunk_look_back=encoder_chunk_look_back,
                                decoder_chunk_look_back=decoder_chunk_look_back
                            )

                            if final_result and isinstance(final_result, list) and len(final_result) > 0 and "text" in final_result[0]:
                                final_text = final_result[0]["text"].strip()
                                if final_text and final_text != last_recognized_text:
                                    collected_text.append(final_text)
                                    print(f"ğŸ¯ æœ€ç»ˆè¯†åˆ«: {final_text}")
                                    logger.info(f"FunASRæœ€ç»ˆè¯†åˆ«ç»“æœ: '{final_text}'")

                        except Exception as e:
                            logger.debug(f"FunASRæœ€ç»ˆè¯†åˆ«å¼‚å¸¸: {e}")

                # æœ€ç»ˆç»“æœåå¤„ç†
                final_collected_text = []
                if collected_text:
                    # åˆå¹¶ç›¸ä¼¼çš„æ–‡æœ¬ç‰‡æ®µ
                    for text in collected_text:
                        if not final_collected_text or not is_duplicate_text(text, final_collected_text[-1]):
                            final_collected_text.append(text)

                # è¾“å‡ºç»Ÿè®¡ä¿¡æ¯
                print("\n" + "=" * 60)
                print("ğŸ“Š æµ‹è¯•ç»“æœç»Ÿè®¡")
                print("=" * 60)

                if final_collected_text:
                    final_text = " ".join(final_collected_text)
                    print(f"ğŸ“ è¯†åˆ«åˆ°çš„æ‰€æœ‰æ–‡æœ¬: {final_text}")
                    print(f"ğŸ”¢ è¯†åˆ«ç‰‡æ®µæ•°é‡: {len(final_collected_text)} (å»é‡å)")
                    print(f"ğŸ¯ è¯†åˆ«åˆ°çš„ç‰‡æ®µ:")
                    for i, text in enumerate(final_collected_text, 1):
                        print(f"   {i}. {text}")

                    # æ˜¾ç¤ºä¼˜åŒ–æ•ˆæœ
                    if len(final_collected_text) < len(collected_text):
                        reduction_count = len(collected_text) - len(final_collected_text)
                        print(f"âœ¨ å»é‡æ•ˆæœ: ç§»é™¤äº† {reduction_count} ä¸ªé‡å¤ç‰‡æ®µ")
                else:
                    print("âŒ æœªè¯†åˆ«åˆ°ä»»ä½•è¯­éŸ³å†…å®¹")
                    print("\nğŸ’¡ å¯èƒ½çš„åŸå› :")
                    print("   - éº¦å…‹é£æœªæ­£ç¡®è¿æ¥æˆ–æƒé™ä¸è¶³")
                    print("   - è¯´è¯éŸ³é‡å¤ªå°æˆ–è·ç¦»éº¦å…‹é£å¤ªè¿œ")
                    print("   - ç¯å¢ƒå™ªéŸ³è¿‡å¤§")
                    print("   - æ¨¡å‹è·¯å¾„æˆ–é…ç½®æœ‰é—®é¢˜")

                print(f"\nğŸ“ˆ éŸ³é¢‘å¤„ç†ç»Ÿè®¡:")
                print(f"   - æ€»å¤„ç†å¸§æ•°: {frames_processed}")
                print(f"   - è¯­éŸ³æ´»åŠ¨å¸§æ•°: {speech_frames}")
                print(f"   - è¯­éŸ³æ´»åŠ¨ç‡: {(speech_frames / max(1, frames_processed)) * 100:.1f}%")
                print(f"   - æµ‹è¯•æ—¶é•¿: {duration}ç§’")

                return True

        except KeyboardInterrupt:
            print("\nâ¹ï¸  æµ‹è¯•è¢«ç”¨æˆ·ä¸­æ–­")
            return True
        except Exception as e:
            logger.error(f"âŒ æµ‹è¯•è¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯: {e}")
            import traceback
            traceback.print_exc()
            return False
    
    def get_status(self):
        """è·å–å½“å‰çŠ¶æ€ä¿¡æ¯"""
        return {
            "funasr_available": FUNASR_AVAILABLE,
            "model_loaded": self.model_loaded,
            "model_path": self.model_path,
            "model_revision": self.model_revision,
            "load_time": self.load_time,
            "python_version": sys.version
        }
    
    def print_status(self):
        """æ‰“å°å½“å‰çŠ¶æ€ä¿¡æ¯"""
        status = self.get_status()
        print("\nğŸ“Š FunASRæµ‹è¯•çŠ¶æ€ä¿¡æ¯:")
        print(f"  - FunASRå¯ç”¨: {'âœ… æ˜¯' if status['funasr_available'] else 'âŒ å¦'}")
        print(f"  - æ¨¡å‹åŠ è½½: {'âœ… å·²åŠ è½½' if status['model_loaded'] else 'âŒ æœªåŠ è½½'}")
        print(f"  - æ¨¡å‹è·¯å¾„: {status['model_path']}")
        print(f"  - æ¨¡å‹ç‰ˆæœ¬: {status['model_revision']}")
        print(f"  - åŠ è½½æ—¶é—´: {status['load_time']:.2f}ç§’" if status['load_time'] > 0 else "  - åŠ è½½æ—¶é—´: æœªåŠ è½½")
        print(f"  - Pythonç‰ˆæœ¬: {status['python_version'].split(' ')[0]}")
        print(f"  - å½“å‰ç›®å½•: {os.getcwd()}")

def main():
    """ä¸»å‡½æ•°"""
    print("=" * 60)
    print("ğŸ¯ FunASR è¯­éŸ³è¯†åˆ«æµ‹è¯•å·¥å…·")
    print("=" * 60)
    print("ğŸ“ è¯´æ˜: æ­¤å·¥å…·ä½¿ç”¨æœ¬åœ°FunASRæ¨¡å‹é€šè¿‡éº¦å…‹é£è¿›è¡Œå®æ—¶è¯­éŸ³è¯†åˆ«")
    print("\n")
    
    # åˆ›å»ºæµ‹è¯•å®ä¾‹
    tester = FunASRTest()
    tester.print_status()
    
    # æµ‹è¯•æ¨¡å‹åŠ è½½
    print("\nğŸ”„ å¼€å§‹æµ‹è¯•æ¨¡å‹åŠ è½½...")
    load_success = tester.load_model()
    
    if load_success:
        tester.print_status()
        
        # æµ‹è¯•è¯­éŸ³è¯†åˆ«
        try:
            print("\n")
            tester.test_recognition(duration=30)  # æ”¹ä¸º30ç§’ï¼Œç»™ç”¨æˆ·æ›´å¤šæµ‹è¯•æ—¶é—´
        except KeyboardInterrupt:
            print("\nâ¹ï¸  æµ‹è¯•è¢«ç”¨æˆ·ä¸­æ–­")
        finally:
            # å¸è½½æ¨¡å‹
            tester.unload_model()
            print("\nğŸ§¹ æµ‹è¯•å®Œæˆï¼Œèµ„æºå·²æ¸…ç†")
    else:
        print("\nâŒ æ¨¡å‹åŠ è½½å¤±è´¥ï¼Œæ— æ³•è¿›è¡Œè¯­éŸ³è¯†åˆ«æµ‹è¯•")
        print("ğŸ’¡ æç¤º: ")
        print("   1. ç¡®ä¿å·²å®‰è£…FunASR: pip install funasr")
        print("   2. æ£€æŸ¥æœ¬åœ°æ¨¡å‹è·¯å¾„æ˜¯å¦æ­£ç¡®")
        print("   3. ç¡®ä¿æœ‰è¶³å¤Ÿçš„ç£ç›˜ç©ºé—´å’Œå†…å­˜")

if __name__ == "__main__":
    main()