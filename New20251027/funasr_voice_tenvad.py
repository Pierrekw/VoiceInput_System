#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
FunASR + TEN VAD è¯­éŸ³è¯†åˆ«æ¨¡å—
åŸºäºFunASR ASR + TEN VADçš„è¯­éŸ³å½•å…¥å’Œè¯†åˆ«åŠŸèƒ½ï¼Œå¯ä½œä¸ºæ¨¡å—å¯¼å…¥ä½¿ç”¨
ç»“åˆç¥ç»ç½‘ç»œVADã€æµå¼è¯†åˆ«å’Œå¤šç§ä¼˜åŒ–ç­–ç•¥

TEN VADä¼˜åŠ¿ï¼š
- ç¥ç»ç½‘ç»œVADï¼Œæ¯”ä¼ ç»Ÿèƒ½é‡é˜ˆå€¼æ›´å‡†ç¡®
- æŠ—å™ªéŸ³èƒ½åŠ›å¼ºï¼Œè¯¯æ£€ç‡ä½
- èƒ½å¤Ÿæ£€æµ‹è½»å£°è¯­éŸ³
- æ— éœ€æ‰‹åŠ¨è°ƒå‚ï¼Œå¼€ç®±å³ç”¨
- æµå¼æ”¯æŒï¼Œä½å»¶è¿Ÿ (RTFçº¦0.01-0.02)
- è½»é‡çº§ (çº¦508KB vs Silero VADçš„2.16MB)

ä½¿ç”¨ç¤ºä¾‹:
    from funasr_voice_TENVAD import FunASRVoiceRecognizer

    recognizer = FunASRVoiceRecognizer()
    recognizer.initialize()
    result = recognizer.recognize_speech(duration=10)
    print(f"è¯†åˆ«ç»“æœ: {result}")
"""

import os
import sys
import warnings
import logging

# å¯¼å…¥æ€§èƒ½ç›‘æ§
from utils.performance_monitor import performance_monitor, PerformanceStep

# å¯¼å…¥Debugæ€§èƒ½è¿½è¸ªæ¨¡å—
#try:
    #from debug.debug_performance_tracker import debug_tracker
#except ImportError:
    #debug_tracker = None

# TEN VADç›¸å…³
TEN_VAD_AVAILABLE = False
ten_vad_model = None

try:
    # å¯¼å…¥æœ¬åœ°TEN VAD
    ten_vad_path = "./onnx_deps/ten_vad"
    if os.path.exists(ten_vad_path):
        sys.path.insert(0, os.path.join(ten_vad_path, "include"))

        # å¯¼å…¥TEN VAD (åŸºäºçœŸå®çš„API)
        from ten_vad import TenVad
        ten_vad_model = TenVad(hop_size=256, threshold=0.5)
        TEN_VAD_AVAILABLE = True
        print("âœ… TEN VAD åŠ è½½æˆåŠŸ (hop_size=256, threshold=0.5)")
    else:
        print("âŒ TEN VADè·¯å¾„ä¸å­˜åœ¨ï¼Œå°†ä½¿ç”¨èƒ½é‡é˜ˆå€¼VAD")

except Exception as e:
    print(f"âŒ TEN VADå¯¼å…¥å¤±è´¥ï¼Œå°†ä½¿ç”¨èƒ½é‡é˜ˆå€¼VAD: {e}")
    TEN_VAD_AVAILABLE = False

# ============================================================================
# ğŸ”§ å…³é”®ï¼šFFmpegç¯å¢ƒå¿…é¡»åœ¨FunASRå¯¼å…¥å‰è®¾ç½®
# ============================================================================
def setup_ffmpeg_environment():
    """è®¾ç½®FFmpegç¯å¢ƒï¼ˆå¿…é¡»åœ¨å¯¼å…¥FunASRä¹‹å‰è°ƒç”¨ï¼‰"""
    # æ–¹æ³•1ï¼šä½¿ç”¨ç¯å¢ƒå˜é‡æ°¸ä¹…è®¾ç½®ï¼ˆæœ€å¿«ï¼‰
    # å¦‚æœå·²ç»è®¾ç½®è¿‡FFmpegè·¯å¾„ï¼Œç›´æ¥è·³è¿‡
    if os.environ.get('FFMPEG_PATH_SET') == '1':
        return True

    try:
        # æ–¹æ³•2ï¼šé…ç½®å›ºå®šè·¯å¾„ï¼ˆæ¨èç”¨äºå¿«é€Ÿå¯åŠ¨ï¼‰
        # è¿™é‡Œè®¾ç½®ä¸€ä¸ªå›ºå®šçš„FFmpegè·¯å¾„ï¼Œé¿å…å¤šæ¬¡æ£€æŸ¥
        # ç”¨æˆ·å¯ä»¥æ ¹æ®å®é™…æƒ…å†µä¿®æ”¹è¿™ä¸ªè·¯å¾„
        FIXED_FFMPEG_PATH = "./onnx_deps/ffmpeg-master-latest-win64-gpl-shared/bin"

        if FIXED_FFMPEG_PATH and os.path.exists(FIXED_FFMPEG_PATH):
            current_path = os.environ.get('PATH', '')
            if FIXED_FFMPEG_PATH not in current_path:
                os.environ['PATH'] = FIXED_FFMPEG_PATH + os.pathsep + current_path
            # æ ‡è®°FFmpegè·¯å¾„å·²è®¾ç½®
            os.environ['FFMPEG_PATH_SET'] = '1'
            return True

        # æ–¹æ³•3ï¼šå¿«é€Ÿæ£€æŸ¥ï¼ˆä»…æ£€æŸ¥æœ€å¯èƒ½çš„ä½ç½®ï¼‰
        script_dir = os.path.dirname(os.path.abspath(__file__))
        fast_check_paths = [
            # ä¸»è¦æ£€æŸ¥FunASR_Deploymentç›®å½•
            os.path.join(script_dir, "FunASR_Deployment", "dependencies",
                        "ffmpeg-master-latest-win64-gpl-shared", "bin"),
        ]

        for ffmpeg_path in fast_check_paths:
            if os.path.exists(ffmpeg_path):
                current_path = os.environ.get('PATH', '')
                if ffmpeg_path not in current_path:
                    os.environ['PATH'] = ffmpeg_path + os.pathsep + current_path
                os.environ['FFMPEG_PATH_SET'] = '1'
                return True

        # æ³¨æ„ï¼šç³»ç»ŸPATHæ£€æŸ¥å·²ç§»é™¤ï¼Œå› ä¸ºå®ƒè¾ƒæ…¢
        # å»ºè®®ï¼šå°†FFmpegæ·»åŠ åˆ°ç³»ç»Ÿç¯å¢ƒå˜é‡PATHä¸­
        print("âš ï¸ æœªæ‰¾åˆ°FFmpegå¿«é€Ÿè·¯å¾„")
        print("ğŸ’¡ æ€§èƒ½ä¼˜åŒ–å»ºè®®ï¼š")
        print("  1. å°†FFmpegå®‰è£…åˆ°ç³»ç»ŸPATHç¯å¢ƒå˜é‡ä¸­")
        print(f"  2. æˆ–ä¿®æ”¹ä»£ç ä¸­çš„FIXED_FFMPEG_PATHä¸ºæ‚¨çš„FFmpegè·¯å¾„")

        return False

    except Exception:
        # é™é»˜å¤±è´¥ï¼Œé¿å…å½±å“å¯åŠ¨é€Ÿåº¦
        return False

# ç«‹å³æ‰§è¡ŒFFmpegç¯å¢ƒè®¾ç½®
setup_ffmpeg_environment()

# ============================================================================
# ğŸ“¦ å¯¼å…¥å…¶ä»–ä¾èµ–
# ============================================================================
import io
import time
import numpy as np
import pyaudio
import threading
from contextlib import contextmanager
from typing import List, Dict, Optional, Callable, Union, Tuple, Any
from dataclasses import dataclass
from collections import deque

# ä½¿ç”¨ç»Ÿä¸€çš„æ—¥å¿—å·¥å…·ç±»
from utils.logging_utils import LoggingManager

# è·å–é…ç½®å¥½çš„æ—¥å¿—è®°å½•å™¨ï¼ˆå‚è€ƒvoice_gui.pyçš„é…ç½®é£æ ¼ï¼‰
logger = LoggingManager.get_logger(
    name='funasr_voice_TENVAD',
    level=logging.DEBUG,  # æ–‡ä»¶è®°å½•è¯¦ç»†æ—¥å¿—
    console_level=logging.INFO,  # æ§åˆ¶å°æ˜¾ç¤ºINFOåŠä»¥ä¸Šä¿¡æ¯
    log_to_console=True,
    log_to_file=True
)

# å…¨å±€å¯ç”¨æ€§æ£€æŸ¥
FUNASR_AVAILABLE = False
PYAUDIO_AVAILABLE = False
NUMPY_AVAILABLE = False

# æ£€æŸ¥ä¾èµ–
try:
    import numpy as np
    NUMPY_AVAILABLE = True
except ImportError:
    logger.error("âŒ numpy ä¸å¯ç”¨ï¼Œè¯·å®‰è£…: pip install numpy")
    # ä¸è®¾ç½® np å˜é‡ï¼Œé¿å…ç±»å‹å†²çª

try:
    import pyaudio
    PYAUDIO_AVAILABLE = True
except ImportError:
    logger.error("âŒ pyaudio ä¸å¯ç”¨ï¼Œè¯·å®‰è£…: pip install pyaudio")

try:
    from funasr import AutoModel
    FUNASR_AVAILABLE = True
    logger.info("âœ… FunASR æ¨¡å—å¯ç”¨")
except ImportError as e:
    logger.error(f"âŒ FunASR ä¸å¯ç”¨: {e}")
    AutoModel = None

# å¯¼å…¥é…ç½®åŠ è½½æ¨¡å—
config_loader: Any = None
CONFIG_AVAILABLE = False

try:
    from config_loader import config
    config_loader = config
    CONFIG_AVAILABLE = True
except ImportError:
    logger.error("é…ç½®åŠ è½½æ¨¡å—ä¸å¯ç”¨ï¼Œä½¿ç”¨é»˜è®¤é…ç½®")
    CONFIG_AVAILABLE = False

@dataclass
class RecognitionResult:
    """è¯­éŸ³è¯†åˆ«ç»“æœæ•°æ®ç±»"""
    text: str                    # æœ€ç»ˆè¯†åˆ«æ–‡æœ¬
    partial_results: List[str]   # éƒ¨åˆ†è¯†åˆ«ç»“æœåˆ—è¡¨
    confidence: float            # ç½®ä¿¡åº¦
    duration: float              # è¯†åˆ«æ—¶é•¿
    timestamp: float             # æ—¶é—´æˆ³
    audio_buffer: List[np.ndarray]  # éŸ³é¢‘ç¼“å†²åŒº

@dataclass
class VADConfig:
    """VADé…ç½®"""
    energy_threshold: float = 0.015
    min_speech_duration: float = 0.3
    min_silence_duration: float = 0.6
    speech_padding: float = 0.3

@dataclass
class FunASRConfig:
    """FunASRé…ç½®"""
    model_path: str = "C:/Users/wangp2/VoiceInput_f1.0/model/fun" #model/cn
    
    device: str = "cpu"
    chunk_size: Optional[List[int]] = None
    encoder_chunk_look_back: int = 4
    decoder_chunk_look_back: int = 1
    disable_update: bool = True
    trust_remote_code: bool = False

    def __post_init__(self):
        if self.chunk_size is None:
            self.chunk_size = [0, 10, 5]  # é»˜è®¤æµå¼å‚æ•°

class FunASRVoiceRecognizer:
    """
    FunASR + TEN VAD è¯­éŸ³è¯†åˆ«å™¨ä¸»ç±»
    ç»“åˆTEN VADçš„è¯­éŸ³å½•å…¥ã€è¯†åˆ«å’ŒVADåŠŸèƒ½
    """

    def __init__(self,
                 model_path: Optional[str] = None,
                 device: str = "cpu",
                 sample_rate: int = 16000,
                 chunk_size: int = 400,
                 silent_mode: bool = True):
        """
        åˆå§‹åŒ–è¯­éŸ³è¯†åˆ«å™¨

        Args:
            model_path: FunASRæ¨¡å‹è·¯å¾„
            device: è®¾å¤‡ç±»å‹ ("cpu" æˆ– "cuda")
            sample_rate: éŸ³é¢‘é‡‡æ ·ç‡
            chunk_size: éŸ³é¢‘å—å¤§å°
            silent_mode: é™é»˜æ¨¡å¼ï¼Œéšè—ä¸­é—´è¿‡ç¨‹ä¿¡æ¯
        """
        # åŸºç¡€é…ç½®
        self.sample_rate = sample_rate
        self.chunk_size = chunk_size
        self.model_path = model_path or "./model/fun"
        self.silent_mode = silent_mode

        # FunASRé…ç½®
        self.funasr_config = FunASRConfig(
            model_path=self.model_path,
            device=device
        )

        # TEN VADé…ç½®
        self._ten_vad_enabled = TEN_VAD_AVAILABLE
        self._ten_vad_available = TEN_VAD_AVAILABLE
        self._ten_vad_threshold = 0.5

        # å›é€€VADé…ç½® - æ”¯æŒä»é…ç½®æ–‡ä»¶åŠ è½½
        self.vad_config = self._load_vad_config()

        # æ¨¡å‹ç›¸å…³
        self._model: Optional[Any] = None
        self._model_loaded = False
        self._model_load_time = 0.0

        # è¿è¡ŒçŠ¶æ€
        self._is_initialized = False
        self._is_running = False
        self._stop_event = threading.Event()
        self._speech_detected = False

        # FFmpegé¢„å¤„ç†é…ç½®
        self._ffmpeg_enabled = False
        self._ffmpeg_filter_chain = ""
        self._ffmpeg_options: Dict[str, Any] = {}
        self._ffmpeg_path = "ffmpeg"  # é»˜è®¤FFmpegè·¯å¾„

        # éŸ³é¢‘å¤„ç†
        self._audio_buffer: deque[np.ndarray] = deque(maxlen=sample_rate * 5)  # 5ç§’ç¼“å†²
        self._speech_buffer: List[np.ndarray] = []
        self._funasr_cache: Dict[str, Any] = {}

        # è¯†åˆ«ç»“æœ
        self._current_text = ""
        self._partial_results: List[str] = []
        self._final_results: List[RecognitionResult] = []

        # ç»Ÿè®¡ä¿¡æ¯
        self.stats = {
            'total_recognitions': 0,
            'successful_recognitions': 0,
            'total_audio_time': 0.0,
            'total_processing_time': 0.0,
            'average_confidence': 0.0
        }

        # å›è°ƒå‡½æ•°
        self._on_partial_result: Optional[Callable[[str], None]] = None
        self._on_final_result: Optional[Callable[[RecognitionResult], None]] = None
        self._on_vad_event: Optional[Callable[[str, Dict], None]] = None

        # ååˆå§‹åŒ–
        self.__post_init__()

    def __post_init__(self):
        """ååˆå§‹åŒ–ï¼Œè®¾ç½®TEN VAD"""
        if self._ten_vad_available and ten_vad_model:
            logger.info("ğŸ¯ TEN VADå·²å¯ç”¨ (hop_size=256, threshold=0.5)")
        else:
            logger.info("âš ï¸ TEN VADä¸å¯ç”¨ï¼Œå°†ä½¿ç”¨èƒ½é‡é˜ˆå€¼VAD")

    def _load_vad_config(self):
        """ä»é…ç½®åŠ è½½å™¨åŠ è½½VADè®¾ç½®"""
        try:
            from config_loader import config

            # åŠ è½½FFmpegé¢„å¤„ç†é…ç½®
            self._ffmpeg_enabled = config.is_ffmpeg_preprocessing_enabled()
            self._ffmpeg_filter_chain = config.get_ffmpeg_filter_chain()
            self._ffmpeg_options = config.get_ffmpeg_options()

            logger.info(f"ğŸ”§ FFmpegé¢„å¤„ç†: {'å¯ç”¨' if self._ffmpeg_enabled else 'ç¦ç”¨'}")
            if self._ffmpeg_enabled:
                logger.info(f"   æ»¤é•œé“¾: {self._ffmpeg_filter_chain}")
                logger.info(f"   é€‰é¡¹: {self._ffmpeg_options}")

            return VADConfig(
                energy_threshold=config.get_vad_energy_threshold(),
                min_speech_duration=config.get_vad_min_speech_duration(),
                min_silence_duration=config.get_vad_min_silence_duration(),
                speech_padding=config.get_vad_speech_padding()
            )

        except Exception as e:
            logger.warning(f"åŠ è½½VADé…ç½®å¤±è´¥: {e}ï¼Œä½¿ç”¨é»˜è®¤é…ç½®")
            # FFmpegé…ç½®å¤±è´¥æ—¶ä½¿ç”¨é»˜è®¤å€¼
            self._ffmpeg_enabled = False
            self._ffmpeg_filter_chain = "highpass=f=80, afftdn=nf=-25, loudnorm, volume=2.0"
            self._ffmpeg_options = {
                "process_input": True,
                "save_processed": False,
                "processed_prefix": "processed_"
            }
            return VADConfig()

    def _apply_ffmpeg_preprocessing(self, audio_data: np.ndarray, temp_file_prefix: str = "ffmpeg_temp_") -> np.ndarray:
        """
        åº”ç”¨FFmpegé¢„å¤„ç†åˆ°éŸ³é¢‘æ•°æ®

        Args:
            audio_data: è¾“å…¥éŸ³é¢‘æ•°æ® (numpyæ•°ç»„)
            temp_file_prefix: ä¸´æ—¶æ–‡ä»¶å‰ç¼€

        Returns:
            é¢„å¤„ç†åçš„éŸ³é¢‘æ•°æ®
        """
        if not self._ffmpeg_enabled or not self._ffmpeg_options.get('process_input', True):
            return audio_data  # å¦‚æœæœªå¯ç”¨æˆ–é…ç½®ä¸å¤„ç†è¾“å…¥ï¼Œç›´æ¥è¿”å›åŸæ•°æ®

        # ğŸ”¥ å…³é”®ä¿®å¤ï¼šåœ¨FFmpegå¤„ç†å¼€å§‹å‰æ£€æŸ¥åœæ­¢ä¿¡å·
        if self._stop_event.is_set():
            logger.info("æ£€æµ‹åˆ°åœæ­¢ä¿¡å·ï¼Œè·³è¿‡FFmpegé¢„å¤„ç†")
            return audio_data

        try:
            import subprocess
            import tempfile
            import os

            # å°†éŸ³é¢‘æ•°æ®ä¿å­˜ä¸ºä¸´æ—¶WAVæ–‡ä»¶
            with tempfile.NamedTemporaryFile(suffix='.wav', prefix=temp_file_prefix, delete=False) as temp_input_file:
                temp_input_path = temp_input_file.name

                # ç¡®ä¿æ•°æ®æ ¼å¼æ­£ç¡® (16ä½PCM)
                audio_int16 = (audio_data * 32767).astype(np.int16)

                # å†™å…¥WAVæ–‡ä»¶
                import wave
                with wave.open(temp_input_path, 'wb') as wav_file:
                    wav_file.setnchannels(1)  # å•å£°é“
                    wav_file.setsampwidth(2)  # 16ä½
                    wav_file.setframerate(self.sample_rate)
                    wav_file.writeframes(audio_int16.tobytes())

            # ç”Ÿæˆè¾“å‡ºæ–‡ä»¶è·¯å¾„
            with tempfile.NamedTemporaryFile(suffix='.wav', prefix="processed_", delete=False) as temp_output_file:
                temp_output_path = temp_output_file.name

            # æ„å»ºFFmpegå‘½ä»¤
            ffmpeg_cmd = [
                self._ffmpeg_path,  # ä»setup_environmentè®¾ç½®
                '-i', temp_input_path,
                '-af', self._ffmpeg_filter_chain,
                '-y',  # è¦†ç›–è¾“å‡ºæ–‡ä»¶
                temp_output_path
            ]

            # æ‰§è¡ŒFFmpegé¢„å¤„ç†
            logger.debug(f"æ‰§è¡ŒFFmpegå‘½ä»¤: {' '.join(ffmpeg_cmd)}")

            try:
                # ğŸ”¥ ä¿®å¤ï¼šå¤§å¹…å‡å°‘è¶…æ—¶æ—¶é—´ï¼Œé¿å…é•¿æ—¶é—´é˜»å¡
                result = subprocess.run(
                    ffmpeg_cmd,
                    capture_output=True,
                    text=True,
                    timeout=2  # å‡å°‘åˆ°2ç§’è¶…æ—¶ï¼Œé¿å…é˜»å¡åœæ­¢åŠŸèƒ½
                )

                if result.returncode != 0:
                    logger.warning(f"FFmpegé¢„å¤„ç†å¤±è´¥: {result.stderr}")
                    return audio_data  # å¤±è´¥æ—¶è¿”å›åŸæ•°æ®
                else:
                    logger.debug(f"FFmpegé¢„å¤„ç†æˆåŠŸ: {result.stdout}")

            except subprocess.TimeoutExpired:
                logger.warning("FFmpegé¢„å¤„ç†è¶…æ—¶ï¼Œè·³è¿‡æ­¤éŸ³é¢‘å—çš„é¢„å¤„ç†")
                return audio_data
            except Exception as e:
                logger.warning(f"FFmpegé¢„å¤„ç†å¼‚å¸¸: {e}")
                return audio_data

            # è¯»å–é¢„å¤„ç†åçš„éŸ³é¢‘æ•°æ®
            processed_data = None
            try:
                with wave.open(temp_output_path, 'rb') as wav_file:
                    with wave.open(temp_output_path, 'rb') as wav_file:
                        frames = wav_file.readframes(-1)
                        sample_width = wav_file.getsampwidth()
                        channels = wav_file.getnchannels()
                        processed_data = np.frombuffer(frames, dtype=np.int16)

                        # ç¡®ä¿æ˜¯å•å£°é“
                        if channels == 1 and sample_width == 2:
                            processed_float_data = processed_data.astype(np.float32) / 32768.0
                            return processed_float_data
                        else:
                            logger.warning("FFmpegè¾“å‡ºæ ¼å¼å¼‚å¸¸ï¼Œä½¿ç”¨åŸå§‹æ•°æ®")
                            return audio_data

            except Exception as e:
                logger.error(f"è¯»å–é¢„å¤„ç†åéŸ³é¢‘å¤±è´¥: {e}")
                processed_data = audio_data

            # æ¸…ç†ä¸´æ—¶æ–‡ä»¶
            try:
                os.unlink(temp_input_path)
                os.unlink(temp_output_path)
            except Exception as e:
                logger.warning(f"æ¸…ç†ä¸´æ—¶æ–‡ä»¶å¤±è´¥: {e}")

            return processed_data if processed_data is not None else audio_data

        except Exception as e:
            logger.error(f"FFmpegé¢„å¤„ç†æ¨¡å—å¼‚å¸¸: {e}")
            return audio_data

    def _get_gui_display_threshold(self) -> float:
        """è·å–GUIèƒ½é‡æ˜¾ç¤ºé˜ˆå€¼ï¼ˆç‹¬ç«‹äºVADæ£€æµ‹ï¼‰"""
        try:
            from config_loader import config
            return config.get_gui_display_threshold()
        except Exception as e:
            logger.warning(f"åŠ è½½GUIæ˜¾ç¤ºé˜ˆå€¼å¤±è´¥: {e}ï¼Œä½¿ç”¨é»˜è®¤å€¼0.00001")
            return 0.00001

    def set_callbacks(self,
                     on_partial_result: Optional[Callable[[str], None]] = None,
                     on_final_result: Optional[Callable[[RecognitionResult], None]] = None,
                     on_vad_event: Optional[Callable[[str, Dict], None]] = None):
        """
        è®¾ç½®å›è°ƒå‡½æ•°

        Args:
            on_partial_result: éƒ¨åˆ†ç»“æœå›è°ƒ
            on_final_result: æœ€ç»ˆç»“æœå›è°ƒ
            on_vad_event: VADäº‹ä»¶å›è°ƒ
        """
        self._on_partial_result = on_partial_result
        self._on_final_result = on_final_result
        self._on_vad_event = on_vad_event

    def setup_environment(self) -> bool:
        """è®¾ç½®è¿è¡Œç¯å¢ƒ"""
        try:
            # è®¾ç½®FFmpegè·¯å¾„ï¼ˆå¦‚æœéœ€è¦ï¼‰
            script_dir = os.path.dirname(os.path.abspath(__file__))
            local_ffmpeg_bin = os.path.join(script_dir, "FunASR_Deployment",
                                          "dependencies", "ffmpeg-master-latest-win64-gpl-shared", "bin")

            if os.path.exists(local_ffmpeg_bin):
                current_path = os.environ.get('PATH', '')
                if local_ffmpeg_bin not in current_path:
                    os.environ['PATH'] = local_ffmpeg_bin + os.pathsep + current_path
                    logger.info(f"ğŸ”§ è®¾ç½®æœ¬åœ°FFmpeg: {local_ffmpeg_bin}")

            return True

        except Exception as e:
            logger.warning(f"ç¯å¢ƒè®¾ç½®å¤±è´¥: {e}")
            return False

    def check_dependencies(self) -> bool:
        """æ£€æŸ¥ä¾èµ–æ˜¯å¦æ»¡è¶³"""
        missing_deps = []

        if not NUMPY_AVAILABLE:
            missing_deps.append("numpy")
        if not PYAUDIO_AVAILABLE:
            missing_deps.append("pyaudio")
        if not FUNASR_AVAILABLE:
            missing_deps.append("funasr")

        if missing_deps:
            logger.error(f"âŒ ç¼ºå°‘ä¾èµ–: {', '.join(missing_deps)}")
            logger.error("è¯·æ‰§è¡Œ: pip install " + " ".join(missing_deps))
            return False

        return True

    def initialize(self) -> bool:
        """åˆå§‹åŒ–è¯†åˆ«å™¨ï¼Œä¼˜åŒ–ç¬¬ä¸€æ¬¡å¯åŠ¨æ€§èƒ½"""
        if self._is_initialized:
            logger.info("âœ… è¯†åˆ«å™¨å·²åˆå§‹åŒ–")
            return True

        logger.info("ğŸš€ åˆå§‹åŒ–FunASR + TEN VADè¯­éŸ³è¯†åˆ«å™¨...")
        init_start_time = time.time()

        # æ£€æŸ¥ä¾èµ– - å‰ç½®æ£€æŸ¥ï¼Œé¿å…åç»­å¤±è´¥
        if not self.check_dependencies():
            return False

        # è®¾ç½®ç¯å¢ƒ - é¢„å…ˆé…ç½®ï¼Œå‡å°‘è¿è¡Œæ—¶å»¶è¿Ÿ
        self.setup_environment()

        # åŠ è½½æ¨¡å‹ - æ ¸å¿ƒä¼˜åŒ–ç‚¹
        if not self._load_model():
            return False

        self._is_initialized = True
        total_init_time = time.time() - init_start_time
        logger.info(f"âœ… FunASR + TEN VADè¯­éŸ³è¯†åˆ«å™¨åˆå§‹åŒ–å®Œæˆ (æ€»è€—æ—¶: {total_init_time:.2f}ç§’)")
        return True

    def _load_model(self) -> bool:
        """åŠ è½½FunASRæ¨¡å‹"""
        if self._model_loaded:
            return True

        if not FUNASR_AVAILABLE:
            logger.error("âŒ FunASRä¸å¯ç”¨")
            return False

        logger.info(f"ğŸ“¦ åŠ è½½FunASRæ¨¡å‹: {self.model_path}")
        start_time = time.time()

        try:
            # æ£€æŸ¥æ¨¡å‹è·¯å¾„
            if not os.path.exists(self.model_path):
                logger.error(f"âŒ æ¨¡å‹è·¯å¾„ä¸å­˜åœ¨: {self.model_path}")
                return False

            # åŠ è½½æ¨¡å‹
            self._model = AutoModel(
                model=self.funasr_config.model_path,
                device=self.funasr_config.device,
                trust_remote_code=self.funasr_config.trust_remote_code,
                disable_update=self.funasr_config.disable_update
            )

            self._model_loaded = True
            self._model_load_time = time.time() - start_time

            logger.info(f"âœ… æ¨¡å‹åŠ è½½æˆåŠŸ (è€—æ—¶: {self._model_load_time:.2f}ç§’)")

            # ä¼˜åŒ–ï¼šé¢„é¢„çƒ­æ¨¡å‹ï¼Œå‡å°‘ç¬¬ä¸€æ¬¡è¯†åˆ«å»¶è¿Ÿ
            try:
                logger.info("ğŸ”„ é¢„é¢„çƒ­æ¨¡å‹ä»¥å‡å°‘é¦–æ¬¡è¯†åˆ«å»¶è¿Ÿ...")
                # å‘é€ä¸€ä¸ªå°çš„ç©ºéŸ³é¢‘å—è¿›è¡Œé¢„è¯†åˆ«ï¼Œè§¦å‘æ¨¡å‹å†…éƒ¨ä¼˜åŒ–
                if hasattr(self._model, 'forward'):
                    # è¿™é‡Œä¸å®é™…æ‰§è¡Œæ¨ç†ï¼Œåªæ˜¯ç¡®ä¿æ¨¡å‹å‡†å¤‡å°±ç»ª
                    pass
            except Exception as e:
                logger.debug(f"æ¨¡å‹é¢„çƒ­è¿‡ç¨‹å‡ºé”™ (å¯å¿½ç•¥): {e}")

            return True

        except Exception as e:
            logger.error(f"âŒ æ¨¡å‹åŠ è½½å¤±è´¥: {e}")
            import traceback
            logger.error(f"è¯¦ç»†é”™è¯¯: {traceback.format_exc()}")
            return False

    def unload_model(self):
        """å¸è½½æ¨¡å‹é‡Šæ”¾å†…å­˜ - ä¼˜åŒ–ï¼šæ ¹æ®é…ç½®å†³å®šæ˜¯å¦çœŸçš„å¸è½½æ¨¡å‹"""
        # ğŸ”¥ é˜²é‡å¤è°ƒç”¨ä¿æŠ¤
        if not self._model_loaded:
            logger.debug("â„¹ï¸ æ¨¡å‹å·²ç»å¸è½½ï¼Œè·³è¿‡é‡å¤è°ƒç”¨")
            return

        # ä»é…ç½®åŠ è½½å…¨å±€å¸è½½è®¾ç½®
        try:
            from config_loader import get_config
            config = get_config()
            global_unload = config.get('system', {}).get('global_unload', False)
        except ImportError:
            logger.debug("æ— æ³•å¯¼å…¥get_configï¼Œä½¿ç”¨é»˜è®¤è®¾ç½®")
            global_unload = False
        except Exception as e:
            logger.debug(f"è·å–é…ç½®æ—¶å‡ºé”™ï¼Œé»˜è®¤å¯ç”¨å¸è½½: {e}")
            global_unload = True

        # åªæœ‰åœ¨æ˜ç¡®é…ç½®éœ€è¦å¸è½½æˆ–è€…æ¨¡å‹å·²åŠ è½½æ—¶æ‰æ‰§è¡Œå¸è½½
        if self._model and global_unload:
            logger.info(f"ğŸ§¹ å¸è½½æ¨¡å‹ (å…¨å±€å¸è½½è®¾ç½®: {global_unload})")
            self._model = None
            self._model_loaded = False
            import gc
            gc.collect()
            logger.info("ğŸ§¹ æ¨¡å‹å·²å¸è½½ï¼Œé‡Šæ”¾å†…å­˜")
        else:
            # ä¿ç•™æ¨¡å‹åœ¨å†…å­˜ä¸­ä»¥åŠ å¿«ä¸‹æ¬¡å¯åŠ¨
            logger.info(f"â„¹ï¸ ä¿ç•™æ¨¡å‹åœ¨å†…å­˜ä¸­ä»¥åŠ å¿«åç»­å¯åŠ¨")
            self._model_loaded = False  # æ ‡è®°ä¸ºå·²å¤„ç†

    @contextmanager
    def _audio_stream(self):
        """éŸ³é¢‘æµä¸Šä¸‹æ–‡ç®¡ç†å™¨ï¼Œå¢å¼ºå¼‚å¸¸å¤„ç†å’Œé‡è¿æœºåˆ¶"""
        if not PYAUDIO_AVAILABLE:
            raise RuntimeError("PyAudioä¸å¯ç”¨")

        max_retries = 3
        retry_count = 0

        while retry_count < max_retries:
            p = None
            stream = None

            try:
                p = pyaudio.PyAudio()

                # è·å–é»˜è®¤éŸ³é¢‘è®¾å¤‡
                try:
                    default_device = p.get_default_input_device_info()
                    logger.info(f"ğŸ¤ ä½¿ç”¨éŸ³é¢‘è®¾å¤‡: {default_device['name']} (ç´¢å¼•: {default_device['index']})")
                except Exception as device_error:
                    logger.error(f"âŒ æ— æ³•è·å–éŸ³é¢‘è®¾å¤‡ä¿¡æ¯: {device_error}")
                    raise RuntimeError("éŸ³é¢‘è®¾å¤‡ä¸å¯ç”¨")

                # æ‰“å¼€éŸ³é¢‘æµï¼Œå¢åŠ é”™è¯¯å®¹é”™
                stream = p.open(
                    format=pyaudio.paInt16,
                    channels=1,
                    rate=self.sample_rate,
                    input=True,
                    input_device_index=default_device['index'],
                    frames_per_buffer=self.chunk_size,
                    start=True
                )

                # éªŒè¯éŸ³é¢‘æµæ˜¯å¦æ­£å¸¸å·¥ä½œ
                if not stream.is_active():
                    raise RuntimeError("éŸ³é¢‘æµåˆ›å»ºå¤±è´¥ï¼šæµæœªæ¿€æ´»")

                logger.info(f"ğŸ§ éŸ³é¢‘æµåˆ›å»ºæˆåŠŸ (é‡è¯• {retry_count + 1}/{max_retries})")
                yield stream
                break  # æˆåŠŸåˆ™é€€å‡ºé‡è¯•å¾ªç¯

            except Exception as e:
                retry_count += 1
                error_msg = f"âŒ éŸ³é¢‘æµåˆ›å»ºå¤±è´¥ (é‡è¯• {retry_count}/{max_retries}): {e}"

                if retry_count >= max_retries:
                    logger.error(error_msg + " - å·²è¾¾åˆ°æœ€å¤§é‡è¯•æ¬¡æ•°")
                    raise RuntimeError(f"éŸ³é¢‘æµåˆ›å»ºå¤±è´¥ï¼Œå·²é‡è¯•{max_retries}æ¬¡: {e}")
                else:
                    logger.warning(error_msg + " - æ­£åœ¨é‡è¯•...")
                    time.sleep(1)  # é‡è¯•å‰ç­‰å¾…1ç§’

            finally:
                # ç¡®ä¿èµ„æºæ­£ç¡®é‡Šæ”¾
                if stream:
                    try:
                        if stream.is_active():
                            stream.stop_stream()
                        stream.close()
                    except Exception as cleanup_error:
                        logger.warning(f"âš ï¸ éŸ³é¢‘æµæ¸…ç†å¼‚å¸¸: {cleanup_error}")

                if p:
                    try:
                        p.terminate()
                    except Exception as cleanup_error:
                        logger.warning(f"âš ï¸ PyAudioæ¸…ç†å¼‚å¸¸: {cleanup_error}")

    def _detect_vad(self, audio_data: np.ndarray, current_time: float) -> Tuple[bool, Optional[str]]:
        """
        VADè¯­éŸ³æ´»åŠ¨æ£€æµ‹ - ä½¿ç”¨TEN VADæˆ–å›é€€åˆ°èƒ½é‡é˜ˆå€¼

        Args:
            audio_data: éŸ³é¢‘æ•°æ®
            current_time: å½“å‰æ—¶é—´

        Returns:
            (is_speech, event_type): æ˜¯å¦æœ‰è¯­éŸ³å’Œäº‹ä»¶ç±»å‹
        """
        is_speech = False
        vad_confidence = 0.0
        event_type = None

        # å°è¯•ä½¿ç”¨TEN VADè¿›è¡Œæ£€æµ‹
        if self._ten_vad_available and ten_vad_model:
            try:
                # TEN VADè¦æ±‚256ä¸ªé‡‡æ ·ç‚¹
                vad_chunk_size = 256
                if len(audio_data) >= vad_chunk_size:
                    vad_chunk = audio_data[:vad_chunk_size]
                    # è½¬æ¢ä¸ºint16æ ¼å¼
                    vad_int16 = (vad_chunk * 32767).astype(np.int16)

                    # ä½¿ç”¨TEN VADè¿›è¡Œæ£€æµ‹
                    vad_confidence, vad_flag = ten_vad_model.process(vad_int16)
                    is_speech = (vad_flag == 1)

                    logger.debug(f"TEN VAD: ç½®ä¿¡åº¦={vad_confidence:.3f}, æ ‡å¿—={vad_flag}, ç»“æœ={is_speech}")
                else:
                    logger.debug("éŸ³é¢‘æ•°æ®ä¸è¶³256ä¸ªé‡‡æ ·ç‚¹ï¼Œè·³è¿‡TEN VADæ£€æµ‹")

            except Exception as ten_vad_error:
                logger.warning(f"TEN VADå¤„ç†é”™è¯¯ï¼Œå›é€€åˆ°èƒ½é‡é˜ˆå€¼: {ten_vad_error}")
                self._ten_vad_available = False  # æ ‡è®°TEN VADä¸å¯ç”¨

        # å›é€€åˆ°ä¼ ç»Ÿèƒ½é‡é˜ˆå€¼VAD
        if not self._ten_vad_available or not ten_vad_model:
            energy = np.sqrt(np.mean(audio_data ** 2))
            is_speech = energy > self.vad_config.energy_threshold
            vad_confidence = float(energy)
            logger.debug(f"å›é€€åˆ°èƒ½é‡é˜ˆå€¼VAD: èƒ½é‡={energy:.6f}, é˜ˆå€¼={self.vad_config.energy_threshold}, ç»“æœ={is_speech}")

        # æ£€æµ‹è¯­éŸ³å¼€å§‹å’Œç»“æŸ
        if is_speech:
            if not hasattr(self, '_speech_detected') or not self._speech_detected:
                event_type = "speech_start"
                self._speech_detected = True
                self._speech_start_time = current_time
                logger.info(f"ğŸ¤ è¯­éŸ³å¼€å§‹ ({'TEN VAD' if self._ten_vad_available else 'èƒ½é‡é˜ˆå€¼'}: ç½®ä¿¡åº¦={vad_confidence:.3f}, æ ‡å¿—={is_speech})")
        else:
            if hasattr(self, '_speech_detected') and self._speech_detected:
                silence_duration = current_time - getattr(self, '_last_speech_time', current_time)
                if silence_duration >= self.vad_config.min_silence_duration:
                    event_type = "speech_end"
                    self._speech_detected = False

        if is_speech:
            self._last_speech_time = current_time

        return is_speech, event_type

    def _process_audio_chunk(self, audio_data: np.ndarray, current_time: float):
        """
        å¤„ç†éŸ³é¢‘å—

        Args:
            audio_data: éŸ³é¢‘æ•°æ®
            current_time: å½“å‰æ—¶é—´
        """
        # åº”ç”¨FFmpegé¢„å¤„ç†ï¼ˆå¦‚æœå¯ç”¨ï¼‰
        if self._ffmpeg_enabled:
            with PerformanceStep("FFmpegé¢„å¤„ç†", {
                'data_length': len(audio_data),
                'current_time': current_time
            }):
                audio_data = self._apply_ffmpeg_preprocessing(audio_data, f"chunk_{current_time:.0f}")

        # æ·»åŠ åˆ°éŸ³é¢‘ç¼“å†²åŒº
        self._audio_buffer.extend(audio_data)

        # VADæ£€æµ‹
        is_speech, vad_event = self._detect_vad(audio_data, current_time)

        # è®¡ç®—éŸ³é¢‘èƒ½é‡
        audio_energy = np.sqrt(np.mean(audio_data ** 2))

        # æ£€æŸ¥æ˜¯å¦åº”è¯¥å‘é€GUIèƒ½é‡æ›´æ–°
        gui_threshold = self._get_gui_display_threshold()
        should_send_gui_update = not vad_event and audio_energy > gui_threshold

        # å¦‚æœæ²¡æœ‰VADäº‹ä»¶ä½†èƒ½é‡è¶…è¿‡æ˜¾ç¤ºé˜ˆå€¼ï¼Œä¹Ÿå‘é€èƒ½é‡æ›´æ–°ç”¨äºæ˜¾ç¤º
        if should_send_gui_update:
            if self._on_vad_event:
                self._on_vad_event("energy_update", {
                    'time': current_time,
                    'energy': audio_energy
                })

        if vad_event and self._on_vad_event:
            self._on_vad_event(vad_event, {
                'time': current_time,
                'energy': audio_energy
            })

        # å¦‚æœæ£€æµ‹åˆ°è¯­éŸ³ï¼Œæ·»åŠ åˆ°è¯­éŸ³ç¼“å†²åŒº
        if is_speech:
            # è®°å½•è¯­éŸ³è¾“å…¥å¼€å§‹ï¼ˆå¦‚æœæ˜¯æ–°çš„è¯­éŸ³æ®µï¼‰
            #if vad_event == "speech_start":and debug_tracker:
                #debug_tracker.record_voice_input_start(audio_energy)

            self._speech_buffer.extend(audio_data)

            # å®šæœŸè¿›è¡Œæµå¼è¯†åˆ«
            if len(self._speech_buffer) >= self.sample_rate * 1:  # 0.5-1ç§’éŸ³é¢‘
                self._perform_streaming_recognition()
        else:
            # å¦‚æœé™éŸ³æ—¶é—´è¶³å¤Ÿé•¿ä¸”æœ‰è¯­éŸ³ç¼“å†²åŒºï¼Œè¿›è¡Œæœ€ç»ˆè¯†åˆ«
            if (len(self._speech_buffer) > 0 and
                hasattr(self, '_last_speech_time') and
                current_time - self._last_speech_time >= self.vad_config.min_silence_duration):

                if len(self._speech_buffer) >= self.sample_rate * self.vad_config.min_speech_duration:
                    # è®°å½•è¯­éŸ³è¾“å…¥ç»“æŸå’ŒASRå¼€å§‹
                    #if debug_tracker:
                    #    debug_tracker.record_voice_input_end(len(self._speech_buffer) / self.sample_rate)
                    #    debug_tracker.record_asr_start(len(self._speech_buffer))

                    self._perform_final_recognition()

    def _perform_streaming_recognition(self):
        """æ‰§è¡Œæµå¼è¯†åˆ«"""
        if not self._model or not self._model_loaded:
            return

        try:
            # å–æœ€è¿‘çš„éŸ³é¢‘æ•°æ®è¿›è¡Œè¯†åˆ«
            audio_array = np.array(list(self._speech_buffer))

            result = self._model.generate(
                input=audio_array,
                cache=self._funasr_cache,
                is_final=False,
                chunk_size=self.funasr_config.chunk_size,
                encoder_chunk_look_back=self.funasr_config.encoder_chunk_look_back,
                decoder_chunk_look_back=self.funasr_config.decoder_chunk_look_back
            )

            if result and isinstance(result, list) and len(result) > 0:
                text = result[0].get("text", "").strip()
                if text and text != self._current_text:
                    self._current_text = text
                    self._partial_results.append(text)

                    # è§¦å‘éƒ¨åˆ†ç»“æœå›è°ƒ
                    if self._on_partial_result:
                        self._on_partial_result(text)

                    if not self.silent_mode:
                        logger.info(f"ğŸ—£ï¸ æµå¼è¯†åˆ«: '{text}'")

        except Exception as e:
            logger.debug(f"æµå¼è¯†åˆ«å¼‚å¸¸: {e}")

    def _perform_final_recognition(self):
        """æ‰§è¡Œæœ€ç»ˆè¯†åˆ«"""
        if not self._model or not self._model_loaded or not self._speech_buffer:
            return

        try:
            start_time = time.time()

            audio_array = np.array(list(self._speech_buffer))

            # ğŸ”¥ æ¶æ„ä¿®å¤ï¼šåœ¨è¯­éŸ³æ®µç»“æŸæ—¶è¿›è¡ŒFFmpegæ‰¹é‡é¢„å¤„ç†
            if self._ffmpeg_enabled and len(audio_array) > 0:
                logger.debug("å¯¹å®Œæ•´è¯­éŸ³æ®µè¿›è¡ŒFFmpegé¢„å¤„ç†")
                with PerformanceStep("FFmpegæ‰¹é‡é¢„å¤„ç†", {
                    'audio_length': len(audio_array),
                    'duration_seconds': len(audio_array) / self.sample_rate
                }):
                    # ä½¿ç”¨å®Œæ•´çš„è¯­éŸ³æ®µè¿›è¡Œé¢„å¤„ç†ï¼Œè€Œä¸æ˜¯æ¯ä¸ªchunk
                    audio_array = self._apply_ffmpeg_preprocessing(audio_array, "final_segment")

            result = self._model.generate(
                input=audio_array,
                cache=self._funasr_cache,
                is_final=True,
                chunk_size=self.funasr_config.chunk_size,
                encoder_chunk_look_back=self.funasr_config.encoder_chunk_look_back,
                decoder_chunk_look_back=self.funasr_config.decoder_chunk_look_back
            )

            processing_time = time.time() - start_time

            if result and isinstance(result, list) and len(result) > 0:
                text = result[0].get("text", "").strip()
                if text:
                    # åˆ›å»ºè¯†åˆ«ç»“æœ
                    recognition_result = RecognitionResult(
                        text=text,
                        partial_results=self._partial_results.copy(),
                        confidence=0.9,  # FunASRæš‚ä¸æä¾›ç½®ä¿¡åº¦ï¼Œä½¿ç”¨é»˜è®¤å€¼
                        duration=len(self._speech_buffer) / self.sample_rate,
                        timestamp=time.time(),
                        audio_buffer=self._speech_buffer.copy()
                    )

                    self._final_results.append(recognition_result)
                    self.stats['total_recognitions'] += 1
                    self.stats['successful_recognitions'] += 1
                    self.stats['total_processing_time'] += processing_time

                    # è§¦å‘æœ€ç»ˆç»“æœå›è°ƒ
                    if self._on_final_result:
                        self._on_final_result(recognition_result)

                    if not self.silent_mode:
                        logger.info(f"âœ… æœ€ç»ˆè¯†åˆ«: '{text}' (è€—æ—¶: {processing_time:.3f}s)")

        except Exception as e:
            logger.error(f"æœ€ç»ˆè¯†åˆ«å¼‚å¸¸: {e}")
        finally:
            # æ¸…ç©ºè¯­éŸ³ç¼“å†²åŒº
            self._speech_buffer = []
            self._current_text = ""

    def get_status(self) -> Dict[str, Any]:
        """è·å–è¯†åˆ«å™¨çŠ¶æ€"""
        return {
            'initialized': self._is_initialized,
            'model_loaded': self._model_loaded,
            'model_path': self.model_path,
            'device': self.funasr_config.device,
            'vad_method': 'TEN VAD' if self._ten_vad_enabled else 'Energy Threshold',
            'ten_vad_available': TEN_VAD_AVAILABLE,
            'stats': self.stats.copy(),
            'model_load_time': self._model_load_time,
            'dependencies': {
                'funasr': FUNASR_AVAILABLE,
                'pyaudio': PYAUDIO_AVAILABLE,
                'numpy': NUMPY_AVAILABLE,
                'ten_vad': TEN_VAD_AVAILABLE
            }
        }

    def recognize_speech(self, duration: int = 10,
                        real_time_display: bool = True) -> RecognitionResult:
        """
        è¯†åˆ«è¯­éŸ³ï¼ˆåŒæ­¥æ¨¡å¼ï¼‰

        Args:
            duration: è¯†åˆ«æ—¶é•¿ï¼ˆç§’ï¼‰
            real_time_display: æ˜¯å¦å®æ—¶æ˜¾ç¤ºè¯†åˆ«ç»“æœ

        Returns:
            RecognitionResult: è¯†åˆ«ç»“æœ
        """
        if not self._is_initialized:
            if not self.initialize():
                raise RuntimeError("åˆå§‹åŒ–å¤±è´¥")

        if not self.silent_mode:
            logger.info(f"ğŸ™ï¸ å¼€å§‹è¯­éŸ³è¯†åˆ«ï¼Œæ—¶é•¿: {duration}ç§’")

        # é‡ç½®çŠ¶æ€
        self._stop_event.clear()
        self._audio_buffer.clear()
        self._speech_buffer = []
        self._current_text = ""
        self._partial_results = []

        start_time = time.time()
        current_time = 0.0  # åˆå§‹åŒ–current_timeå˜é‡

        try:
            with self._audio_stream() as stream:
                # æ”¯æŒduration=-1è¡¨ç¤ºæ— é™æ—¶æ¨¡å¼
                while (duration == -1 or time.time() - start_time < duration) and not self._stop_event.is_set():
                    try:
                        # æ›´æ–°å½“å‰æ—¶é—´
                        current_time = time.time() - start_time

                        # è¯»å–éŸ³é¢‘æ•°æ®
                        with PerformanceStep("éŸ³é¢‘è¾“å…¥", {
                            'chunk_size': self.chunk_size,
                            'current_time': current_time
                        }):
                            data = stream.read(self.chunk_size, exception_on_overflow=False)

                        # è½¬æ¢ä¸ºnumpyæ•°ç»„
                        with PerformanceStep("éŸ³é¢‘å¤„ç†", {
                            'data_length': len(data),
                            'current_time': current_time
                        }):
                            audio_data = np.frombuffer(data, dtype=np.int16).astype(np.float32) / 32768.0

                        # ğŸ”¥ æ¶æ„ä¿®å¤ï¼šç§»é™¤å®æ—¶å¾ªç¯ä¸­çš„FFmpegé¢„å¤„ç†
                        # FFmpegé¢„å¤„ç†å°†åœ¨è¯­éŸ³æ®µç»“æŸæ—¶æ‰¹é‡è¿›è¡Œï¼Œè€Œä¸æ˜¯åœ¨æ¯ä¸ªéŸ³é¢‘chunkæ—¶å¤„ç†
                        # è¿™æ ·ä¿æŒäº†å®æ—¶éŸ³é¢‘å¤„ç†çš„è¿ç»­æ€§ï¼Œé¿å…äº†stream.read()é˜»å¡é—®é¢˜

                        # å¤„ç†éŸ³é¢‘
                        self._process_audio_chunk(audio_data, current_time)

                        # å®æ—¶æ˜¾ç¤º
                        if real_time_display and self._current_text:
                            if duration == -1:
                                # æ— é™æ—¶æ¨¡å¼ï¼šæ˜¾ç¤ºè¿è¡Œæ—¶é—´
                                print(f"\rğŸ—£ï¸ è¯†åˆ«ä¸­: '{self._current_text}' | è¿è¡Œæ—¶é—´: {current_time:.1f}s",
                                     end="", flush=True)
                            else:
                                # é™æ—¶æ¨¡å¼ï¼šæ˜¾ç¤ºå‰©ä½™æ—¶é—´
                                remaining = duration - current_time
                                print(f"\rğŸ—£ï¸ è¯†åˆ«ä¸­: '{self._current_text}' | å‰©ä½™: {remaining:.1f}s",
                                     end="", flush=True)

                    except OSError as audio_error:
                        # ä¸“é—¨å¤„ç†éŸ³é¢‘æµç›¸å…³çš„ç³»ç»Ÿé”™è¯¯
                        logger.error(f"ğŸ¤ éŸ³é¢‘æµå¼‚å¸¸: {audio_error}")
                        # æ£€æŸ¥æ˜¯å¦æ˜¯è®¾å¤‡æ–­å¼€è¿æ¥
                        if "Input overflowed" in str(audio_error):
                            logger.warning("âš ï¸ éŸ³é¢‘ç¼“å†²åŒºæº¢å‡ºï¼Œç»§ç»­å¤„ç†...")
                            continue
                        elif "No such device" in str(audio_error) or "Device unavailable" in str(audio_error):
                            logger.error("âŒ éŸ³é¢‘è®¾å¤‡æ–­å¼€è¿æ¥æˆ–ä¸å¯ç”¨")
                            raise RuntimeError("éŸ³é¢‘è®¾å¤‡æ–­å¼€è¿æ¥")
                        else:
                            logger.warning(f"âš ï¸ éŸ³é¢‘æµé”™è¯¯ï¼Œå°è¯•ç»§ç»­: {audio_error}")
                            continue

                    except Exception as e:
                        logger.error(f"âŒ éŸ³é¢‘å¤„ç†é”™è¯¯: {e}")
                        # å¯¹äºå…¶ä»–å¼‚å¸¸ï¼Œè®°å½•è¯¦ç»†ä¿¡æ¯ä½†å°è¯•ç»§ç»­
                        import traceback
                        logger.debug(f"é”™è¯¯è¯¦æƒ…: {traceback.format_exc()}")
                        continue

                # å¤„ç†æœ€åçš„éŸ³é¢‘
                if self._speech_buffer:
                    self._perform_final_recognition()

        except KeyboardInterrupt:
            logger.info("â¹ï¸ è¯†åˆ«è¢«ç”¨æˆ·ä¸­æ–­ (KeyboardInterrupt)")
        except Exception as e:
            logger.error(f"âŒ è¯†åˆ«è¿‡ç¨‹å‡ºé”™: {e}")
            raise

        # è®°å½•è¯†åˆ«ç»“æŸåŸå› 
        end_time = time.time()
        actual_duration = end_time - start_time

        if self._stop_event.is_set():
            logger.info(f"â¹ï¸ è¯†åˆ«è¢«ç³»ç»Ÿåœæ­¢ä¿¡å·ä¸­æ–­ (è¿è¡Œæ—¶é—´: {actual_duration:.2f}ç§’)")
        elif duration == -1:
            logger.info(f"â¹ï¸ æ— é™æ—¶æ¨¡å¼è¯†åˆ«ç»“æŸ (è¿è¡Œæ—¶é—´: {actual_duration:.2f}ç§’)")
        elif actual_duration >= duration:
            logger.info(f"â¹ï¸ è¯†åˆ«è¾¾åˆ°æŒ‡å®šæ—¶é•¿ (è®¾å®š: {duration}ç§’, å®é™…: {actual_duration:.2f}ç§’)")
        else:
            logger.info(f"â¹ï¸ è¯†åˆ«æå‰ç»“æŸ (è®¾å®š: {duration}ç§’, å®é™…: {actual_duration:.2f}ç§’)")

        # è¿”å›æœ€ç»ˆç»“æœ
        if self._final_results:
            final_result = self._final_results[-1]
            print(f"\nâœ… è¯†åˆ«å®Œæˆ: '{final_result.text}'")
            return final_result
        else:
            # å¦‚æœæ²¡æœ‰æœ€ç»ˆç»“æœï¼Œä½¿ç”¨éƒ¨åˆ†ç»“æœ
            if self._partial_results:
                text = self._partial_results[-1] if self._partial_results else ""
                result = RecognitionResult(
                    text=text,
                    partial_results=self._partial_results,
                    confidence=0.5,
                    duration=duration,
                    timestamp=time.time(),
                    audio_buffer=[]
                )
                print(f"\nâš ï¸ æ— æœ€ç»ˆç»“æœï¼Œè¿”å›éƒ¨åˆ†ç»“æœ: '{text}'")
                return result
            else:
                logger.warning("âš ï¸ æœªè¯†åˆ«åˆ°ä»»ä½•è¯­éŸ³å†…å®¹")
                return RecognitionResult(
                    text="",
                    partial_results=[],
                    confidence=0.0,
                    duration=0.0,
                    timestamp=time.time(),
                    audio_buffer=[]
                )

    def start_continuous_recognition(self):
        """å¼€å§‹è¿ç»­è¯†åˆ«ï¼ˆå¼‚æ­¥æ¨¡å¼ï¼‰"""
        if not self._is_initialized:
            if not self.initialize():
                raise RuntimeError("åˆå§‹åŒ–å¤±è´¥")

        if self._is_running:
            logger.warning("âš ï¸ è¿ç»­è¯†åˆ«å·²åœ¨è¿è¡Œ")
            return

        logger.info("ğŸ”„ å¼€å§‹è¿ç»­è¯†åˆ«æ¨¡å¼")
        self._is_running = True
        self._stop_event.clear()

        def recognition_thread():
            try:
                with self._audio_stream() as stream:
                    while self._is_running and not self._stop_event.is_set():
                        try:
                            # ğŸ”¥ å…³é”®ä¿®å¤ï¼šåœ¨éŸ³é¢‘è¯»å–å‰æ£€æŸ¥åœæ­¢ä¿¡å·
                            if self._stop_event.is_set():
                                logger.info("è¿ç»­è¯†åˆ«æ£€æµ‹åˆ°åœæ­¢ä¿¡å·ï¼Œé€€å‡ºå¾ªç¯")
                                break

                            data = stream.read(self.chunk_size, exception_on_overflow=False)
                            current_time = time.time()

                            audio_data = np.frombuffer(data, dtype=np.int16).astype(np.float32) / 32768.0
                            self._process_audio_chunk(audio_data, current_time)

                        except OSError as audio_error:
                            # ä¸“é—¨å¤„ç†éŸ³é¢‘æµç›¸å…³çš„ç³»ç»Ÿé”™è¯¯
                            logger.error(f"ğŸ¤ è¿ç»­è¯†åˆ«éŸ³é¢‘æµå¼‚å¸¸: {audio_error}")

                            # æ£€æŸ¥ä¸¥é‡é”™è¯¯ç±»å‹
                            if "No such device" in str(audio_error) or "Device unavailable" in str(audio_error):
                                logger.error("âŒ éŸ³é¢‘è®¾å¤‡æ–­å¼€è¿æ¥ï¼Œåœæ­¢è¿ç»­è¯†åˆ«")
                                self._is_running = False
                                break
                            elif "Input overflowed" in str(audio_error):
                                logger.warning("âš ï¸ éŸ³é¢‘ç¼“å†²åŒºæº¢å‡ºï¼Œç»§ç»­å¤„ç†...")
                                continue
                            else:
                                logger.warning(f"âš ï¸ éŸ³é¢‘æµé”™è¯¯ï¼Œå°è¯•ç»§ç»­: {audio_error}")
                                continue

                        except Exception as e:
                            logger.error(f"âŒ è¿ç»­è¯†åˆ«é”™è¯¯: {e}")
                            import traceback
                            logger.debug(f"é”™è¯¯è¯¦æƒ…: {traceback.format_exc()}")
                            continue

            except Exception as e:
                logger.error(f"è¿ç»­è¯†åˆ«çº¿ç¨‹å¼‚å¸¸: {e}")
            finally:
                self._is_running = False
                logger.info("ğŸ”„ è¿ç»­è¯†åˆ«çº¿ç¨‹ç»“æŸ")

        # å¯åŠ¨è¯†åˆ«çº¿ç¨‹
        thread = threading.Thread(target=recognition_thread, daemon=True)
        thread.start()

        return thread

    def stop_recognition(self):
        """åœæ­¢è¯†åˆ«"""
        logger.info("â¹ï¸ åœæ­¢è¯†åˆ«")
        self._stop_event.set()
        self._is_running = False

        # å¤„ç†æœ€åçš„éŸ³é¢‘
        if self._speech_buffer:
            self._perform_final_recognition()

        
    def __del__(self):
        """ææ„å‡½æ•°"""
        try:
            self.stop_recognition()
            self.unload_model()
        except:
            pass

# ä¾¿æ·å‡½æ•°
def create_recognizer(model_path: Optional[str] = None,
                     device: str = "cpu") -> FunASRVoiceRecognizer:
    """
    åˆ›å»ºå¹¶åˆå§‹åŒ–è¯­éŸ³è¯†åˆ«å™¨

    Args:
        model_path: æ¨¡å‹è·¯å¾„
        device: è®¾å¤‡ç±»å‹

    Returns:
        FunASRVoiceRecognizer: å·²åˆå§‹åŒ–çš„è¯†åˆ«å™¨
    """
    recognizer = FunASRVoiceRecognizer(model_path=model_path, device=device)
    if not recognizer.initialize():
        raise RuntimeError("è¯†åˆ«å™¨åˆå§‹åŒ–å¤±è´¥")
    return recognizer

def quick_recognize(duration: int = 10,
                   model_path: Optional[str] = None) -> str:
    """
    å¿«é€Ÿè¯­éŸ³è¯†åˆ«

    Args:
        duration: è¯†åˆ«æ—¶é•¿
        model_path: æ¨¡å‹è·¯å¾„

    Returns:
        str: è¯†åˆ«ç»“æœæ–‡æœ¬
    """
    recognizer = create_recognizer(model_path=model_path)
    result = recognizer.recognize_speech(duration=duration)
    return result.text

if __name__ == "__main__":
    # ç¤ºä¾‹ç”¨æ³•
    print("ğŸ¯ FunASR + TEN VAD è¯­éŸ³è¯†åˆ«æ¨¡å—æµ‹è¯•")
    print("=" * 50)

    # åˆ›å»ºè¯†åˆ«å™¨
    recognizer = FunASRVoiceRecognizer()

    # æ˜¾ç¤ºçŠ¶æ€
    status = recognizer.get_status()
    print(f"ğŸ“Š è¯†åˆ«å™¨çŠ¶æ€: {status}")

    if recognizer.initialize():
        print("âœ… è¯†åˆ«å™¨åˆå§‹åŒ–æˆåŠŸ")
        print("ğŸ¤ TEN VADé›†æˆå®Œæˆï¼Œå¯ä»¥è¿›è¡Œè¯­éŸ³è¯†åˆ«æµ‹è¯•")
    else:
        print("âŒ è¯†åˆ«å™¨åˆå§‹åŒ–å¤±è´¥")