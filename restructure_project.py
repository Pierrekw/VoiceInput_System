# -*- coding: utf-8 -*-
"""
é¡¹ç›®é‡æ„å·¥å…·è„šæœ¬

æ­¤è„šæœ¬ç”¨äºæ ¹æ®ç³»ç»Ÿåˆ†ç¦»æ–¹æ¡ˆè‡ªåŠ¨é‡æ„é¡¹ç›®ç›®å½•ç»“æ„ï¼Œ
å°†åŒæ­¥å’Œå¼‚æ­¥ç³»ç»Ÿåˆ†ç¦»åˆ°ç‹¬ç«‹çš„ç›®å½•ä¸­ï¼Œå¹¶åˆ›å»ºå…±äº«ç»„ä»¶ç›®å½•ã€‚

ä½¿ç”¨æ–¹æ³•ï¼š
1. å¤‡ä»½é¡¹ç›®æ–‡ä»¶
2. è¿è¡Œæ­¤è„šæœ¬: python restructure_project.py
3. è„šæœ¬ä¼šæ ¹æ®é…ç½®è‡ªåŠ¨ç§»åŠ¨æ–‡ä»¶å’Œåˆ›å»ºç›®å½•

æ³¨æ„äº‹é¡¹ï¼š
- è¯·ç¡®ä¿åœ¨è¿è¡Œå‰å…³é—­æ‰€æœ‰ä½¿ç”¨é¡¹ç›®æ–‡ä»¶çš„ç¨‹åº
- å»ºè®®åœ¨è¿è¡Œå‰å…ˆæŸ¥çœ‹è„šæœ¬çš„é…ç½®å’Œå®ç°ï¼Œç¡®ä¿ç¬¦åˆæ‚¨çš„éœ€æ±‚
- è„šæœ¬æä¾›äº†æ¨¡æ‹Ÿè¿è¡Œæ¨¡å¼ï¼Œå¯ä»¥å…ˆé¢„è§ˆå°†è¦æ‰§è¡Œçš„æ“ä½œ
"""

import os
import shutil
import logging
import argparse
from pathlib import Path
import sys

# é…ç½®æ—¥å¿—
def setup_logger(log_level=logging.INFO):
    """è®¾ç½®æ—¥å¿—è®°å½•å™¨"""
    logger = logging.getLogger('ProjectRestructurer')
    logger.setLevel(log_level)
    
    # é¿å…é‡å¤æ·»åŠ handler
    if not logger.handlers:
        # åˆ›å»ºæ§åˆ¶å°handler
        console_handler = logging.StreamHandler()
        console_handler.setLevel(log_level)
        
        # åˆ›å»ºæ–‡ä»¶handler
        log_dir = Path(__file__).parent / 'logs'
        log_dir.mkdir(parents=True, exist_ok=True)
        log_file = log_dir / 'restructure.log'
        file_handler = logging.FileHandler(log_file, encoding='utf-8')
        file_handler.setLevel(log_level)
        
        # è®¾ç½®æ—¥å¿—æ ¼å¼
        formatter = logging.Formatter('%(asctime)s - %(name)s - %(levelname)s - %(message)s')
        console_handler.setFormatter(formatter)
        file_handler.setFormatter(formatter)
        
        # æ·»åŠ handleråˆ°logger
        logger.addHandler(console_handler)
        logger.addHandler(file_handler)
    
    return logger


class ProjectRestructurer:
    """é¡¹ç›®é‡æ„å™¨ç±»"""
    
    def __init__(self, simulate=False, log_level=logging.INFO):
        # é¡¹ç›®æ ¹ç›®å½•
        self.project_root = Path(__file__).parent
        
        # æ¨¡æ‹Ÿè¿è¡Œæ¨¡å¼
        self.simulate = simulate
        
        # åˆå§‹åŒ–æ—¥å¿—
        self.logger = setup_logger(log_level)
        
        # å®šä¹‰ç›®å½•ç»“æ„
        # æºç›®å½• -> ç›®æ ‡ç›®å½•æ˜ å°„
        self.directory_mapping = {
            # åŒæ­¥ç³»ç»Ÿç›®å½•
            'main.py': 'sync_system/main.py',
            'adapters/audio_capture.py': 'sync_system/adapters/audio_capture.py',
            'adapters/data_exporter.py': 'sync_system/adapters/data_exporter.py',
            'adapters/tts_controller.py': 'sync_system/adapters/tts_controller.py',
            'sync_config/': 'sync_system/config/',
            
            # å¼‚æ­¥ç³»ç»Ÿç›®å½•
            'main_production.py': 'async_system/main.py',
            'async_audio/': 'async_system/audio/',
            'async_config/': 'async_system/config/',
            'async_processing/': 'async_system/processing/',
            
            # å…±äº«ç»„ä»¶ç›®å½•
            'interfaces/': 'shared/interfaces/',
            'text_processor.py': 'shared/text_processor.py',
            'shared_utils/': 'shared/utils/',
            'models/': 'shared/models/',
            
            # æµ‹è¯•ç›®å½•
            'tests/': 'tests/',
            
            # æ–‡æ¡£ç›®å½•
            'docs/': 'docs/',
            'SYSTEM_WORKFLOW.md': 'docs/SYSTEM_WORKFLOW.md',
            'SHARED_MODULE_GUIDE.md': 'docs/SHARED_MODULE_GUIDE.md',
            'SYSTEM_SEPARATION_PLAN.md': 'docs/SYSTEM_SEPARATION_PLAN.md',
            'DETAILED_RESTRUCTURING_GUIDE.md': 'docs/DETAILED_RESTRUCTURING_GUIDE.md',
            'SYSTEM_SEPARATION_COMPARISON.md': 'docs/SYSTEM_SEPARATION_COMPARISON.md',
        }
        
        # éœ€è¦åˆ›å»ºçš„ç›®å½•åˆ—è¡¨
        self.required_directories = [
            'sync_system',
            'sync_system/adapters',
            'sync_system/config',
            'async_system',
            'async_system/audio',
            'async_system/config',
            'async_system/processing',
            'shared',
            'shared/interfaces',
            'shared/utils',
            'shared/models',
            'tests',
            'docs',
            'logs/sync',
            'logs/async',
        ]
        
        # ç‰¹æ®Šå¤„ç†æ–‡ä»¶
        self.special_files = {
            'requirements.txt': {
                'dest': 'requirements.txt',
                'action': 'keep'
            },
            '.gitignore': {
                'dest': '.gitignore',
                'action': 'keep'
            },
            'README.md': {
                'dest': 'README.md',
                'action': 'update'
            }
        }
        
        # ä¿å­˜å·²ç§»åŠ¨çš„æ–‡ä»¶è®°å½•
        self.moved_files = []
        
        # ä¿å­˜åˆ›å»ºçš„ç›®å½•è®°å½•
        self.created_directories = []
        
        # ä¿å­˜è·³è¿‡çš„æ–‡ä»¶è®°å½•
        self.skipped_files = []
        
        # ä¿å­˜å¤±è´¥çš„æ“ä½œè®°å½•
        self.failed_operations = []
    
    def create_directories(self):
        """åˆ›å»ºæ‰€éœ€çš„ç›®å½•ç»“æ„"""
        self.logger.info("ğŸ“ å¼€å§‹åˆ›å»ºç›®å½•ç»“æ„...")
        
        for dir_path in self.required_directories:
            abs_dir_path = self.project_root / dir_path
            if not abs_dir_path.exists():
                if self.simulate:
                    self.logger.info(f"ğŸ“‹ [æ¨¡æ‹Ÿ] å°†åˆ›å»ºç›®å½•: {abs_dir_path}")
                else:
                    try:
                        abs_dir_path.mkdir(parents=True, exist_ok=True)
                        self.logger.info(f"âœ… åˆ›å»ºç›®å½•æˆåŠŸ: {abs_dir_path}")
                        self.created_directories.append(str(abs_dir_path))
                    except Exception as e:
                        self.logger.error(f"âŒ åˆ›å»ºç›®å½•å¤±è´¥: {abs_dir_path}, é”™è¯¯: {e}")
                        self.failed_operations.append(("create_dir", str(abs_dir_path), str(e)))
            else:
                self.logger.warning(f"âš ï¸ ç›®å½•å·²å­˜åœ¨: {abs_dir_path}")
    
    def move_files(self):
        """æ ¹æ®æ˜ å°„ç§»åŠ¨æ–‡ä»¶"""
        self.logger.info("ğŸ“‚ å¼€å§‹ç§»åŠ¨æ–‡ä»¶...")
        
        for src, dest in self.directory_mapping.items():
            src_path = self.project_root / src
            dest_path = self.project_root / dest
            
            # æ£€æŸ¥æºè·¯å¾„æ˜¯å¦å­˜åœ¨
            if not src_path.exists():
                self.logger.warning(f"âš ï¸ æºè·¯å¾„ä¸å­˜åœ¨: {src_path}")
                self.skipped_files.append(str(src_path))
                continue
            
            # ç¡®ä¿ç›®æ ‡ç›®å½•å­˜åœ¨
            dest_dir = dest_path.parent
            if not dest_dir.exists():
                if self.simulate:
                    self.logger.info(f"ğŸ“‹ [æ¨¡æ‹Ÿ] å°†åˆ›å»ºç›®å½•: {dest_dir}")
                else:
                    try:
                        dest_dir.mkdir(parents=True, exist_ok=True)
                        self.logger.info(f"âœ… åˆ›å»ºç›®æ ‡ç›®å½•æˆåŠŸ: {dest_dir}")
                        self.created_directories.append(str(dest_dir))
                    except Exception as e:
                        self.logger.error(f"âŒ åˆ›å»ºç›®æ ‡ç›®å½•å¤±è´¥: {dest_dir}, é”™è¯¯: {e}")
                        self.failed_operations.append(("create_dir", str(dest_dir), str(e)))
                        continue
            
            # ç§»åŠ¨æ–‡ä»¶æˆ–ç›®å½•
            try:
                if src_path.is_dir():
                    # ç§»åŠ¨ç›®å½•
                    if self.simulate:
                        self.logger.info(f"ğŸ“‹ [æ¨¡æ‹Ÿ] å°†ç§»åŠ¨ç›®å½•: {src_path} -> {dest_path}")
                    else:
                        # å¦‚æœç›®æ ‡ç›®å½•å·²å­˜åœ¨ï¼Œåˆå¹¶å†…å®¹
                        if dest_path.exists():
                            self.logger.info(f"ğŸ”„ ç›®æ ‡ç›®å½•å·²å­˜åœ¨ï¼Œåˆå¹¶å†…å®¹: {dest_path}")
                            # éå†æºç›®å½•ä¸­çš„æ‰€æœ‰æ–‡ä»¶å’Œå­ç›®å½•
                            for item in src_path.iterdir():
                                item_dest = dest_path / item.name
                                if item.is_dir():
                                    if item_dest.exists():
                                        # é€’å½’åˆå¹¶å­ç›®å½•
                                        self._merge_directories(item, item_dest)
                                    else:
                                        shutil.move(str(item), str(item_dest))
                                        self.logger.info(f"âœ… ç§»åŠ¨å­ç›®å½•: {item} -> {item_dest}")
                                else:
                                    # æ–‡ä»¶å­˜åœ¨åˆ™è¦†ç›–
                                    if item_dest.exists():
                                        self.logger.warning(f"âš ï¸ æ–‡ä»¶å·²å­˜åœ¨ï¼Œå°†è¦†ç›–: {item_dest}")
                                    shutil.move(str(item), str(item_dest))
                                    self.logger.info(f"âœ… ç§»åŠ¨æ–‡ä»¶: {item} -> {item_dest}")
                        else:
                            shutil.move(str(src_path), str(dest_path))
                            self.logger.info(f"âœ… ç§»åŠ¨ç›®å½•: {src_path} -> {dest_path}")
                        self.moved_files.append((str(src_path), str(dest_path)))
                else:
                    # ç§»åŠ¨æ–‡ä»¶
                    if self.simulate:
                        self.logger.info(f"ğŸ“‹ [æ¨¡æ‹Ÿ] å°†ç§»åŠ¨æ–‡ä»¶: {src_path} -> {dest_path}")
                    else:
                        # æ–‡ä»¶å­˜åœ¨åˆ™è¦†ç›–
                        if dest_path.exists():
                            self.logger.warning(f"âš ï¸ æ–‡ä»¶å·²å­˜åœ¨ï¼Œå°†è¦†ç›–: {dest_path}")
                        shutil.move(str(src_path), str(dest_path))
                        self.logger.info(f"âœ… ç§»åŠ¨æ–‡ä»¶: {src_path} -> {dest_path}")
                        self.moved_files.append((str(src_path), str(dest_path)))
            except Exception as e:
                self.logger.error(f"âŒ ç§»åŠ¨å¤±è´¥: {src_path} -> {dest_path}, é”™è¯¯: {e}")
                self.failed_operations.append(("move", str(src_path), str(dest_path), str(e)))
    
    def _merge_directories(self, src_dir, dest_dir):
        """é€’å½’åˆå¹¶ä¸¤ä¸ªç›®å½•"""
        for item in src_dir.iterdir():
            item_dest = dest_dir / item.name
            if item.is_dir():
                if item_dest.exists():
                    # é€’å½’åˆå¹¶å­ç›®å½•
                    self._merge_directories(item, item_dest)
                else:
                    shutil.move(str(item), str(item_dest))
                    self.logger.info(f"âœ… ç§»åŠ¨å­ç›®å½•: {item} -> {item_dest}")
            else:
                # æ–‡ä»¶å­˜åœ¨åˆ™è¦†ç›–
                if item_dest.exists():
                    self.logger.warning(f"âš ï¸ æ–‡ä»¶å·²å­˜åœ¨ï¼Œå°†è¦†ç›–: {item_dest}")
                shutil.move(str(item), str(item_dest))
                self.logger.info(f"âœ… ç§»åŠ¨æ–‡ä»¶: {item} -> {item_dest}")
    
    def handle_special_files(self):
        """å¤„ç†ç‰¹æ®Šæ–‡ä»¶"""
        self.logger.info("ğŸ“ å¼€å§‹å¤„ç†ç‰¹æ®Šæ–‡ä»¶...")
        
        for src, config in self.special_files.items():
            src_path = self.project_root / src
            dest_path = self.project_root / config['dest']
            action = config['action']
            
            if action == 'keep':
                # ä¿æŒæ–‡ä»¶ä¸å˜
                if src_path.exists():
                    self.logger.info(f"ğŸ“Œ ä¿æŒæ–‡ä»¶ä¸å˜: {src_path}")
                else:
                    self.logger.warning(f"âš ï¸ æ–‡ä»¶ä¸å­˜åœ¨ï¼Œè·³è¿‡ä¿æŒæ“ä½œ: {src_path}")
            elif action == 'update':
                # æ›´æ–°æ–‡ä»¶
                if self.simulate:
                    self.logger.info(f"ğŸ“‹ [æ¨¡æ‹Ÿ] å°†æ›´æ–°æ–‡ä»¶: {src_path}")
                else:
                    if src_path.exists():
                        # å¤‡ä»½åŸæ–‡ä»¶
                        backup_path = src_path.with_suffix(src_path.suffix + '.bak')
                        try:
                            shutil.copy2(str(src_path), str(backup_path))
                            self.logger.info(f"ğŸ’¾ å¤‡ä»½æ–‡ä»¶: {src_path} -> {backup_path}")
                            
                            # è¿™é‡Œå¯ä»¥æ·»åŠ æ›´æ–°æ–‡ä»¶çš„é€»è¾‘
                            # ä¾‹å¦‚æ›´æ–°README.mdä»¥åæ˜ æ–°çš„é¡¹ç›®ç»“æ„
                            if src == 'README.md':
                                self._update_readme(src_path)
                        except Exception as e:
                            self.logger.error(f"âŒ æ›´æ–°æ–‡ä»¶å¤±è´¥: {src_path}, é”™è¯¯: {e}")
                            self.failed_operations.append(("update", str(src_path), str(e)))
                    else:
                        self.logger.warning(f"âš ï¸ æ–‡ä»¶ä¸å­˜åœ¨ï¼Œè·³è¿‡æ›´æ–°æ“ä½œ: {src_path}")
            elif action == 'create':
                # åˆ›å»ºæ–‡ä»¶
                if self.simulate:
                    self.logger.info(f"ğŸ“‹ [æ¨¡æ‹Ÿ] å°†åˆ›å»ºæ–‡ä»¶: {dest_path}")
                else:
                    if not dest_path.exists():
                        try:
                            # è¿™é‡Œå¯ä»¥æ·»åŠ åˆ›å»ºæ–‡ä»¶çš„é€»è¾‘
                            # ä¾‹å¦‚åˆ›å»º.gitignoreæ–‡ä»¶
                            if src == '.gitignore':
                                self._create_gitignore(dest_path)
                        except Exception as e:
                            self.logger.error(f"âŒ åˆ›å»ºæ–‡ä»¶å¤±è´¥: {dest_path}, é”™è¯¯: {e}")
                            self.failed_operations.append(("create", str(dest_path), str(e)))
                    else:
                        self.logger.warning(f"âš ï¸ æ–‡ä»¶å·²å­˜åœ¨ï¼Œè·³è¿‡åˆ›å»ºæ“ä½œ: {dest_path}")
    
    def _update_readme(self, readme_path):
        """æ›´æ–°README.mdæ–‡ä»¶"""
        try:
            # è¯»å–ç°æœ‰å†…å®¹
            with open(readme_path, 'r', encoding='utf-8') as f:
                content = f.read()
            
            # æ£€æŸ¥æ˜¯å¦å·²ç»åŒ…å«é¡¹ç›®ç»“æ„ä¿¡æ¯
            if "## é¡¹ç›®ç»“æ„" not in content:
                # æ·»åŠ é¡¹ç›®ç»“æ„ä¿¡æ¯
                new_content = content + "\n\n## é¡¹ç›®ç»“æ„\n\n""
                ```\n"
                "â”œâ”€â”€ sync_system/           # åŒæ­¥ç³»ç»Ÿä»£ç \n"
                "â”‚   â”œâ”€â”€ main.py            # åŒæ­¥ç³»ç»Ÿå…¥å£\n"
                "â”‚   â”œâ”€â”€ adapters/          # åŒæ­¥ç³»ç»Ÿé€‚é…å™¨\n"
                "â”‚   â””â”€â”€ config/            # åŒæ­¥ç³»ç»Ÿé…ç½®\n"
                "â”œâ”€â”€ async_system/          # å¼‚æ­¥ç³»ç»Ÿä»£ç \n"
                "â”‚   â”œâ”€â”€ main.py            # å¼‚æ­¥ç³»ç»Ÿå…¥å£\n"
                "â”‚   â”œâ”€â”€ audio/             # å¼‚æ­¥éŸ³é¢‘å¤„ç†\n"
                "â”‚   â”œâ”€â”€ processing/        # å¼‚æ­¥æ•°æ®å¤„ç†\n"
                "â”‚   â””â”€â”€ config/            # å¼‚æ­¥ç³»ç»Ÿé…ç½®\n"
                "â”œâ”€â”€ shared/                # å…±äº«ç»„ä»¶\n"
                "â”‚   â”œâ”€â”€ interfaces/        # å…±äº«æ¥å£å®šä¹‰\n"
                "â”‚   â”œâ”€â”€ utils/             # å…±äº«å·¥å…·ç±»\n"
                "â”‚   â””â”€â”€ models/            # å…±äº«æ¨¡å‹æ–‡ä»¶\n"
                "â”œâ”€â”€ tests/                 # æµ‹è¯•ä»£ç \n"
                "â”œâ”€â”€ docs/                  # æ–‡æ¡£\n"
                "â”œâ”€â”€ logs/                  # æ—¥å¿—æ–‡ä»¶\n"
                "â”‚   â”œâ”€â”€ sync/              # åŒæ­¥ç³»ç»Ÿæ—¥å¿—\n"
                "â”‚   â””â”€â”€ async/             # å¼‚æ­¥ç³»ç»Ÿæ—¥å¿—\n"
                "â”œâ”€â”€ requirements.txt       # é¡¹ç›®ä¾èµ–\n"
                "â”œâ”€â”€ README.md              # é¡¹ç›®è¯´æ˜\n"
                "â””â”€â”€ .gitignore             # Gitå¿½ç•¥è§„åˆ™\n"
                "```\n""
            
            # æ›´æ–°README.md
            
                with open(readme_path, 'w', encoding='utf-8') as f:
                    f.write(new_content)
                    self.logger.info(f"âœ… æ›´æ–°README.mdæˆåŠŸ: {readme_path}")
            else:
                    self.logger.info(f"âœ… README.mdå·²åŒ…å«é¡¹ç›®ç»“æ„ä¿¡æ¯ï¼Œè·³è¿‡æ›´æ–°: {readme_path}")
        except Exception as e:
    
            self.logger.error(f"âŒ æ›´æ–°README.mdå¤±è´¥: {e}")
            raise
    
    def _create_gitignore(self, gitignore_path):
        """åˆ›å»º.gitignoreæ–‡ä»¶"""
        try:
            gitignore_content = """
# Python
__pycache__/
*.py[cod]
*$py.class

# Virtual environments
venv/
.env
.env.local
.env.development.local
.env.test.local
.env.production.local

# IDEs and editors
.vscode/
.idea/
*.swp
*.swo
*~

# OS generated files
.DS_Store
.DS_Store?
._*
.Spotlight-V100
.Trashes
ehthumbs.db
Thumbs.db

# Logs
logs/
*.log

# Runtime data
pids
*.pid
*.seed
*.pid.lock

# Coverage directory used by tools like istanbul
coverage/

# nyc test coverage
.nyc_output

# Grunt intermediate storage (https://gruntjs.com/creating-plugins#storing-task-files)
.grunt

# Bower dependency directory (https://bower.io/)
bower_components/

# node-waf configuration
.lock-wscript

# Compiled binary addons (https://nodejs.org/api/addons.html)
build/Release

# Dependency directories
node_modules/
jspm_packages/

# Snowpack dependency directory (https://snowpack.dev/)
web_modules/

# TypeScript cache
*.tsbuildinfo

# Optional npm cache directory
.npm

# Optional eslint cache
.eslintcache

# Microbundle cache
.rpt2_cache/
.rts2_cache_cjs/
.rts2_cache_es/
.rts2_cache_umd/

# Optional REPL history
.node_repl_history

# Output of 'npm pack'
*.tgz

# Yarn Integrity file
.yarn-integrity

# parcel-bundler cache (https://parceljs.org/)
.cache
.parcel-cache

# Next.js build output
.next

# Nuxt.js build / generate output
.nuxt
dist

# Gatsby files
.cache/
public

# vuepress build output
.vuepress/dist

# vuepress v2.x temp and cache directory
.temp
.cache

# Serverless directories
.serverless/

# FuseBox cache
.fusebox/

# DynamoDB Local files
.dynamodb/

# TernJS port file
.tern-port

# Stores VSCode versions used for testing VSCode extensions
.vscode-test

# yarn v2
.yarn/cache
.yarn/unplugged
.yarn/build-state.yml
.yarn/install-state.gz
.pnp.*

# Excel files
*.xlsx
*.xls
!tests/*.xlsx
!tests/*.xls

# Model files (å¦‚æœæ¨¡å‹æ–‡ä»¶å¾ˆå¤§ï¼Œå¯ä»¥è€ƒè™‘ä¸æäº¤)
# shared/models/
"""
            
            with open(gitignore_path, 'w', encoding='utf-8') as f:
                f.write(gitignore_content.strip())
            self.logger.info(f"âœ… åˆ›å»º.gitignoreæˆåŠŸ: {gitignore_path}")
        except Exception as e:
            self.logger.error(f"âŒ åˆ›å»º.gitignoreå¤±è´¥: {e}")
            raise
    
    def create_venv_files(self):
        """åˆ›å»ºè™šæ‹Ÿç¯å¢ƒç›¸å…³æ–‡ä»¶"""
        self.logger.info("ğŸ å¼€å§‹åˆ›å»ºè™šæ‹Ÿç¯å¢ƒç›¸å…³æ–‡ä»¶...")
        
        # åˆ›å»ºåŒæ­¥ç³»ç»Ÿvenvé…ç½®
        sync_venv_file = self.project_root / 'sync_system' / 'requirements.txt'
        if not sync_venv_file.exists():
            if self.simulate:
                self.logger.info(f"ğŸ“‹ [æ¨¡æ‹Ÿ] å°†åˆ›å»ºåŒæ­¥ç³»ç»Ÿrequirements.txt: {sync_venv_file}")
            else:
                try:
                    # å¤åˆ¶ä¸»requirements.txtå†…å®¹
                    main_requirements = self.project_root / 'requirements.txt'
                    if main_requirements.exists():
                        shutil.copy2(str(main_requirements), str(sync_venv_file))
                        self.logger.info(f"âœ… åˆ›å»ºåŒæ­¥ç³»ç»Ÿrequirements.txtæˆåŠŸ: {sync_venv_file}")
                    else:
                        # åˆ›å»ºç©ºæ–‡ä»¶æˆ–é»˜è®¤å†…å®¹
                        with open(sync_venv_file, 'w', encoding='utf-8') as f:
                            f.write("# åŒæ­¥ç³»ç»Ÿä¾èµ–\n")
                        self.logger.info(f"âœ… åˆ›å»ºç©ºçš„åŒæ­¥ç³»ç»Ÿrequirements.txtæˆåŠŸ: {sync_venv_file}")
                except Exception as e:
                    self.logger.error(f"âŒ åˆ›å»ºåŒæ­¥ç³»ç»Ÿrequirements.txtå¤±è´¥: {e}")
                    self.failed_operations.append(("create", str(sync_venv_file), str(e)))
        else:
            self.logger.warning(f"âš ï¸ åŒæ­¥ç³»ç»Ÿrequirements.txtå·²å­˜åœ¨: {sync_venv_file}")
        
        # åˆ›å»ºå¼‚æ­¥ç³»ç»Ÿvenvé…ç½®
        async_venv_file = self.project_root / 'async_system' / 'requirements.txt'
        if not async_venv_file.exists():
            if self.simulate:
                self.logger.info(f"ğŸ“‹ [æ¨¡æ‹Ÿ] å°†åˆ›å»ºå¼‚æ­¥ç³»ç»Ÿrequirements.txt: {async_venv_file}")
            else:
                try:
                    # å¤åˆ¶ä¸»requirements.txtå†…å®¹
                    main_requirements = self.project_root / 'requirements.txt'
                    if main_requirements.exists():
                        shutil.copy2(str(main_requirements), str(async_venv_file))
                        self.logger.info(f"âœ… åˆ›å»ºå¼‚æ­¥ç³»ç»Ÿrequirements.txtæˆåŠŸ: {async_venv_file}")
                    else:
                        # åˆ›å»ºç©ºæ–‡ä»¶æˆ–é»˜è®¤å†…å®¹
                        with open(async_venv_file, 'w', encoding='utf-8') as f:
                            f.write("# å¼‚æ­¥ç³»ç»Ÿä¾èµ–\n")
                        self.logger.info(f"âœ… åˆ›å»ºç©ºçš„å¼‚æ­¥ç³»ç»Ÿrequirements.txtæˆåŠŸ: {async_venv_file}")
                except Exception as e:
                    self.logger.error(f"âŒ åˆ›å»ºå¼‚æ­¥ç³»ç»Ÿrequirements.txtå¤±è´¥: {e}")
                    self.failed_operations.append(("create", str(async_venv_file), str(e)))
        else:
            self.logger.warning(f"âš ï¸ å¼‚æ­¥ç³»ç»Ÿrequirements.txtå·²å­˜åœ¨: {async_venv_file}")
    
    def generate_report(self):
        """ç”Ÿæˆé‡æ„æŠ¥å‘Š"""
        self.logger.info("ğŸ“Š ç”Ÿæˆé‡æ„æŠ¥å‘Š...")
        
        report_path = self.project_root / 'logs' / 'restructure_report.md'
        
        try:
            with open(report_path, 'w', encoding='utf-8') as f:
                f.write("# é¡¹ç›®é‡æ„æŠ¥å‘Š\n\n")
                f.write(f"## é‡æ„æ—¶é—´\n\n{self.logger.handlers[1].formatter.formatTime(logging.LogRecord('dummy', logging.INFO, '', 0, '', (), None))}\n\n")
                f.write("## é‡æ„æ¨¡å¼\n\n")
                f.write(f"- æ¨¡æ‹Ÿè¿è¡Œ: {'æ˜¯' if self.simulate else 'å¦'}\n\n")
                
                f.write("## åˆ›å»ºçš„ç›®å½•\n\n")
                if self.created_directories:
                    for dir_path in sorted(self.created_directories):
                        f.write(f"- {dir_path}\n")
                else:
                    f.write("- æ— \n")
                f.write("\n")
                
                f.write("## ç§»åŠ¨çš„æ–‡ä»¶\n\n")
                if self.moved_files:
                    for src, dest in self.moved_files:
                        f.write(f"- {src} -> {dest}\n")
                else:
                    f.write("- æ— \n")
                f.write("\n")
                
                f.write("## è·³è¿‡çš„æ–‡ä»¶\n\n")
                if self.skipped_files:
                    for file_path in sorted(self.skipped_files):
                        f.write(f"- {file_path}\n")
                else:
                    f.write("- æ— \n")
                f.write("\n")
                
                f.write("## å¤±è´¥çš„æ“ä½œ\n\n")
                if self.failed_operations:
                    for op in self.failed_operations:
                        if len(op) == 4:
                            action, src, dest, error = op
                            f.write(f"- {action}: {src} -> {dest}, é”™è¯¯: {error}\n")
                        elif len(op) == 3:
                            action, path, error = op
                            f.write(f"- {action}: {path}, é”™è¯¯: {error}\n")
                        else:
                            f.write(f"- {op}\n")
                else:
                    f.write("- æ— \n")
                f.write("\n")
                
                f.write("## é‡æ„å»ºè®®\n\n")
                if self.failed_operations:
                    f.write("1. æ£€æŸ¥å¤±è´¥çš„æ“ä½œï¼Œæ‰‹åŠ¨å¤„ç†è¿™äº›é—®é¢˜\n")
                f.write("1. é‡æ„å®Œæˆåï¼Œå»ºè®®è¿è¡Œæµ‹è¯•ç¡®ä¿ç³»ç»ŸåŠŸèƒ½æ­£å¸¸\n")
                f.write("2. æ ¹æ®æ–°çš„ç›®å½•ç»“æ„æ›´æ–°å¯¼å…¥è·¯å¾„\n")
                f.write("3. è€ƒè™‘ä¸ºåŒæ­¥å’Œå¼‚æ­¥ç³»ç»Ÿåˆ›å»ºç‹¬ç«‹çš„è™šæ‹Ÿç¯å¢ƒ\n")
                f.write("4. æ›´æ–°Gitä»“åº“ä»¥åæ˜ æ–°çš„é¡¹ç›®ç»“æ„\n")
            
            self.logger.info(f"âœ… é‡æ„æŠ¥å‘Šç”ŸæˆæˆåŠŸ: {report_path}")
            
            # æ‰“å°æ‘˜è¦
            self.logger.info("\nğŸ“‹ é‡æ„æ‘˜è¦:")
            self.logger.info(f"âœ… åˆ›å»ºç›®å½•: {len(self.created_directories)}")
            self.logger.info(f"âœ… ç§»åŠ¨æ–‡ä»¶: {len(self.moved_files)}")
            self.logger.info(f"âš ï¸ è·³è¿‡æ–‡ä»¶: {len(self.skipped_files)}")
            self.logger.info(f"âŒ å¤±è´¥æ“ä½œ: {len(self.failed_operations)}")
            self.logger.info(f"ğŸ“Š è¯¦ç»†æŠ¥å‘Š: {report_path}")
        except Exception as e:
            self.logger.error(f"âŒ ç”Ÿæˆé‡æ„æŠ¥å‘Šå¤±è´¥: {e}")
    
    def run(self):
        """æ‰§è¡Œé‡æ„è¿‡ç¨‹"""
        self.logger.info("ğŸš€ å¼€å§‹é¡¹ç›®é‡æ„...")
        
        try:
            # 1. åˆ›å»ºç›®å½•ç»“æ„
            self.create_directories()
            
            # 2. ç§»åŠ¨æ–‡ä»¶
            self.move_files()
            
            # 3. å¤„ç†ç‰¹æ®Šæ–‡ä»¶
            self.handle_special_files()
            
            # 4. åˆ›å»ºè™šæ‹Ÿç¯å¢ƒç›¸å…³æ–‡ä»¶
            self.create_venv_files()
            
            # 5. ç”Ÿæˆé‡æ„æŠ¥å‘Š
            self.generate_report()
            
            if self.simulate:
                self.logger.info("âœ… æ¨¡æ‹Ÿé‡æ„å®Œæˆï¼Œè¯·æ£€æŸ¥è¾“å‡ºå¹¶ç¡®è®¤åå†æ‰§è¡Œå®é™…é‡æ„")
            else:
                self.logger.info("âœ… é¡¹ç›®é‡æ„å®Œæˆï¼")
            
        except Exception as e:
            self.logger.error(f"âŒ é‡æ„è¿‡ç¨‹ä¸­å‘ç”Ÿå¼‚å¸¸: {e}")
            self.failed_operations.append(("run", "æ•´ä¸ªé‡æ„è¿‡ç¨‹", str(e)))
            self.generate_report()
            raise


# ä¸»å‡½æ•°
def main():
    """ä¸»å‡½æ•°"""
    # è§£æå‘½ä»¤è¡Œå‚æ•°
    parser = argparse.ArgumentParser(description='é¡¹ç›®é‡æ„å·¥å…·')
    parser.add_argument('--simulate', '-s', action='store_true', help='æ¨¡æ‹Ÿè¿è¡Œæ¨¡å¼ï¼Œä¸å®é™…æ‰§è¡Œæ–‡ä»¶æ“ä½œ')
    parser.add_argument('--verbose', '-v', action='store_true', help='è¯¦ç»†è¾“å‡ºæ¨¡å¼')
    args = parser.parse_args()
    
    # ç¡®å®šæ—¥å¿—çº§åˆ«
    log_level = logging.DEBUG if args.verbose else logging.INFO
    
    # åˆ›å»ºé‡æ„å™¨å®ä¾‹
    restructurer = ProjectRestructurer(simulate=args.simulate, log_level=log_level)
    
    # æ‰§è¡Œé‡æ„
    try:
        restructurer.run()
        return 0
    except Exception as e:
        print(f"âŒ é‡æ„å¤±è´¥: {e}")
        return 1


# ç¨‹åºå…¥å£
if __name__ == "__main__":
    sys.exit(main())