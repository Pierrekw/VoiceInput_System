#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
FunASR CPUä¼˜åŒ–ç‰ˆæœ¬æµ‹è¯•ç¨‹åº
é’ˆå¯¹é›†æˆæ˜¾å¡å’Œä½é…ç½®ç”µè„‘ä¼˜åŒ–ï¼Œä½¿ç”¨CPUæ¨ç†
"""

import os
import sys
import time
import logging
import numpy as np
from contextlib import contextmanager

# é…ç½®æ—¥å¿—
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s',
    datefmt='%Y-%m-%d %H:%M:%S'
)
logger = logging.getLogger(__name__)

# å°è¯•å¯¼å…¥FunASR
FUNASR_AVAILABLE = False
try:
    from funasr import AutoModel
    FUNASR_AVAILABLE = True
    logger.info("âœ… æˆåŠŸå¯¼å…¥FunASRæ¨¡å—")
except ImportError as e:
    logger.error(f"âŒ æ— æ³•å¯¼å…¥FunASRæ¨¡å—: {e}")
    logger.error("è¯·å®‰è£…FunASR: pip install funasr")
    AutoModel = None

# éŸ³é¢‘æµä¸Šä¸‹æ–‡ç®¡ç†å™¨
@contextmanager
def audio_stream(sample_rate=16000, chunk_size=8000):
    """æ‰“å¼€PyAudioè¾“å…¥æµå¹¶è‡ªåŠ¨æ¸…ç†"""
    import pyaudio

    p = pyaudio.PyAudio()
    stream = None
    try:
        # è·å–é»˜è®¤éŸ³é¢‘è®¾å¤‡ä¿¡æ¯
        default_device = p.get_default_input_device_info()
        logger.info(f"ğŸ¤ ä½¿ç”¨éŸ³é¢‘è®¾å¤‡: {default_device['name']} (ç´¢å¼•: {default_device['index']})")

        # æ‰“å¼€éŸ³é¢‘æµ
        stream = p.open(
            format=pyaudio.paInt16,
            channels=1,
            rate=sample_rate,
            input=True,
            frames_per_buffer=chunk_size,
            start=True
        )
        logger.info(f"ğŸ§ éŸ³é¢‘æµåˆ›å»ºæˆåŠŸ - æ´»åŠ¨çŠ¶æ€: {stream.is_active()}")
        yield stream
    except Exception as e:
        logger.error(f"âŒ éŸ³é¢‘æµåˆ›å»ºå¤±è´¥: {e}")
        raise
    finally:
        # èµ„æºæ¸…ç†
        if stream:
            if stream.is_active():
                stream.stop_stream()
            stream.close()
        p.terminate()

class FunASRCpuOptimizedTest:
    """FunASR CPUä¼˜åŒ–æµ‹è¯•ç±»"""

    def __init__(self, model_path="f:\\04_AI\\01_Workplace\\Voice_Input\\model\\fun"):
        """åˆå§‹åŒ–æµ‹è¯•ç±»"""
        self.model_path = model_path
        self._model = None
        self.model_loaded = False
        self.load_time = 0.0
        self.sample_rate = 16000
        self.chunk_size = 8000

    def load_model(self):
        """åŠ è½½FunASRæ¨¡å‹ï¼ˆCPUä¼˜åŒ–ç‰ˆæœ¬ï¼‰"""
        if not FUNASR_AVAILABLE:
            logger.error("âŒ FunASRæ¨¡å—ä¸å¯ç”¨ï¼Œæ— æ³•åŠ è½½æ¨¡å‹")
            return False

        if self.model_loaded and self._model is not None:
            logger.info("âœ… FunASRæ¨¡å‹å·²åŠ è½½ï¼Œæ— éœ€é‡å¤åŠ è½½")
            return True

        logger.info(f"ğŸ“¦ å¼€å§‹åŠ è½½FunASR CPUä¼˜åŒ–æ¨¡å‹: {self.model_path}")
        start_time = time.time()

        try:
            # åˆ›å»ºFunASRæ¨¡å‹ï¼Œå¼ºåˆ¶ä½¿ç”¨CPU
            logger.info("ğŸ”„ æ­£åœ¨åˆå§‹åŒ–CPUä¼˜åŒ–æ¨¡å‹...")
            logger.info(f"  - model: {self.model_path}")
            logger.info("  - device: cpu (CPUä¼˜åŒ–æ¨¡å¼)")
            logger.info("  - é€‚åˆ: é›†æˆæ˜¾å¡ã€ä½é…ç½®ç”µè„‘")

            # ä½¿ç”¨CPUè®¾å¤‡ï¼Œé€‚åˆé›†æˆæ˜¾å¡
            self._model = AutoModel(
                model=self.model_path,
                device="cpu",
                trust_remote_code=False  # ç¡®ä¿ä½¿ç”¨æœ¬åœ°ä»£ç 
            )

            self.model_loaded = True
            self.load_time = time.time() - start_time
            logger.info(f"âœ… FunASR CPUä¼˜åŒ–æ¨¡å‹åŠ è½½å®Œæˆ (è€—æ—¶: {self.load_time:.2f}ç§’)")
            return True

        except Exception as e:
            logger.error(f"âŒ FunASRæ¨¡å‹åŠ è½½å¤±è´¥: {e}")
            import traceback
            logger.error(f"è¯¦ç»†é”™è¯¯ä¿¡æ¯:\n{traceback.format_exc()}")
            self._model = None
            self.model_loaded = False
            return False

    def test_recognition(self, duration=30):
        """æµ‹è¯•è¯­éŸ³è¯†åˆ«åŠŸèƒ½ - CPUä¼˜åŒ–ç‰ˆæœ¬"""
        if not FUNASR_AVAILABLE:
            logger.error("âŒ FunASRæ¨¡å—ä¸å¯ç”¨ï¼Œæ— æ³•è¿›è¡Œè¯†åˆ«æµ‹è¯•")
            return False

        if not self.model_loaded or self._model is None:
            logger.warning("âš ï¸ æ¨¡å‹æœªåŠ è½½ï¼Œå°è¯•åŠ è½½...")
            if not self.load_model():
                logger.error("âŒ æ— æ³•åŠ è½½æ¨¡å‹ï¼Œæµ‹è¯•ç»ˆæ­¢")
                return False

        logger.info("ğŸ¤ å‡†å¤‡è¿›è¡ŒCPUä¼˜åŒ–ç‰ˆè¯­éŸ³è¯†åˆ«æµ‹è¯•...")

        print("=" * 60)
        print("ğŸ“¢ FunASR CPUä¼˜åŒ– è¯­éŸ³è¯†åˆ«æµ‹è¯•")
        print("=" * 60)
        print("ğŸ”Š è¯·ç¡®ä¿æ‚¨çš„éº¦å…‹é£å·²å¼€å¯å¹¶æ­£å¸¸å·¥ä½œ")
        print(f"â±ï¸  æµ‹è¯•å°†æŒç»­ {duration} ç§’")
        print("ğŸ’¬ è¯·åœ¨æç¤ºå¼€å§‹åå¯¹ç€éº¦å…‹é£è¯´è¯")
        print("ğŸ¯ æ‚¨å¯ä»¥è¯´ä¸€äº›ä¸­æ–‡å¥å­")
        print("âš¡ ä¼˜åŒ–: CPUæ¨ç†ï¼Œé€‚åˆé›†æˆæ˜¾å¡")
        print("ğŸ”§ é›†æˆåŠŸèƒ½: VAD + PUNC")
        print("=" * 60)

        # æ£€æŸ¥æ˜¯å¦ä¸ºäº¤äº’å¼ç¯å¢ƒ
        import sys
        is_interactive = hasattr(sys, 'ps1') or sys.flags.interactive

        if is_interactive:
            print("\nè¯·æŒ‰Enteré”®å¼€å§‹æµ‹è¯•...")
            input()

        # å€’è®¡æ—¶
        countdown = 5
        print(f"\nâ° å½•éŸ³å°†åœ¨ {countdown} ç§’åå¼€å§‹...")
        for i in range(countdown, 0, -1):
            print(f"ğŸ”´ å‡†å¤‡ä¸­: {i}ç§’ ", end="\r")
            time.sleep(1)
        print()
        print("""
==================================================================
ğŸ”µ æ­£åœ¨å½•éŸ³ï¼è¯·å¯¹ç€éº¦å…‹é£è¯´è¯...ğŸ”µ
==================================================================
        """)

        # è¯­éŸ³æ´»åŠ¨æ£€æµ‹å‚æ•° - CPUä¼˜åŒ–ç‰ˆ
        speech_energy_threshold = 0.02   # ç•¥å¾®æé«˜é˜ˆå€¼ï¼Œå‡å°‘è¯¯æ£€æµ‹
        min_speech_duration = 0.4        # æœ€å°è¯­éŸ³æ—¶é•¿
        min_silence_duration = 0.8       # é™éŸ³æ—¶é•¿

        # è¯†åˆ«çŠ¶æ€æ§åˆ¶
        speech_segment_audio = []
        is_speech_segment = False
        speech_start_time = 0
        last_speech_time = 0
        recognition_count = 0
        last_recognized_text = ""
        collected_text = []

        # æ–‡æœ¬ç›¸ä¼¼åº¦æ£€æµ‹
        def calculate_text_similarity(text1, text2):
            """è®¡ç®—æ–‡æœ¬ç›¸ä¼¼åº¦"""
            if not text1 or not text2:
                return 0.0
            import re
            clean1 = re.sub(r'[^\w]', '', text1.lower())
            clean2 = re.sub(r'[^\w]', '', text2.lower())
            if not clean1 or not clean2:
                return 0.0
            set1, set2 = set(clean1), set(clean2)
            intersection = len(set1.intersection(set2))
            union = len(set1.union(set2))
            return intersection / union if union > 0 else 0.0

        def is_duplicate_text(new_text, previous_text):
            """åˆ¤æ–­é‡å¤æ–‡æœ¬"""
            if not previous_text:
                return False
            similarity = calculate_text_similarity(new_text, previous_text)
            return similarity >= 0.8

        def post_process_text(text):
            """åå¤„ç†æ–‡æœ¬"""
            if not text:
                return text
            # ç§»é™¤é‡å¤å­—ç¬¦
            result = []
            prev_char = None
            for char in text:
                if char != prev_char:
                    result.append(char)
                prev_char = char
            return ''.join(result)

        def is_valid_text(text):
            """æ£€æŸ¥æ–‡æœ¬æœ‰æ•ˆæ€§"""
            if not text or len(text.strip()) < 2:
                return False
            # è¿‡æ»¤è¯¯è¯†åˆ«
            invalid_patterns = ['e', 'yeah', 'å—¯', 'å•Š', 'å“¦', 'å‘ƒ', 'é¢']
            text_clean = text.strip().lower()
            for pattern in invalid_patterns:
                if text_clean == pattern or text_clean.count(pattern) > 2:
                    return False
            # æ£€æŸ¥æœ‰æ„ä¹‰å­—ç¬¦
            import re
            meaningful_chars = re.findall(r'[\u4e00-\u9fff\w]', text)
            return len(meaningful_chars) >= 2

        try:
            with audio_stream(sample_rate=self.sample_rate, chunk_size=self.chunk_size) as stream:
                print("\nğŸ”´ ä½¿ç”¨FunASR CPUä¼˜åŒ–ç‰ˆæœ¬è¿›è¡Œè¯­éŸ³è¯†åˆ«...")
                print("ğŸ’¡ CPUæ¨ç†æ¨¡å¼ï¼Œé€‚åˆé›†æˆæ˜¾å¡å’Œä½é…ç½®ç”µè„‘")

                start_time = time.time()
                frames_processed = 0

                while time.time() - start_time < duration:
                    try:
                        # è¯»å–éŸ³é¢‘æ•°æ®
                        data = stream.read(self.chunk_size, exception_on_overflow=False)
                        frames_processed += 1

                        # è½¬æ¢ä¸ºnumpyæ•°ç»„
                        audio_data = np.frombuffer(data, dtype=np.int16).astype(np.float32) / 32768.0
                        current_time = time.time() - start_time

                        # è®¡ç®—éŸ³é¢‘èƒ½é‡
                        audio_energy = np.sqrt(np.mean(audio_data**2))
                        is_speech = audio_energy > speech_energy_threshold

                        if is_speech and not is_speech_segment:
                            # å¼€å§‹è¯­éŸ³æ®µ
                            is_speech_segment = True
                            speech_start_time = current_time
                            speech_segment_audio = []
                            logger.info(f"ğŸ¯ å¼€å§‹è¯­éŸ³æ®µï¼Œèƒ½é‡: {audio_energy:.4f}")

                        elif is_speech and is_speech_segment:
                            # ç»§ç»­è¯­éŸ³æ®µ
                            last_speech_time = current_time

                        elif not is_speech and is_speech_segment:
                            # æ£€æŸ¥è¯­éŸ³æ˜¯å¦ç»“æŸ
                            silence_duration = current_time - last_speech_time
                            speech_duration = current_time - speech_start_time

                            should_end = (
                                silence_duration >= min_silence_duration or
                                (silence_duration >= 0.5 and speech_duration >= 1.0)
                            )

                            if should_end:
                                # è¯­éŸ³æ®µç»“æŸï¼Œè¿›è¡Œè¯†åˆ«
                                is_speech_segment = False

                                if speech_duration >= min_speech_duration and len(speech_segment_audio) > 0:
                                    recognition_count += 1
                                    logger.info(f"è¯­éŸ³æ®µç»“æŸï¼Œæ—¶é•¿: {speech_duration:.2f}s")

                                    # ä½¿ç”¨FunASRè¿›è¡Œè¯†åˆ«
                                    try:
                                        result = self._model.generate(
                                            input=np.array(speech_segment_audio)
                                        )

                                        if result and isinstance(result, list) and len(result) > 0 and "text" in result[0]:
                                            raw_text = result[0]["text"].strip()
                                            if raw_text:
                                                processed_text = post_process_text(raw_text)

                                                if is_valid_text(processed_text):
                                                    if not is_duplicate_text(processed_text, last_recognized_text):
                                                        last_recognized_text = processed_text
                                                        collected_text.append(processed_text)

                                                        print(f"\nğŸ¯ CPUè¯†åˆ«: {processed_text}")
                                                        logger.info(f"è¯†åˆ«ç»“æœ: '{processed_text}'")

                                    except Exception as e:
                                        logger.debug(f"è¯†åˆ«å¼‚å¸¸: {e}")

                        # æ”¶é›†è¯­éŸ³æ•°æ®
                        if is_speech_segment:
                            speech_segment_audio.extend(audio_data)

                        # çŠ¶æ€æ˜¾ç¤º
                        remaining_time = duration - current_time
                        if frames_processed % 50 == 0:
                            if is_speech_segment:
                                status = "ğŸ—£ï¸ è¯´è¯ä¸­"
                                speech_duration = current_time - speech_start_time
                                extra_info = f"({speech_duration:.1f}s)"
                            else:
                                status = "ğŸ”‡ é™éŸ³"
                                extra_info = ""

                            print(f"\r{status}{extra_info} | èƒ½é‡:{audio_energy:.4f} | å‰©ä½™:{remaining_time:.1f}s | è¯†åˆ«:{recognition_count} | ", end="", flush=True)

                    except Exception as e:
                        logger.error(f"âŒ éŸ³é¢‘å¤„ç†é”™è¯¯: {e}")
                        continue

                # å¤„ç†æœ€ç»ˆç»“æœ
                print(f"\nğŸ å½•éŸ³ç»“æŸï¼Œå¤„ç†æœ€ç»ˆç»“æœ...")

                if is_speech_segment and len(speech_segment_audio) > 0:
                    speech_duration = time.time() - start_time - speech_start_time
                    if speech_duration >= min_speech_duration:
                        try:
                            final_result = self._model.generate(
                                input=np.array(speech_segment_audio)
                            )
                            if final_result and isinstance(final_result, list) and len(final_result) > 0 and "text" in final_result[0]:
                                final_text = final_result[0]["text"].strip()
                                if final_text and final_text != last_recognized_text:
                                    collected_text.append(final_text)
                                    print(f"ğŸ¯ æœ€ç»ˆè¯†åˆ«: {final_text}")
                        except Exception as e:
                            logger.debug(f"æœ€ç»ˆè¯†åˆ«å¼‚å¸¸: {e}")

                # è¾“å‡ºç»Ÿè®¡ä¿¡æ¯
                print("\n" + "=" * 60)
                print("ğŸ“Š CPUä¼˜åŒ–ç‰ˆæµ‹è¯•ç»“æœ")
                print("=" * 60)

                if collected_text:
                    # å»é‡
                    unique_texts = []
                    for text in collected_text:
                        if not unique_texts or not is_duplicate_text(text, unique_texts[-1]):
                            unique_texts.append(text)

                    final_text = " ".join(unique_texts)
                    print(f"ğŸ“ è¯†åˆ«æ–‡æœ¬: {final_text}")
                    print(f"ğŸ”¢ ç‰‡æ®µæ•°é‡: {len(unique_texts)} (å»é‡å)")

                    for i, text in enumerate(unique_texts, 1):
                        print(f"   {i}. {text}")
                else:
                    print("âŒ æœªè¯†åˆ«åˆ°è¯­éŸ³å†…å®¹")
                    print("\nğŸ’¡ å¯èƒ½åŸå› :")
                    print("   - éº¦å…‹é£é—®é¢˜")
                    print("   - è¯´è¯éŸ³é‡å¤ªå°")
                    print("   - ç¯å¢ƒå™ªéŸ³")
                    print("   - æ¨¡å‹é…ç½®é—®é¢˜")

                print(f"\nğŸ“ˆ CPUä¼˜åŒ–ç»Ÿè®¡:")
                print(f"   - æµ‹è¯•æ—¶é•¿: {duration}ç§’")
                print(f"   - æ¨¡å‹åŠ è½½: {self.load_time:.2f}ç§’")
                print(f"   - å¤„ç†å¸§æ•°: {frames_processed}")
                print(f"   - è¯†åˆ«æ¬¡æ•°: {recognition_count}")

                print(f"\nğŸ’¡ CPUä¼˜åŒ–ä¼˜åŠ¿:")
                print(f"   - âœ… é€‚åˆé›†æˆæ˜¾å¡")
                print(f"   - âœ… ä½å†…å­˜å ç”¨")
                print(f"   - âœ… ç¨³å®šæ¨ç†")
                print(f"   - âœ… å…¼å®¹æ€§å¥½")

                return True

        except KeyboardInterrupt:
            print("\nâ¹ï¸  æµ‹è¯•è¢«ç”¨æˆ·ä¸­æ–­")
            return True
        except Exception as e:
            logger.error(f"âŒ æµ‹è¯•é”™è¯¯: {e}")
            return False

    def get_status(self):
        """è·å–çŠ¶æ€ä¿¡æ¯"""
        return {
            "funasr_available": FUNASR_AVAILABLE,
            "model_loaded": self.model_loaded,
            "model_path": self.model_path,
            "load_time": self.load_time
        }

    def print_status(self):
        """æ‰“å°çŠ¶æ€ä¿¡æ¯"""
        status = self.get_status()
        print("\nğŸ“Š CPUä¼˜åŒ–ç‰ˆçŠ¶æ€:")
        print(f"  - FunASRå¯ç”¨: {'âœ… æ˜¯' if status['funasr_available'] else 'âŒ å¦'}")
        print(f"  - æ¨¡å‹åŠ è½½: {'âœ… å·²åŠ è½½' if status['model_loaded'] else 'âŒ æœªåŠ è½½'}")
        print(f"  - æ¨¡å‹è·¯å¾„: {status['model_path']}")
        print(f"  - åŠ è½½æ—¶é—´: {status['load_time']:.2f}ç§’" if status['load_time'] > 0 else "  - åŠ è½½æ—¶é—´: æœªåŠ è½½")

def main():
    """ä¸»å‡½æ•°"""
    print("=" * 60)
    print("ğŸ¯ FunASR CPUä¼˜åŒ– è¯­éŸ³è¯†åˆ«æµ‹è¯•")
    print("=" * 60)
    print("ğŸ’» é€‚åˆ: é›†æˆæ˜¾å¡ã€ä½é…ç½®ç”µè„‘")
    print("âš¡ ä¼˜åŒ–: CPUæ¨ç†ã€ä½å†…å­˜å ç”¨")
    print("\n")

    # åˆ›å»ºæµ‹è¯•å®ä¾‹
    tester = FunASRCpuOptimizedTest()
    tester.print_status()

    # æµ‹è¯•æ¨¡å‹åŠ è½½
    print("\nğŸ”„ å¼€å§‹æµ‹è¯•CPUä¼˜åŒ–æ¨¡å‹åŠ è½½...")
    load_success = tester.load_model()

    if load_success:
        tester.print_status()

        # æµ‹è¯•è¯­éŸ³è¯†åˆ«
        try:
            print("\n")
            tester.test_recognition(duration=30)
        except KeyboardInterrupt:
            print("\nâ¹ï¸  æµ‹è¯•è¢«ç”¨æˆ·ä¸­æ–­")

        print("\nâœ… CPUä¼˜åŒ–æµ‹è¯•å®Œæˆ")
    else:
        print("\nâŒ æ¨¡å‹åŠ è½½å¤±è´¥")
        print("ğŸ’¡ è¯·æ£€æŸ¥:")
        print("   1. FunASRæ˜¯å¦å®‰è£…: pip install funasr")
        print("   2. æ¨¡å‹è·¯å¾„æ˜¯å¦æ­£ç¡®")
        print("   3. Pythonç¯å¢ƒæ˜¯å¦å…¼å®¹")

if __name__ == "__main__":
    main()